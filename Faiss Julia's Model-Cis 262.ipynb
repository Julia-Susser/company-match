{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6897ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c2579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    #CLS is a special classification token and the last hidden state of BERT Embedding\n",
    "    def cls_pooling(self, model_output):\n",
    "        return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "    #BERT tokenizer of input text\n",
    "    def get_embeddings(self, text_list):\n",
    "        encoded_input = tokenizer(\n",
    "            text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        model_output = model(**encoded_input)\n",
    "        return self.cls_pooling(model_output).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ee4a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Faiss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #convert dataset into embeddings dataset to run FAISS\n",
    "    def makeEmbeddings(self,dataset,df=None):\n",
    "        embeddings = []\n",
    "        count = 0\n",
    "        for data in dataset:\n",
    "            print(count)\n",
    "            embeddings.append(Embedding().get_embeddings(data)[0])\n",
    "            count += 1\n",
    "        embeddings_dataset = pd.DataFrame(\n",
    "            {\n",
    "                \"embeddings\":embeddings,\n",
    "                \"values\":dataset\n",
    "            })\n",
    "        if (df is not None):\n",
    "            embeddings_dataset = pd.concat([df, embeddings_dataset], axis=1)\n",
    "        embeddings_dataset = Dataset.from_pandas(embeddings_dataset)\n",
    "        return embeddings_dataset\n",
    "    \n",
    "    # run faiss model on dataset\n",
    "    def faiss(self,embeddings_dataset):\n",
    "        embeddings_dataset.add_faiss_index(column=\"embeddings\")\n",
    "    \n",
    "    #get query embedding\n",
    "    def getQueryEmbedding(self, query):\n",
    "        return Embedding().get_embeddings([query])\n",
    "        \n",
    "    #predict 4 nearest neighbors\n",
    "    def predict(self,query,embeddings_dataset,k=4):\n",
    "        query_embedding = self.getQueryEmbedding(query)\n",
    "        scores, samples = embeddings_dataset.get_nearest_examples(\"embeddings\", query_embedding, k=5)\n",
    "        samples = pd.DataFrame(samples)\n",
    "        samples[\"scores\"] = scores\n",
    "        return samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f0aecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# open the pdf file\n",
    "reader = PdfReader(\"combined.pdf\")\n",
    "\n",
    "# get number of pages\n",
    "num_pages = len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64dd9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Copyright 2012 Cengage Learning. All Rights Reserved. May not be copied, scanned, or duplicated, in whole or in part. Due to electronic rights, some third party content may be suppressed from the eBook and/or eChapter(s). Editorial review has deemed that any suppressed content does not materially affect the overall learning experience. Cengage Learning reserves the right to remove additional content at any time if subsequent rights restrictions require it.\"\n",
    "dataset = [page.extract_text() for page in reader.pages]\n",
    "df = pd.DataFrame({\"page\":list(range(1,194))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c0e14dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['page', 'embeddings', 'values'],\n",
       "    num_rows: 193\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Faiss()\n",
    "embeddings_dataset = f.makeEmbeddings(dataset,df)\n",
    "embeddings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7400dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6444349390b84fc6aa6978149ee5c73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>values</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165</td>\n",
       "      <td>[0.039218176156282425, -0.7150614857673645, -0...</td>\n",
       "      <td>Another Problem for TMs\\n21P = { &lt;M&gt; | M is a ...</td>\n",
       "      <td>23.291431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>[0.031310174614191055, -0.34490180015563965, -...</td>\n",
       "      <td>Recap: Known Facts\\n23If A is decidable, then ...</td>\n",
       "      <td>24.443407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143</td>\n",
       "      <td>[0.0638505071401596, -0.6105973124504089, -0.1...</td>\n",
       "      <td>Non- acceptance Problem for TMs\\n22ATM = { &lt;M,...</td>\n",
       "      <td>24.575928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148</td>\n",
       "      <td>[0.08690290153026581, -0.5814269781112671, -0....</td>\n",
       "      <td>Halting Problem for TMs\\n4HALTTM = { &lt;M,w&gt; | M...</td>\n",
       "      <td>25.426054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141</td>\n",
       "      <td>[0.03824932500720024, -0.2070421278476715, -0....</td>\n",
       "      <td>Problem Classification\\n20DECIDABLERECOGNIZABL...</td>\n",
       "      <td>25.609194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page                                         embeddings  \\\n",
       "0   165  [0.039218176156282425, -0.7150614857673645, -0...   \n",
       "1   144  [0.031310174614191055, -0.34490180015563965, -...   \n",
       "2   143  [0.0638505071401596, -0.6105973124504089, -0.1...   \n",
       "3   148  [0.08690290153026581, -0.5814269781112671, -0....   \n",
       "4   141  [0.03824932500720024, -0.2070421278476715, -0....   \n",
       "\n",
       "                                              values     scores  \n",
       "0  Another Problem for TMs\\n21P = { <M> | M is a ...  23.291431  \n",
       "1  Recap: Known Facts\\n23If A is decidable, then ...  24.443407  \n",
       "2  Non- acceptance Problem for TMs\\n22ATM = { <M,...  24.575928  \n",
       "3  Halting Problem for TMs\\n4HALTTM = { <M,w> | M...  25.426054  \n",
       "4  Problem Classification\\n20DECIDABLERECOGNIZABL...  25.609194  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.faiss(embeddings_dataset)\n",
    "samples = f.predict(\"\"\"Classify whether each of the following languages is decidable, recognizable-but-undecidable, or\n",
    "unrecognizable. Prove your answer. For your proofs, you can assume that the problem ATM =\n",
    "{⟨M, w⟩ | M is a TM and accepts w} is undecidable.\n",
    "1. P1 = { ⟨M⟩ | M is a TM and M accepts at least 2 strings }.\n",
    "2. P2 = { ⟨M⟩ | M is a TM and there is no string w such that M accepts w and w is a palindrome }.\"\"\",embeddings_dataset)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cac24cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Another Problem for TMs\\n21P = { <M> | M is a TM and intersection of L(M) and 0* is empty  } \\nGiven a TM, check that it does not accept any string with only 0’sIs this problem:\\n decidable, recognizable -but-undecidable, unrecognizable ??\\nConsider the complement:~P: Given TM M accepts some string with only 0’s\\nClaim: ~P is recognizable but undecidableFollows that P is unrecognizable'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[\"values\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3ddc4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01978c4c59d54e94ad4ee6a4f7b9b9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_dataset = embeddings_dataset.map(lambda x: {**x, 'C': list(range(100, 121))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5ccf11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dce4e47c8c4b039eac7a715626d124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['embeddings', 'values', 'C'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf41caf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B1.pdf',\n",
       " 'B2.pdf',\n",
       " 'B3.pdf',\n",
       " 'B4.pdf',\n",
       " 'B5.pdf',\n",
       " 'B6.pdf',\n",
       " 'B7.pdf',\n",
       " 'B8.pdf']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files = [\"B\"+str(x)+\".pdf\" for x in list(range(1,9))]\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7588c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Create a PDF writer object to write the combined PDF\n",
    "pdf_writer = PyPDF2.PdfWriter()\n",
    "\n",
    "# Loop through the list of PDF files and add each page to the writer\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    for page in pdf_reader.pages:\n",
    "        pdf_writer.add_page(page)\n",
    "\n",
    "# Create and save the combined PDF\n",
    "combined_pdf = 'combined.pdf'  # Replace with the desired output file name\n",
    "with open(combined_pdf, 'wb') as output_pdf:\n",
    "    pdf_writer.write(output_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7549b4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/juliasusser/Desktop\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea8f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
