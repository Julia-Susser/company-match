{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37add1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import faiss\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ddd6ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "    #CLS is a special classification token and the last hidden state of BERT Embedding\n",
    "    def cls_pooling(self, model_output):\n",
    "        return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "    #BERT tokenizer of input text\n",
    "    def get_embeddings(self, text_list):\n",
    "        encoded_input = tokenizer(\n",
    "            text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        model_output = model(**encoded_input)\n",
    "        return self.cls_pooling(model_output).cpu().detach().numpy()\n",
    "    \n",
    "    \n",
    "    #convert dataset into embeddings dataset to run FAISS\n",
    "    def makeEmbeddings(self,dataset):\n",
    "        embeddings = []\n",
    "        for data in dataset:\n",
    "            embeddings.append(self.get_embeddings(data)[0])\n",
    "        return np.array(embeddings)\n",
    "    \n",
    "    def getQueryEmbedding(self, query):\n",
    "        return self.get_embeddings([query])\n",
    "    \n",
    "class Faiss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def faiss(self,xb):\n",
    "        d = xb[0].size\n",
    "        M = 32\n",
    "        index = faiss.IndexHNSWFlat(d, M)            \n",
    "        index.hnsw.efConstruction = 40         # Setting the value for efConstruction.\n",
    "        index.hnsw.efSearch = 16               # Setting the value for efSearch.\n",
    "        index.add(xb)\n",
    "        return index\n",
    "    \n",
    "    def query(self,index,xq,k=3):\n",
    "        D, I = index.search(xq, k)   \n",
    "        return D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c86fe434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [\"julia is super nice\",\"julia loves pie\",\"isabelle is happy\"]\n",
    "embeddings_dataset = Embeddings().makeEmbeddings(values)\n",
    "xb = embeddings_dataset\n",
    "xq = Embeddings().getQueryEmbedding(\"isa is happy\")\n",
    "index = Faiss().faiss(xb)\n",
    "D,I = Faiss().query(index,xq)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9ae801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05169334, -0.26670387, -0.39721736, ..., -0.05143736,\n",
       "         0.14770423, -0.25271532],\n",
       "       [-0.1921795 , -0.22556634, -0.46003044, ..., -0.12975267,\n",
       "         0.05429002, -0.42701638],\n",
       "       [ 0.10342234, -0.39489412, -0.43086833, ...,  0.19120945,\n",
       "         0.15889496, -0.33146405]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7652eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = np.array([[ 0.2858461 ,  2.291011  ,  1.1027378 , -1.3654897 ,  0.50570506],\n",
    "       [-0.43984768,  1.707121  , -0.33323628, -1.3266757 ,  0.0403869 ],\n",
    "       [ 1.2801098 , -0.38431922, -0.89034826,  0.26452443,  0.01639184],\n",
    "       [ 0.787185  ,  0.47547337, -0.2487884 ,  0.93552494,  0.02594745]])\n",
    "index = Faiss().faiss(xb)\n",
    "xq = np.array([[ 1.5905408 ,  0.75759834,  1.3138535 , -0.5175146 ,  0.2957387 ]])\n",
    "D,I = Faiss().query(index,xq)\n",
    "I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfbdb983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03503197, -0.02060164, -0.01537573, ..., -0.01162699,\n",
       "        -0.00087646,  0.00465802]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "key = \"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\"\n",
    "# Initialize OpenAI client (replace '...' with your API key)\n",
    "client = OpenAI(api_key=key)\n",
    "\n",
    "\n",
    "class OpenAIEmbeddings:\n",
    "    def __init__(self,api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        \n",
    "    \n",
    "    def get_embeddings(self, text_list):\n",
    "        data = self.client.embeddings.create(input=text_list, model='text-embedding-ada-002').data\n",
    "        embeddings = [embedding.embedding for embedding in data]\n",
    "        return embeddings\n",
    "    \n",
    "    \n",
    "    #convert dataset into embeddings dataset to run FAISS\n",
    "    def makeEmbeddings(self,dataset):\n",
    "        embeddings = self.get_embeddings(dataset)\n",
    "        return np.array(embeddings)\n",
    "    \n",
    "    def getQueryEmbedding(self, query):\n",
    "        return self.get_embeddings([query])\n",
    "    \n",
    "e = OpenAIEmbeddings(key)\n",
    "e.makeEmbeddings([\"hi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f791ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [\"julia is super nice\",\"julia loves pie\",\"isabelle is happy\", \"hey baby\"]\n",
    "embeddings_dataset = OpenAIEmbeddings(key).makeEmbeddings(values)\n",
    "xb = embeddings_dataset\n",
    "xq = OpenAIEmbeddings(key).getQueryEmbedding(\"hey babe\")\n",
    "index = Faiss().faiss(xb)\n",
    "D,I = Faiss().query(index,np.array(xq))\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42016980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42e9f211",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m D,I \u001b[38;5;241m=\u001b[39m \u001b[43mFaiss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxq\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36mFaiss.query\u001b[0;34m(self, index, xq, k)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m,index,xq,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 40\u001b[0m     D, I \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m D, I\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/faiss/class_wrappers.py:329\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[0;34m(self, x, k, params, D, I)\u001b[0m\n\u001b[1;32m    327\u001b[0m n, d \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    328\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m k \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m D \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D,I = Faiss().query(index,xq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c24e8fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab56e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
