{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7347becd",
   "metadata": {},
   "source": [
    "TO Do\n",
    "fix word to vec embeddings\n",
    "try on different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0eaf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "secDataPath = \"../../inputs/SEC-CompanyTicker.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e758e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "\n",
    "\n",
    "def sdp_attention(query, key, value):\n",
    "    dim_k = query.size(-1) # dimension component\n",
    "    sfact = sqrt(dim_k)     \n",
    "    scores = torch.bmm(query, key.transpose(1,2)) / sfact\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)\n",
    "\n",
    "'''\n",
    "\n",
    "Attention Class\n",
    "\n",
    "# nn.linear : apply linear transformation to incoming data\n",
    "#             y = x * A^T + b\n",
    "# Ax = b where x is input, b is output, A is weight\n",
    "\n",
    "# calculate scaled dot product attention matrix\n",
    "# Requires embedding dimension \n",
    "# Each attention head is made of different q,k,v vectors\n",
    "\n",
    "'''\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    # initalisation \n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the three vectors\n",
    "        # input - embed_dim, output - head_dim\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    # main class operation\n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # calculate scaled dot product given a \n",
    "        attn_outputs = sdp_attention(\n",
    "            self.q(hidden_state), \n",
    "            self.k(hidden_state), \n",
    "            self.v(hidden_state))\n",
    "        \n",
    "        return attn_outputs\n",
    "    \n",
    "\n",
    "    \n",
    "'''\n",
    "\n",
    "Multihead attention class\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class multiHeadAttention(nn.Module):\n",
    "    \n",
    "    # Config during initalisation\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # model params, read from config file\n",
    "        embed_dim = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # attention head (define only w/o hidden state)\n",
    "        # each attention head is initialised with embedd/heads head dimension\n",
    "        self.heads = nn.ModuleList(\n",
    "            [Attention(embed_dim, head_dim) for _ in range(num_heads)])\n",
    "        \n",
    "        # output uses whole embedding dimension for output\n",
    "        self.out_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    # Given a hidden state (embeddings)\n",
    "    # Apply operation for multihead attention\n",
    "        \n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # for each head embed_size/heads, calculate attention\n",
    "        heads = [head(hidden_state) for head in self.heads] \n",
    "        x = torch.cat(heads, dim=-1) # merge/concat head data together\n",
    "    \n",
    "        # apply linear transformation to multihead attension scalar product\n",
    "        x = self.out_linear(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class feedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.linear2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    # define layer operations input x\n",
    "        \n",
    "    def forward(self, x):    # note must be forward\n",
    "        x = self.gelu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class encoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = multiHeadAttention(config)    # multihead attention layer \n",
    "        self.feed_forward = feedForward(config)        # feed forward layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Apply layer norm. to hidden state, copy input into query, key, value\n",
    "        # Apply attention with a skip connection\n",
    "        x = x + self.attention(self.norm1(x))\n",
    "        \n",
    "        # Apply feed-forward layer with a skip connection\n",
    "        x = x + self.feed_forward(self.norm2(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "'''\n",
    "\n",
    "Token + Position Embedding \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class tpEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):        \n",
    "        super().__init__()\n",
    "        \n",
    "        # token embedding layer\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size,\n",
    "                                             config.hidden_size)\n",
    "        \n",
    "        # positional embedding layer\n",
    "        # config.max_position_embeddings -> max number of positions in text 512 (tokens)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
    "                                                config.hidden_size)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \n",
    "        # Create position IDs for input sequence\n",
    "        seq_length = input_ids.size(1) # number of tokens\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long)[None,:] # range(0,9)\n",
    "        \n",
    "        # tensor([[ 1996, 11286,  1997,  1037,  5340,  3392,  2003,  2200,  5931]])\n",
    "        # tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8]])\n",
    "        \n",
    "        # Create token and position embeddings\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # Combine token and position embeddings\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        \n",
    "        # Add normalisation & dropout layers\n",
    "        embeddings = self.norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "    \n",
    "    \n",
    "    \n",
    "# full transformer encoder combining the `Embedding` with the ``Embedding` ` layers\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):       \n",
    "        super().__init__()\n",
    "        \n",
    "        # token & positional embedding layer\n",
    "        self.embeddings = tpEmbedding(config)\n",
    "        \n",
    "        # attention & forward feed layer \n",
    "        self.layers = nn.ModuleList([encoderLayer(config)\n",
    "                                     for _ in range(config.num_hidden_layers)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # embeddings layer output\n",
    "        x = self.embeddings(x)\n",
    "        \n",
    "        # cycle through all heads\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        x = x[:, 0, :] # select hidden state of [CLS] token\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0452422d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'secDatPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 35\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43msecDatPath\u001b[49m,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcompanyName[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m     36\u001b[0m train \u001b[38;5;241m=\u001b[39m TrainEmbeddings()\n\u001b[1;32m     37\u001b[0m train\u001b[38;5;241m.\u001b[39mtrain(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'secDatPath' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer  \n",
    "import torch\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TrainEmbeddings():\n",
    "    def __init__(self):\n",
    "        self.model = TransformerEncoder(config)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "        \n",
    "    def getTensor(self,text):\n",
    "        inputs = self.tokenizer(text, \n",
    "                   return_tensors=\"pt\",      # pytorc tensor\n",
    "                   add_special_tokens=False,\n",
    "                          padding=True) # don't use pad, sep tokens\n",
    "        return inputs.input_ids\n",
    "    \n",
    "    def train(self,data,epochs=100):\n",
    "        self.model.train()\n",
    "        tensorData = self.getTensor(data)\n",
    "        for epoch in range(epochs):\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"epoch %s\" % epoch)\n",
    "            self.model.forward(tensorData)\n",
    "    \n",
    "    def getEmbeddings(self,q):\n",
    "        self.model.eval()\n",
    "        inputs = self.getTensor(q)\n",
    "        with torch.no_grad():\n",
    "            x = self.model(inputs).cpu().detach().numpy()\n",
    "            return x\n",
    "        \n",
    "\n",
    "data = list(pd.read_csv(secDatPath,index_col=0).companyName[:100])\n",
    "train = TrainEmbeddings()\n",
    "train.train(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c27f87bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 10\n",
      "epoch 20\n",
      "epoch 30\n",
      "epoch 40\n",
      "epoch 50\n",
      "epoch 60\n",
      "epoch 70\n",
      "epoch 80\n",
      "epoch 90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-6.98212534e-05,  3.07853334e-05,  6.64498657e-04,\n",
       "         1.17308239e-03, -1.21132156e-03, -9.26667824e-04,\n",
       "         8.40999011e-04,  1.16835779e-03, -6.53050549e-04,\n",
       "        -4.90022358e-04,  9.61003185e-04, -1.99670743e-04,\n",
       "        -5.90704847e-04,  8.53392121e-04, -6.32833398e-04,\n",
       "        -2.36460633e-04,  3.74554656e-04,  1.29150227e-04,\n",
       "        -1.07880402e-03, -1.23031484e-03,  9.52052884e-04,\n",
       "         6.60190359e-04,  8.79907981e-04,  9.93314534e-05,\n",
       "         8.26938835e-04, -4.43407014e-04, -1.23229343e-04,\n",
       "         7.51116313e-04, -9.79379867e-04, -5.12513507e-04,\n",
       "        -9.78070660e-04, -1.21099256e-04,  1.24194252e-03,\n",
       "        -9.53016512e-04, -3.03876121e-04, -2.52310041e-04,\n",
       "         1.05174957e-03, -7.72252039e-04,  5.88052580e-06,\n",
       "        -6.18975784e-04, -1.25046226e-03,  6.51991286e-04,\n",
       "        -1.14057108e-03, -5.71852259e-04, -4.57031047e-06,\n",
       "        -3.85652929e-05, -9.97557305e-04,  1.25191966e-03,\n",
       "         6.48705463e-04,  1.20223220e-03, -1.06222881e-03,\n",
       "         5.85390429e-04, -5.38681808e-04,  1.07361469e-04,\n",
       "         1.10659108e-03, -5.81012573e-04,  5.88216179e-04,\n",
       "        -8.83718778e-04, -4.62042779e-04,  1.22376403e-03,\n",
       "        -2.05423523e-04,  4.18452546e-05, -5.39144501e-04,\n",
       "        -1.00034999e-03, -1.96355235e-04,  3.21587868e-04,\n",
       "        -1.15628507e-04,  7.20528886e-04, -3.57158482e-04,\n",
       "         2.94279307e-04,  7.10389868e-04,  1.08671270e-03,\n",
       "        -1.89289145e-04, -1.19897688e-03,  5.69082331e-04,\n",
       "         7.44511708e-05,  9.68998473e-04, -1.05896186e-04,\n",
       "        -3.43543477e-04, -1.13971473e-03, -1.11530848e-04,\n",
       "         3.68042063e-04,  7.03311060e-04,  9.18314618e-04,\n",
       "        -7.42593955e-04,  2.42033813e-04,  7.92820763e-04,\n",
       "        -6.24746259e-04, -4.04591206e-04,  8.85108020e-04,\n",
       "         2.12431725e-04,  2.47287880e-05,  4.52296488e-04,\n",
       "         2.83564441e-05,  1.25245133e-03,  6.58932782e-04,\n",
       "        -1.16111850e-03, -9.16869845e-04,  1.17377065e-04,\n",
       "         8.32361169e-04, -1.12235511e-03,  4.77309659e-04,\n",
       "         6.75766089e-04,  7.47648242e-04,  9.72254958e-04,\n",
       "        -8.03082716e-04,  1.43960118e-04,  7.87406520e-04,\n",
       "        -3.69798247e-04, -8.03844072e-04, -5.34144529e-05,\n",
       "        -1.08970690e-03, -7.29168300e-04,  9.25070141e-04,\n",
       "         4.36528586e-04,  9.40842379e-04,  8.85448884e-04,\n",
       "         9.80565324e-04, -4.93379484e-04, -7.31518157e-05,\n",
       "         3.05778201e-04, -5.88415656e-04,  1.09228271e-03,\n",
       "        -1.28361501e-03,  8.80812586e-04,  3.79481353e-04,\n",
       "        -6.42295752e-04,  5.72680670e-04, -2.26507123e-04,\n",
       "         8.73878133e-04,  1.29750650e-03, -5.68026502e-04,\n",
       "        -7.80387782e-05, -7.41619442e-04,  5.01409173e-04,\n",
       "         3.62842024e-04,  8.97275575e-04,  7.94413500e-04,\n",
       "         1.24199176e-03,  1.20747613e-03,  1.02839433e-03,\n",
       "        -9.10091680e-04, -1.19216985e-03, -4.63219658e-05,\n",
       "        -4.03625105e-04,  1.02790585e-03,  7.73251813e-04,\n",
       "        -2.01258183e-04,  1.96740031e-04,  2.33078215e-04,\n",
       "         1.01791287e-03, -1.23830559e-03, -2.67618652e-05,\n",
       "         4.51718312e-04, -1.22262005e-04,  1.09137653e-03,\n",
       "         1.17327913e-03,  8.51107587e-04, -9.26589928e-05,\n",
       "         1.00395887e-03, -1.11124152e-03,  4.17592004e-04,\n",
       "        -6.03905879e-04, -6.62624370e-04,  4.67398204e-04,\n",
       "         6.99262891e-04,  1.01165555e-03, -7.50847161e-04,\n",
       "         9.67885542e-04,  8.62694811e-04, -4.83046897e-04,\n",
       "        -1.13875547e-03,  7.08003528e-04,  8.47624440e-04,\n",
       "        -1.02545600e-04, -8.73679121e-04, -9.22646548e-04,\n",
       "        -3.25138069e-04,  6.69694506e-04, -4.77244466e-04,\n",
       "        -1.22005993e-03,  4.98273410e-04,  6.35999895e-04,\n",
       "        -8.37052532e-04,  1.57364339e-04, -2.70166289e-04,\n",
       "         3.17751733e-06, -1.28691515e-03,  3.50521412e-04,\n",
       "        -6.18503429e-04,  1.41620636e-04, -2.05237578e-04,\n",
       "         2.86025141e-04, -1.02624681e-03, -3.53799987e-04,\n",
       "         3.46770656e-04,  6.96182542e-04, -3.11395153e-04,\n",
       "        -1.23829348e-03,  5.86702954e-04,  1.23130158e-05,\n",
       "         4.00692690e-04, -8.87063157e-04, -1.79097056e-04,\n",
       "         9.98513191e-04,  9.56563745e-04, -4.78293892e-04,\n",
       "         3.44101805e-04, -1.08295958e-03,  8.08005978e-04,\n",
       "        -6.03818044e-04, -4.11993038e-04,  1.21241622e-03,\n",
       "         1.13722090e-04,  9.75351955e-04, -7.90893566e-04,\n",
       "         6.71941030e-04,  1.29203417e-03, -1.10122282e-03,\n",
       "        -6.68709807e-04, -9.19900660e-04, -6.33157790e-04,\n",
       "        -4.92000487e-04, -1.11148425e-03,  1.03588623e-03,\n",
       "        -6.30721159e-04,  1.09682465e-03,  6.85230538e-04,\n",
       "        -8.52867961e-04,  5.15347812e-04,  7.12259032e-04,\n",
       "        -9.66996886e-04, -9.64286446e-04, -3.22295673e-04,\n",
       "        -1.12314138e-03, -2.05933888e-04, -5.25303185e-05,\n",
       "         4.29646432e-04,  1.87744852e-04, -1.14768431e-04,\n",
       "        -7.28392974e-04,  2.25308046e-04, -1.16845280e-04,\n",
       "         8.84595152e-04,  5.17394568e-04,  5.89774922e-04,\n",
       "         1.86758582e-04, -3.51543684e-04, -5.68595424e-04,\n",
       "        -1.34384725e-04,  1.87112950e-04, -3.44532396e-04,\n",
       "        -9.21065453e-04, -1.01631600e-03, -1.18773256e-03,\n",
       "        -7.72808504e-04, -2.40550071e-04, -5.63004054e-04,\n",
       "        -8.41233123e-04, -4.84026357e-04,  5.58484171e-04,\n",
       "        -4.86854609e-04,  1.09090831e-03,  1.99738730e-04,\n",
       "        -9.43010382e-04,  1.22835918e-03,  9.93647496e-04,\n",
       "         7.15271104e-04, -8.91776755e-04,  7.58161303e-04,\n",
       "         5.22017304e-04,  6.75178308e-04,  5.54153870e-04,\n",
       "         2.52572208e-04, -4.12781577e-04,  1.08774018e-03,\n",
       "         1.25158590e-03,  4.93828498e-04, -3.69400397e-04,\n",
       "         9.28062946e-07,  1.58700321e-04, -1.10134436e-03,\n",
       "        -1.07082620e-03, -3.00801676e-05,  1.61105141e-04,\n",
       "        -7.47836020e-04, -6.15270052e-04, -9.56520147e-04,\n",
       "         1.08445517e-03,  1.57939885e-05, -5.87161339e-04,\n",
       "         7.42409553e-04,  1.19531446e-03, -5.33837534e-04,\n",
       "         1.03706785e-03,  6.99926342e-04,  7.65510835e-04,\n",
       "         6.67435452e-05,  1.06941198e-03, -9.13937576e-04,\n",
       "        -1.07326533e-03,  1.21085346e-03, -2.57370993e-05,\n",
       "        -2.56155763e-04,  5.99431049e-04, -5.33244282e-04,\n",
       "         3.57176323e-04,  9.03641514e-04,  7.89768994e-04,\n",
       "        -9.77967982e-04,  1.22166018e-03,  6.08308415e-04,\n",
       "         5.16421918e-04, -8.12956423e-04,  1.10155984e-03,\n",
       "        -2.79969390e-04,  1.14911294e-03, -6.98177435e-04,\n",
       "        -1.05851807e-03,  8.88614450e-04,  2.17603214e-04,\n",
       "        -2.86264200e-04,  1.23875018e-03,  1.23617903e-03,\n",
       "        -1.27266243e-03,  3.26201640e-04,  8.01652670e-04,\n",
       "         5.04226133e-04,  2.63383758e-04,  5.60549088e-05,\n",
       "         8.77124257e-05, -4.97478701e-04, -9.29720060e-04,\n",
       "        -2.71988567e-04,  5.10924205e-04,  1.14826614e-03,\n",
       "         1.20561849e-03, -7.78116751e-04, -1.22430606e-03,\n",
       "         1.27140328e-03,  4.46586550e-04,  6.72671478e-04,\n",
       "         8.18013679e-04, -3.65138374e-04,  9.53477051e-04,\n",
       "         3.68524954e-04,  3.73828690e-04, -3.09944007e-04,\n",
       "        -4.07324173e-04, -3.08612216e-04,  5.56827697e-04,\n",
       "         9.90337412e-06, -1.24795304e-03, -1.25853438e-03,\n",
       "        -8.00546084e-04, -1.67408343e-05,  2.60080211e-04,\n",
       "         1.22812076e-03,  7.27128994e-04, -5.58684405e-04,\n",
       "         3.62391584e-05,  6.46400906e-04,  1.00238400e-03,\n",
       "        -1.48987398e-04,  5.62945381e-04, -7.57080677e-04,\n",
       "        -1.04712322e-04,  1.05469406e-03, -3.07300128e-04,\n",
       "        -1.25826243e-03,  7.52507884e-04, -5.11695631e-04,\n",
       "        -1.59228221e-04,  1.29954657e-03, -2.93795631e-04,\n",
       "        -6.19409431e-04, -6.93930604e-04,  9.08970076e-04,\n",
       "        -7.43342738e-04,  2.75216531e-04, -6.84330706e-04,\n",
       "         7.96967943e-04,  5.67357696e-04,  3.39369144e-04,\n",
       "        -1.94151420e-04, -3.57560348e-04,  1.17095525e-03,\n",
       "         6.79137360e-04, -2.81578075e-04, -1.23311335e-03,\n",
       "        -9.66933847e-04, -1.38507996e-04, -1.03508741e-04,\n",
       "        -3.33712116e-04,  1.26077095e-03, -5.97032085e-05,\n",
       "         7.64812634e-04, -9.69737943e-04, -3.26311681e-04,\n",
       "        -7.22638506e-04, -9.29559290e-04,  1.61592543e-04,\n",
       "        -9.34468291e-04, -2.92267971e-04,  4.84284334e-04,\n",
       "         7.59521325e-04,  1.56013455e-04,  2.73793150e-04,\n",
       "        -5.35207160e-04,  9.40798607e-04, -8.21229361e-04,\n",
       "         6.05106179e-04, -1.07030896e-03,  2.65165087e-04,\n",
       "        -6.48053654e-04, -5.53084363e-04, -4.04815655e-04,\n",
       "         7.36355316e-04,  7.55000103e-04, -6.47740730e-04,\n",
       "         1.00694131e-04, -1.10622111e-03,  1.01690181e-03,\n",
       "         1.20537647e-03, -3.57073877e-04,  1.04195751e-04,\n",
       "         9.72202979e-05,  7.13266258e-04, -1.12058315e-03,\n",
       "         7.61010087e-05,  8.94455996e-04,  2.90572178e-04,\n",
       "         1.46442253e-04, -1.21382240e-03,  1.10447488e-03,\n",
       "        -8.15641601e-04, -3.89631983e-04,  4.54920199e-04,\n",
       "        -1.00602549e-04,  1.83761891e-04,  2.32030172e-04,\n",
       "        -8.89179588e-04, -1.26625143e-03,  1.17715949e-03,\n",
       "         8.07038334e-04, -9.00120765e-04,  4.43161785e-04,\n",
       "         2.68312488e-05,  6.18977298e-04, -9.27075918e-04,\n",
       "         5.24342991e-04,  5.66072122e-04,  1.29653246e-03,\n",
       "        -5.82518231e-04, -1.80893738e-04, -9.52776230e-04,\n",
       "        -1.26273825e-03, -1.18232518e-03, -1.33171212e-04,\n",
       "        -8.46782525e-04,  6.31475064e-04, -8.02607567e-04,\n",
       "         3.28018941e-04,  9.62813720e-05, -4.41686716e-04,\n",
       "        -1.27503023e-04,  1.29936531e-03,  1.19087065e-03,\n",
       "        -5.80967404e-04,  1.18268572e-03, -7.34604604e-04,\n",
       "         7.72255473e-04, -4.03283630e-04,  4.46842663e-04,\n",
       "         3.92868038e-04,  8.98497470e-04, -3.09099443e-04,\n",
       "         1.14258286e-03,  9.88206826e-04, -1.24318304e-03,\n",
       "        -1.04273565e-03, -9.94517817e-04,  3.80632468e-04,\n",
       "        -3.63896135e-04, -9.02281317e-04, -1.05836766e-03,\n",
       "         1.08192442e-03,  2.59178225e-04, -1.21458562e-03,\n",
       "        -6.24051609e-04,  4.08429507e-04, -6.13698736e-04,\n",
       "         6.87609718e-04, -5.51229343e-04,  3.43983847e-04,\n",
       "        -1.04761554e-03,  8.08578916e-04,  6.27459493e-04,\n",
       "         1.02499034e-04,  3.92375980e-04, -1.13639096e-03,\n",
       "         2.77364772e-04, -1.13742739e-04, -1.21342298e-03,\n",
       "        -1.22762274e-03, -1.83687240e-04,  5.77136583e-04,\n",
       "         4.82300908e-04, -8.46184033e-04, -8.94930679e-04,\n",
       "        -6.50965143e-04, -2.97766179e-04, -9.44047875e-04,\n",
       "        -1.25043199e-03, -3.57243378e-04, -1.08891155e-03,\n",
       "        -7.86311924e-04, -7.38402188e-04, -3.05226218e-04,\n",
       "        -2.22265255e-04, -1.16627582e-03, -9.57290977e-05,\n",
       "         1.06152426e-03,  1.00135803e-03, -9.38296318e-04,\n",
       "        -4.77451977e-04,  4.06061445e-04, -1.24618784e-03,\n",
       "         1.92244697e-04,  8.49539880e-04,  7.48231716e-04,\n",
       "        -1.14102371e-03, -5.88169787e-04, -1.05991680e-03,\n",
       "         5.98390261e-06,  1.20620232e-03,  7.77774199e-04,\n",
       "         6.59805723e-04,  6.58992503e-04, -4.22254816e-04,\n",
       "         1.24377385e-03, -9.57867771e-04, -9.46665008e-04,\n",
       "        -2.94972531e-04, -1.01375081e-04, -4.18763462e-04,\n",
       "        -7.71596096e-05,  9.75107134e-04, -9.08227303e-05,\n",
       "        -2.11580817e-04,  3.57343670e-04, -1.08842459e-03,\n",
       "         1.02289114e-03,  1.11147191e-03, -1.24792801e-03,\n",
       "         3.18524282e-04,  1.28970982e-03, -9.98151489e-04,\n",
       "        -9.07150854e-04, -1.00735901e-03,  1.09321915e-03,\n",
       "        -8.87156129e-05,  1.19067822e-03, -1.06226839e-03,\n",
       "         4.87380807e-04,  3.43104504e-04,  9.67074520e-05,\n",
       "         3.03082779e-04, -9.72538255e-04, -1.21853827e-03,\n",
       "         3.06585483e-04,  8.00580077e-04,  1.03980314e-03,\n",
       "         7.46861275e-04, -1.01215672e-04,  1.08153187e-03,\n",
       "        -1.21566595e-03,  4.43506840e-04,  3.47335190e-05,\n",
       "         5.02245326e-04,  9.61690501e-04, -8.75672791e-04,\n",
       "         7.27145933e-04, -1.23987300e-03, -1.04747247e-04,\n",
       "        -1.13134598e-03, -6.63889747e-04,  1.20953470e-03,\n",
       "        -2.41961170e-04,  3.79482604e-04,  1.18115626e-03,\n",
       "         1.16381934e-03, -1.06880662e-03, -3.92228365e-04,\n",
       "         1.28731842e-03,  6.64639461e-04, -2.06782177e-04,\n",
       "        -1.13177358e-03,  3.85614112e-04, -8.69257550e-04,\n",
       "         1.05888955e-03, -5.80382068e-04, -1.39109019e-04,\n",
       "         1.31037086e-04, -2.48846281e-05,  1.49502259e-04,\n",
       "         7.96075619e-04, -2.63952347e-06, -4.22651734e-04,\n",
       "        -1.96709458e-04,  7.67877500e-04,  1.97148722e-04,\n",
       "        -9.43049454e-05,  1.21526653e-03, -6.40792132e-04,\n",
       "        -1.09167922e-04,  1.19471503e-03,  8.78831663e-04,\n",
       "         1.95684377e-04, -1.15658343e-03,  1.49576299e-04,\n",
       "        -2.97949970e-04,  1.21982256e-03,  1.57542687e-04,\n",
       "         1.94018707e-04,  3.13334633e-04, -2.39063360e-04,\n",
       "        -6.50994014e-04,  3.02642584e-05, -2.62263085e-04,\n",
       "         8.59496475e-04,  1.16407860e-03, -8.78586434e-05,\n",
       "         3.87632143e-04, -7.95267522e-04,  2.21266251e-04,\n",
       "        -9.01853200e-04, -1.13203470e-03, -7.68255617e-04,\n",
       "        -1.16620772e-03,  9.47603490e-04, -7.51566608e-04,\n",
       "         1.07765000e-03, -9.43169929e-04,  4.45530604e-04,\n",
       "         1.25976547e-03, -1.01373019e-03, -1.29492942e-03,\n",
       "        -5.63690905e-04, -3.49365961e-04, -3.53241339e-05,\n",
       "        -1.14994159e-03, -1.12207781e-03,  3.64610780e-04,\n",
       "        -1.06854260e-03, -1.18090317e-03, -3.04748159e-04,\n",
       "        -1.12393324e-03, -9.18834645e-04, -1.09389983e-03,\n",
       "        -3.92355323e-05, -5.94309706e-04,  8.62913381e-04,\n",
       "         1.98849011e-04, -4.35087975e-04,  7.95439060e-04,\n",
       "        -7.82979827e-04, -6.06272079e-04, -9.38477751e-04,\n",
       "        -5.64658840e-04, -2.35589847e-04,  8.45005561e-04,\n",
       "        -3.60728242e-04,  6.40490558e-04,  8.99015926e-04,\n",
       "        -9.71836678e-04,  5.94381534e-04,  7.97783665e-04,\n",
       "        -3.84697225e-04,  8.62633053e-04,  7.97640532e-04,\n",
       "        -8.38995446e-04, -8.80800944e-04,  3.30593582e-04,\n",
       "        -2.11434744e-04, -7.89730169e-04,  1.23687612e-03,\n",
       "        -6.67987857e-04, -8.53398058e-04, -1.56100523e-05,\n",
       "        -3.51748429e-04,  5.78646250e-05, -4.60606534e-04,\n",
       "        -5.46003394e-05, -9.22676772e-05,  1.07138105e-04,\n",
       "         1.06703350e-03, -7.46967096e-04, -2.16084372e-04,\n",
       "         7.25469727e-04,  1.06355734e-03, -5.78519888e-04,\n",
       "         1.16997829e-03,  1.07469596e-03, -5.77502884e-04,\n",
       "         3.94668132e-05,  5.56574378e-04, -5.11239574e-04,\n",
       "        -7.23953824e-04, -8.47958669e-04, -8.73357058e-05,\n",
       "        -3.85314524e-05,  5.81130851e-04, -3.22142470e-04,\n",
       "        -2.24751420e-05,  3.20556719e-04,  6.33801974e-04,\n",
       "        -4.01151692e-06, -8.25443945e-04, -1.20583421e-03,\n",
       "         3.47103924e-06,  8.67434137e-04,  1.90888371e-04,\n",
       "        -1.16751587e-03, -1.03367248e-03,  8.53112258e-04,\n",
       "        -4.92927153e-04,  8.14452127e-04, -8.69926065e-04,\n",
       "         1.10412261e-03, -8.48479744e-04,  4.28127591e-04,\n",
       "        -1.37628362e-04, -8.83792702e-04, -4.28072497e-04,\n",
       "        -1.51225526e-04, -7.12361943e-04, -1.57727554e-04,\n",
       "        -9.84806451e-04,  3.44617147e-04,  1.18100888e-03,\n",
       "        -3.09537776e-04, -1.27149746e-04,  4.57494985e-04,\n",
       "         1.12826657e-03, -7.71074556e-04, -8.96820042e-04,\n",
       "        -3.81899066e-04,  1.19110628e-03,  1.12795271e-04,\n",
       "        -1.13000011e-03, -1.88408725e-04,  1.23430544e-03,\n",
       "        -9.83006204e-04, -6.97669107e-04,  1.21309410e-03,\n",
       "        -1.16845395e-03,  4.98165085e-04,  8.66459086e-05,\n",
       "         8.67278781e-04,  1.08238973e-03, -3.71195987e-04,\n",
       "        -5.19832422e-04,  1.15858298e-03,  2.72089295e-04,\n",
       "         8.13664228e-04, -1.22991076e-03,  1.24871405e-03]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Word2VecEmbeddings():\n",
    "    #required to train on all data and queries, because use keys to find embeddings\n",
    "    def train(self, data,epochs=100):\n",
    "        data = [[x] for x in data]\n",
    "        self.model = Word2Vec(data, \n",
    "                 min_count = 1, vector_size = 768,\n",
    "                                             window = 5, sg = 1)\n",
    "        for epoch in range(epochs):\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"epoch %s\" % epoch)\n",
    "            self.model.train([[\"shell\"]], total_examples=self.model.corpus_count, epochs=100)\n",
    "            \n",
    "            \n",
    "    def getEmbeddings(self,q):\n",
    "        values = []\n",
    "        for val in q:\n",
    "            values.append(self.model.wv.get_vector(val))\n",
    "        return np.array(values)\n",
    "    \n",
    "    def getKeys(self):\n",
    "        words = list(self.model.wv.index_to_key)\n",
    "        return words\n",
    "\n",
    "data = list(pd.read_csv(secDataPath,index_col=0).companyName[:100])\n",
    "train = Word2VecEmbeddings()\n",
    "FullKeys = data + [\"shell\"]\n",
    "train.train(FullKeys)\n",
    "xq = train.getEmbeddings([\"shell\"])\n",
    "xb = train.getEmbeddings(data)\n",
    "xq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "db3e1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "key = os.environ.get(\"OPENAI_KEY\")\n",
    "\n",
    "# Initialize OpenAI client (replace '...' with your API key)\n",
    "client = OpenAI(api_key=key)\n",
    "\n",
    "\n",
    "class OpenAIEmbeddings:\n",
    "    def __init__(self,api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        \n",
    "    \n",
    "    def getEmbeddings(self, text_list):\n",
    "        data = self.client.embeddings.create(input=text_list, model='text-embedding-ada-002').data\n",
    "        embeddings = [embedding.embedding for embedding in data]\n",
    "        return np.array(embeddings)\n",
    "    \n",
    "    \n",
    "train = OpenAIEmbeddings(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d26f1c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.67052944e-02, -2.26962656e-01, -3.52288604e-01,\n",
       "         1.39271274e-01,  3.63313109e-02, -2.48244584e-01,\n",
       "        -7.24242255e-03,  2.84364730e-01, -2.24267125e-01,\n",
       "         2.74040073e-01,  6.68052286e-02, -2.88262486e-01,\n",
       "        -2.35641703e-01,  3.63490671e-01, -6.73132315e-02,\n",
       "        -1.02233335e-01,  1.31339893e-01,  2.46826887e-01,\n",
       "         2.06331387e-01, -1.72131449e-01, -1.58596531e-01,\n",
       "         2.81898826e-01, -7.99801722e-02,  2.85342634e-01,\n",
       "        -2.63511576e-02, -2.79757380e-01,  2.15131685e-01,\n",
       "         4.59036194e-02, -9.49969664e-02,  9.71716344e-02,\n",
       "        -4.19612303e-02, -1.43848658e-02, -8.02190006e-02,\n",
       "        -7.30765983e-02, -1.07166685e-04, -1.66405842e-01,\n",
       "         1.28892303e-01,  5.45171127e-02, -1.84124723e-01,\n",
       "        -1.19634345e-01, -7.17815757e-02, -2.55356371e-01,\n",
       "        -3.24021101e-01, -3.18603784e-01, -2.07002670e-01,\n",
       "        -2.33787283e-01,  1.15620144e-01, -2.81645685e-01,\n",
       "        -2.65673101e-02, -1.69645041e-01,  2.72051960e-01,\n",
       "         4.92678061e-02, -1.36198476e-02, -4.67848741e-02,\n",
       "         1.98244274e-01, -6.20089471e-03, -7.20805824e-02,\n",
       "        -2.05151394e-01,  1.21839486e-01, -8.10572729e-02,\n",
       "         6.99825346e-01,  2.77802080e-01,  4.06696722e-02,\n",
       "        -4.35135067e-01, -1.35701537e-01, -1.50714302e-02,\n",
       "         5.42821825e-01, -1.91447049e-01,  8.71475786e-02,\n",
       "         1.56485051e-01,  3.27457666e-01,  7.49490708e-02,\n",
       "         8.01794082e-02,  2.73294628e-01, -1.06390826e-01,\n",
       "         2.93283254e-01, -2.31957227e-01,  8.95097181e-02,\n",
       "        -1.34768011e-02,  2.70025227e-02,  1.67484239e-01,\n",
       "        -1.49717897e-01, -1.03473119e-01,  1.78339630e-01,\n",
       "         1.34364769e-01,  1.76614076e-01,  3.96789350e-02,\n",
       "         1.14231519e-02, -8.74148011e-02, -2.22473070e-01,\n",
       "        -7.51830280e-01, -4.14764285e-02, -2.40708321e-01,\n",
       "        -1.59915894e-01,  2.31549844e-01, -1.02040485e-01,\n",
       "        -1.00931294e-01,  1.09458119e-01, -2.04621404e-01,\n",
       "        -3.73768866e-01,  3.34479481e-01,  1.00472473e-01,\n",
       "         1.11694135e-01,  2.13551596e-02,  1.65466771e-01,\n",
       "        -2.21411064e-02,  1.16983816e-01, -9.83885229e-02,\n",
       "         7.35410973e-02, -1.14277534e-01, -2.95458704e-01,\n",
       "        -1.11259021e-01,  2.58083522e-01, -1.40133798e-01,\n",
       "         4.49746214e-02,  9.54620391e-02,  1.89113095e-01,\n",
       "         6.74087927e-03, -5.97697832e-02,  5.75506277e-02,\n",
       "        -6.37316585e-01,  3.75245884e-02,  2.36922234e-01,\n",
       "         2.18960375e-01, -4.66642469e-01,  1.60327524e-01,\n",
       "        -2.08496243e-01,  7.91451186e-02,  3.79963517e-02,\n",
       "        -1.62997782e-01, -3.84413600e-01,  1.37426630e-01,\n",
       "        -2.55297095e-01, -1.69554174e-01, -1.88664705e-01,\n",
       "        -5.25342114e-02,  2.27767043e-02, -1.42230168e-01,\n",
       "         1.48461163e-01, -1.86383009e-01,  1.75510928e-01,\n",
       "        -2.00269610e-01,  1.99716777e-01, -1.73727006e-01,\n",
       "        -1.37014017e-01,  8.72480124e-03,  1.86500493e-02,\n",
       "        -3.14480841e-01, -8.68059099e-02,  1.10198207e-01,\n",
       "         2.90966541e-01, -4.84865993e-01,  1.89643294e-01,\n",
       "         2.21101865e-01,  3.07532012e-01, -1.85968235e-01,\n",
       "         7.67785907e-02,  3.33477199e-01, -1.41580522e-01,\n",
       "        -8.95908549e-02, -8.37761238e-02,  7.34572411e-02,\n",
       "         1.47042245e-01, -3.03110093e-01,  3.94960940e-02,\n",
       "        -1.00639328e-01,  1.93896703e-02, -3.68619114e-02,\n",
       "        -2.66592465e-02, -1.66032575e-02,  4.40118611e-01,\n",
       "         2.41677955e-01,  1.01877883e-01,  7.91396052e-02,\n",
       "        -5.18022627e-02,  1.61497518e-01,  3.52659345e-01,\n",
       "        -3.40803087e-01,  1.80374831e-01, -6.00973628e-02,\n",
       "         2.45157734e-01, -9.15476605e-02, -1.44787490e-01,\n",
       "         1.17740631e-01,  4.93402213e-01, -3.05552576e-02,\n",
       "        -4.85131413e-01,  3.44934702e-01,  7.17239231e-02,\n",
       "        -7.23890290e-02,  1.45415254e-02,  1.36146232e-01,\n",
       "        -1.30361065e-01, -1.93914361e-02, -6.37624115e-02,\n",
       "         1.57722682e-01,  1.62305042e-01, -1.90456793e-01,\n",
       "         1.37071267e-01, -2.23016530e-01,  2.69431323e-01,\n",
       "         1.11218214e-01,  3.34793299e-01,  5.19510567e-01,\n",
       "         9.29496586e-02,  1.30683303e-01,  1.83144629e-01,\n",
       "        -2.13431746e-01, -1.22481585e-03,  1.22108988e-01,\n",
       "         8.20283517e-02, -1.56741381e-01,  1.31017417e-02,\n",
       "         5.91183230e-02,  5.46666503e-01,  1.51498988e-03,\n",
       "         2.88280964e-01,  1.19308703e-01, -2.65083522e-01,\n",
       "        -3.01424414e-04, -2.85406440e-01,  4.44024593e-01,\n",
       "         1.52272373e-01, -1.39788732e-01,  2.22930267e-01,\n",
       "         1.33886728e-02,  1.24151736e-01, -1.80119619e-01,\n",
       "        -1.22900270e-01,  3.21016252e-01,  3.44847083e-01,\n",
       "         1.29181147e-01,  2.07503200e-01, -9.86359790e-02,\n",
       "        -1.79033205e-01, -1.86438337e-02,  1.21018581e-01,\n",
       "         1.22235566e-02, -1.05224289e-01, -2.55295753e-01,\n",
       "         3.10072392e-01,  2.96794415e-01,  6.06839359e-02,\n",
       "         5.00157475e-04,  3.58001351e-01,  1.52173176e-01,\n",
       "         2.22199008e-01, -1.09937273e-01, -2.10983083e-02,\n",
       "         1.11186482e-01, -2.26863831e-01, -1.08423762e-01,\n",
       "        -1.85111657e-01, -3.28872114e-01,  1.33008510e-01,\n",
       "        -5.16240418e-01, -3.27274948e-02, -4.71812904e-01,\n",
       "        -4.68140393e-01,  3.11511457e-02,  9.71194431e-02,\n",
       "         1.58131905e-02,  2.81085670e-01,  9.19424593e-02,\n",
       "        -1.63103640e-02,  7.17285722e-02, -3.03778619e-01,\n",
       "        -2.43421644e-02, -4.60295498e-01,  1.94195956e-01,\n",
       "         1.33495688e-01, -6.28722906e-02,  2.28221461e-01,\n",
       "         6.02511838e-02,  3.38503331e-01, -2.38713428e-01,\n",
       "        -1.53827593e-01, -2.38669395e-01, -2.40121827e-01,\n",
       "        -2.43243471e-01, -2.10869044e-01, -2.96773970e-01,\n",
       "        -1.51509792e-01, -4.20028940e-02,  7.30652362e-02,\n",
       "         2.71065161e-04,  1.18145362e-01, -4.84966636e-02,\n",
       "         4.11136359e-01, -5.38925231e-01,  1.77191764e-01,\n",
       "         8.53120461e-02,  4.01937887e-02,  4.66394186e-01,\n",
       "        -2.64127940e-01,  1.61939338e-02,  1.55607015e-01,\n",
       "         5.26889265e-01, -2.87395895e-01, -8.28470103e-03,\n",
       "        -1.13464102e-01, -2.04167038e-01, -2.92278022e-01,\n",
       "         2.30567783e-01, -3.01172674e-01,  1.96092755e-01,\n",
       "        -2.70721763e-01,  2.56885648e-01,  1.85332641e-01,\n",
       "        -2.44825512e-01, -4.19600546e-01, -6.74439073e-02,\n",
       "        -2.27268413e-03, -1.77080482e-01, -7.24389404e-02,\n",
       "         1.19108498e-01, -1.71659693e-01, -7.09671155e-02,\n",
       "        -4.63807173e-02, -2.22905159e-01, -1.17861979e-01,\n",
       "        -1.39193330e-02, -4.13962044e-02, -2.44788945e-01,\n",
       "         3.17875333e-02, -1.97824240e-01, -3.47608000e-01,\n",
       "        -2.01711729e-01,  3.52064252e-01, -5.86014315e-02,\n",
       "         4.30492088e-02, -4.60065603e-02,  6.18813224e-02,\n",
       "        -1.57391131e-01,  1.91762790e-01,  1.84721902e-01,\n",
       "         2.12987959e-02, -7.03232884e-02,  2.15195015e-01,\n",
       "        -8.35271850e-02,  4.06301506e-02, -1.06210619e-01,\n",
       "        -2.83128798e-01, -1.32000163e-01, -6.08419999e-02,\n",
       "        -2.13150114e-01,  5.04592776e-01,  5.29831126e-02,\n",
       "         1.67710274e-01, -5.66192493e-02, -6.51037470e-02,\n",
       "         2.96081364e-01,  2.08033666e-01, -2.58169830e-01,\n",
       "        -1.88771933e-01, -2.20615909e-01,  3.71897779e-02,\n",
       "         2.90124238e-01, -8.11643228e-02, -2.30321884e-01,\n",
       "         3.02018046e-01, -2.33338382e-02, -2.73071766e-01,\n",
       "         1.93860933e-01,  3.76983821e-01,  5.16306996e-01,\n",
       "         3.91358763e-01,  1.52620107e-01,  2.53022164e-01,\n",
       "        -9.78853181e-02, -1.04188032e-01,  6.47482127e-02,\n",
       "        -2.75230587e-01,  1.59282953e-01,  1.64575964e-01,\n",
       "        -5.51896334e-01, -4.57597189e-02, -3.00117016e-01,\n",
       "        -1.15697227e-01,  4.91119586e-02,  8.85215029e-02,\n",
       "        -4.06496823e-02,  4.12716717e-01, -3.79074402e-02,\n",
       "        -2.51502782e-01, -3.23980212e-01, -1.66310906e-01,\n",
       "        -8.38590860e-02,  3.65416557e-02,  1.99315310e-01,\n",
       "        -2.62204558e-02, -3.05942893e-01,  6.21834874e-01,\n",
       "        -2.64938921e-01,  5.36368340e-02,  8.84730667e-02,\n",
       "         6.36535212e-02, -9.26130861e-02, -3.18204284e-01,\n",
       "         3.68412323e-02, -2.57697523e-01,  9.53866839e-01,\n",
       "        -2.46144965e-01,  1.01828270e-01, -2.27812544e-01,\n",
       "        -2.49327213e-01, -1.48103759e-01, -2.59450134e-02,\n",
       "        -1.84820011e-01, -5.12010371e-03,  2.37809286e-01,\n",
       "         7.57219613e-01,  1.17209330e-02,  2.06590444e-01,\n",
       "         7.97266811e-02, -4.93284136e-01, -8.96546394e-02,\n",
       "        -7.66374618e-02, -1.12704761e-01,  7.83435553e-02,\n",
       "         6.16844520e-02,  2.37822562e-01,  8.58181119e-02,\n",
       "         2.69005030e-01,  3.68880391e-01, -8.74714106e-02,\n",
       "        -2.52613574e-01, -9.45166424e-02,  1.49754152e-01,\n",
       "         1.02431789e-01,  1.54147804e-01, -9.28212851e-02,\n",
       "         1.09129176e-01,  7.90148228e-03, -9.82105136e-02,\n",
       "        -3.75313073e-01,  2.00398445e-01,  2.79151857e-01,\n",
       "        -3.65601182e-01, -2.61525422e-01,  2.94829845e-01,\n",
       "         4.81780350e-01,  1.50454864e-01,  1.26477122e-01,\n",
       "         4.30101156e-03,  4.00943905e-02,  2.74219096e-01,\n",
       "        -1.07175991e-01, -4.59849164e-02,  2.91197300e-01,\n",
       "         1.45607904e-01, -3.14987183e-01, -8.99043679e-02,\n",
       "        -6.85250536e-02,  8.47895294e-02, -2.17782781e-01,\n",
       "         5.38590662e-02,  1.41896546e-01, -7.07250163e-02,\n",
       "         1.30216599e-01,  1.95284128e-01,  1.24321318e+00,\n",
       "         2.07477987e-01,  1.01507291e-01, -9.80115905e-02,\n",
       "        -6.79299176e-01, -1.73818856e-01, -7.84694374e-01,\n",
       "         1.82528913e-01, -1.78337380e-01, -4.04718101e-01,\n",
       "        -2.09831484e-02, -1.46438032e-01,  4.11359333e-02,\n",
       "         1.93520799e-01, -2.04519942e-01, -2.76050776e-01,\n",
       "        -2.64150083e-01,  2.62919277e-01,  3.09049878e-02,\n",
       "        -3.33927386e-02,  2.28185326e-01,  2.15992332e-02,\n",
       "         2.56612599e-01,  2.59681404e-01,  1.44230053e-02,\n",
       "        -1.30791143e-02, -1.63196415e-01, -1.05642505e-01,\n",
       "        -6.69914559e-02, -8.26000497e-02, -9.01542231e-02,\n",
       "         3.84536922e-01,  2.93598175e-01, -4.10283729e-02,\n",
       "         1.68878008e-02, -4.36296612e-02, -2.19345823e-01,\n",
       "         3.03515434e-01,  5.86757898e-01,  1.61654428e-01,\n",
       "         1.37319133e-01,  4.38389182e-02,  1.20895028e-01,\n",
       "         2.06671171e-02, -1.54680610e-01,  1.15646899e-01,\n",
       "         4.36759144e-02, -3.50254864e-01, -5.03895938e-01,\n",
       "        -3.65658626e-02,  1.27433106e-01, -4.28537428e-01,\n",
       "        -7.23323345e-01,  1.29155964e-02, -5.55226147e-01,\n",
       "         7.78005421e-02, -6.38609380e-02,  5.79718113e-01,\n",
       "        -6.84905574e-02, -3.48265916e-02,  1.80385232e-01,\n",
       "        -6.46893382e-02, -2.56143302e-01,  3.11605483e-01,\n",
       "         1.05822459e-01, -1.44985199e-01, -2.80678004e-01,\n",
       "         1.29839912e-01,  1.26221240e-01,  4.24672604e-01,\n",
       "         5.94766662e-02, -1.25173673e-01, -2.29692787e-01,\n",
       "        -2.36086488e-01, -2.85015702e-01,  3.42973292e-01,\n",
       "        -1.00967735e-02,  4.21140283e-01, -3.73286575e-01,\n",
       "        -3.06515127e-01, -8.44099894e-02, -1.30670667e-01,\n",
       "        -3.60587388e-02,  3.57556455e-02, -1.29920959e-01,\n",
       "        -2.28186563e-01, -1.79874338e-02,  2.62972772e-01,\n",
       "         6.85954541e-02, -4.40257974e-02, -2.00894833e-01,\n",
       "         1.22594729e-01, -1.59435630e-01,  1.85860649e-01,\n",
       "        -4.14132833e-01,  5.32592386e-02,  3.05239469e-01,\n",
       "         1.00044951e-01,  1.13783292e-01, -3.66840959e-01,\n",
       "         2.20355958e-01,  1.69479340e-01,  2.76633352e-01,\n",
       "         3.79004590e-02,  5.30984923e-02, -3.35347712e-01,\n",
       "        -3.11886631e-02,  6.76513016e-02,  3.85256484e-04,\n",
       "        -1.37095734e-01, -2.23088071e-01, -1.46511197e-01,\n",
       "         3.12624872e-03,  1.23822587e-02, -6.82663918e-02,\n",
       "         2.32585043e-01,  1.82694376e-01,  4.92096134e-02,\n",
       "         1.52679890e-01,  2.18364656e-01,  1.75983980e-02,\n",
       "        -1.41712740e-01,  4.43799525e-01,  6.43835738e-02,\n",
       "        -1.79957420e-01, -1.57113820e-01,  1.69143453e-01,\n",
       "        -1.67379335e-01, -5.44760108e-01, -6.04146197e-02,\n",
       "         5.43774188e-01,  3.39783460e-01, -3.93766686e-02,\n",
       "         1.34145558e-01, -1.10354841e-01, -1.76539108e-01,\n",
       "         2.26430371e-02, -7.91048259e-03,  2.16563627e-01,\n",
       "        -7.27272555e-02,  4.18852597e-01,  2.85397530e-01,\n",
       "        -6.65765256e-02, -2.68435240e-01, -9.24579352e-02,\n",
       "        -1.52573362e-01,  2.43106820e-02,  1.01742573e-01,\n",
       "        -2.84128308e-01,  2.59357750e-01,  7.28507340e-03,\n",
       "        -7.92907625e-02, -6.12357371e-02,  1.05788775e-01,\n",
       "         1.91291958e-01, -1.78998336e-01, -1.36444457e-02,\n",
       "        -7.16195107e-02,  1.93376020e-01,  3.22604656e-01,\n",
       "         4.37910780e-02,  6.30831063e-01,  2.79437631e-01,\n",
       "        -8.32119957e-02,  8.62570882e-01,  2.01182663e-01,\n",
       "         2.48442888e-01,  3.50527585e-01, -6.21538125e-02,\n",
       "         3.65265831e-02,  2.52969444e-01,  1.58022285e-01,\n",
       "         1.27721459e-01, -4.42414284e-01,  2.55726904e-01,\n",
       "        -3.41232896e-01, -1.36830434e-01, -1.90912500e-01,\n",
       "        -2.26111531e-01, -1.38653830e-01, -1.70491412e-01,\n",
       "         9.59496200e-03, -3.98271680e-02, -3.82896774e-02,\n",
       "        -9.48265046e-02, -1.40654877e-01, -4.36626881e-01,\n",
       "         1.35407805e-01,  1.50953650e-01,  1.11770913e-01,\n",
       "        -1.30818605e-01,  1.40862718e-01,  1.77594334e-01,\n",
       "         9.83307511e-02,  1.77152112e-01,  2.53465503e-01,\n",
       "         2.86977768e-01, -3.25608253e-01,  1.49745494e-01,\n",
       "         1.84291437e-01,  1.26229510e-01, -3.57276559e-01,\n",
       "         6.90062940e-02,  4.87969890e-02, -4.10381049e-01,\n",
       "        -4.41157073e-02,  1.07965395e-01,  5.10367632e-01,\n",
       "         2.43674949e-01, -3.16091061e-01,  2.04064444e-01,\n",
       "        -2.80220240e-01,  6.62050545e-01,  2.30600104e-01,\n",
       "         2.95521826e-01,  9.89766717e-02,  1.53292581e-01,\n",
       "         2.02029869e-01,  9.64686200e-02, -6.36239275e-02,\n",
       "        -9.24861506e-02, -1.34532452e-01,  3.44157726e-01,\n",
       "         4.00496423e-01,  3.19236191e-04, -1.03460990e-01,\n",
       "         3.36944044e-01,  1.28614381e-01,  2.29059294e-01,\n",
       "         4.00742516e-02,  7.41420910e-02,  4.20942307e-02,\n",
       "        -2.55442038e-02, -8.53251591e-02,  2.98758000e-01,\n",
       "         3.01829606e-01, -1.08162344e-01, -1.31807014e-01,\n",
       "        -2.14518577e-01, -6.83629736e-02,  2.17472106e-01,\n",
       "        -2.10005008e-02,  1.68693498e-01,  5.12310443e-03,\n",
       "        -2.00728670e-01,  4.28106561e-02, -1.36223137e-01,\n",
       "         9.94950682e-02,  3.87358785e-01,  3.54161173e-01,\n",
       "         2.90805846e-01,  9.90012661e-03,  1.01185665e-01,\n",
       "        -3.03487368e-02,  2.69663125e-01, -8.48868676e-03,\n",
       "        -2.63947546e-01, -2.73438305e-01, -7.39452392e-02,\n",
       "         2.98937440e-01, -1.11994669e-01,  4.53439169e-02,\n",
       "        -3.43015850e-01, -1.17619224e-01,  1.50781497e-01,\n",
       "        -9.11590159e-02,  2.41323840e-03,  1.05335779e-01,\n",
       "         1.17117211e-01,  3.51360619e-01, -2.54779845e-01,\n",
       "         1.05026454e-01,  2.42280379e-01, -1.44505605e-01,\n",
       "         2.43585065e-01,  4.54998851e-01,  2.07335219e-01,\n",
       "        -8.33911672e-02,  1.79265231e-01, -2.30156362e-01,\n",
       "        -2.48648629e-01,  5.34767866e-01, -1.03815049e-01,\n",
       "        -1.14728250e-01, -2.88390040e-01, -1.84428513e-01,\n",
       "         4.28340852e-01,  2.07193382e-02, -2.84689993e-01,\n",
       "        -2.15675548e-01,  1.40996724e-01,  4.89010662e-01,\n",
       "         1.44746408e-01,  1.41405016e-01,  1.89004123e-01,\n",
       "         1.13518827e-01, -2.86039114e-01, -1.00577146e-01,\n",
       "         2.66672730e-01,  2.25654900e-01, -3.68733928e-02,\n",
       "         1.66075304e-03, -3.10998410e-01,  3.07555705e-01,\n",
       "        -8.62251520e-02, -8.99316818e-02, -2.83052981e-01]], dtype=float32)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class BERTEmbeddings:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "        self.model = AutoModel.from_pretrained(model_ckpt)\n",
    "        \n",
    "    #CLS is a special classification token and the last hidden state of BERT Embedding\n",
    "    def cls_pooling(self, model_output):\n",
    "        return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "    #BERT tokenizer of input text\n",
    "    def getEmbeddings(self, text_list):\n",
    "        encoded_input = self.tokenizer(\n",
    "            text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        model_output = self.model(**encoded_input)\n",
    "        return self.cls_pooling(model_output).cpu().detach().numpy()\n",
    "    \n",
    "train = BERTEmbeddings()\n",
    "train.getEmbeddings([\"julia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6f3bd06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell Plc\n",
      "Accenture Plc \n",
      "Linde Plc\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "    \n",
    "class Faiss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def faiss(self,xb):\n",
    "        d = xb[0].size\n",
    "        M = 32\n",
    "        index = faiss.IndexHNSWFlat(d, M)            \n",
    "        index.hnsw.efConstruction = 40         # Setting the value for efConstruction.\n",
    "        index.hnsw.efSearch = 16               # Setting the value for efSearch.\n",
    "        index.add(xb)\n",
    "        return index\n",
    "    \n",
    "    def query(self,index,xq,k=3):\n",
    "        D, I = index.search(xq, k)   \n",
    "        return D, I\n",
    "\n",
    "xq = train.getEmbeddings([\"shell plc\"])\n",
    "xb = train.getEmbeddings(data)\n",
    "index = Faiss().faiss(xb)\n",
    "D,I = Faiss().query(index,xq)\n",
    "I = I[0]\n",
    "print(data[I[0]] + \"\\n\" + data[I[1]], \"\\n\" + data[I[2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
