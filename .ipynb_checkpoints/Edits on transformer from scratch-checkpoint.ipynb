{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e9a7e8",
   "metadata": {
    "papermill": {
     "duration": 0.009019,
     "end_time": "2023-11-07T12:11:42.558290",
     "exception": false,
     "start_time": "2023-11-07T12:11:42.549271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>1 |</span></b> <b>BACKGROUND</b></div>\n",
    "\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>ENCODER BASE</span></b></p></div>\n",
    "\n",
    "In the following notebook, we'll look at the following components of the Transformer Encoder structure\n",
    "\n",
    "<div style=\" background-color:#3b3745; padding: 13px 13px; border-radius: 8px; color: white\">\n",
    "    \n",
    "<ul>\n",
    "<li>Simple Attention</li>\n",
    "<li>Multi-Head Self Attention</li>\n",
    "<li>Feed Forward Layer</li>\n",
    "<li>Normalisation</li>\n",
    "<li>Skip Connection</li>\n",
    "<li>Position Embeddings</li>\n",
    "<li>Transformer Encoder</li>\n",
    "<li>Classifier Head</li>\n",
    "</ul> \n",
    "</div> \n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>ENCODER BASE</span></b></p></div>\n",
    "\n",
    "Encoder simply put:\n",
    "- Converts a **series tokens** into a **series of embedding vectors** (hidden state)\n",
    "- The encoder (neural network) consists of **multiple layers** (**blocks**) constructed together \n",
    "\n",
    "The encoder structure:\n",
    "- Composed of multiple encoder layers (blocks) stacked next to each other (similar to CNN layer stacks)\n",
    "- Each encoder block contains **multi-head self attention** & **fully connected feed forward layer** (for each input embedding)\n",
    "\n",
    "Purpose of the Encoder\n",
    "- Input tokens are encoded & modified into a form that **stores some contextual information** in the sequence\n",
    "\n",
    "The example we'll use:\n",
    "\n",
    "> the bark of a palm tree is very rough\n",
    "\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>CLASSIFICATION HEAD</span></b></p></div>\n",
    "\n",
    "- Transformers can be utilised for various application so they are created in a base form\n",
    "- If we want to utilise them for a specific task, we add an extra component **head** to the transformer\n",
    "- In this example, we'll utilise it for **classification** purposes, and look at how we can combine the base with the **head**\n",
    "\n",
    "\n",
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>2 |</span></b> <b>SIMPLE SELF ATTENTION</b></div>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>TYPES OF ATTENTION</span></b></p></div>\n",
    "\n",
    "**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention</mark>**\n",
    " \n",
    "- Mechanism which allows networks to assign **different weight distributions to each element** in a sequence \n",
    "- Elements in sequence - `token embeddings` (each token mapped to a vector of fixed dimension) (eg. BERT model - 768 dimensions)\n",
    " \n",
    " \n",
    "**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">self-attention</mark>**\n",
    "\n",
    "- Instead of using fixed embeddings for each token, can use whole sequence to **compute weighted average** of each `embedding`\n",
    "- One can think of self-attention as a form of averaging\n",
    "- Common form of `self-attention` **scaled dot-product attention** \n",
    "\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>FOUR MAIN STEPS</span></b></p></div>\n",
    "\n",
    "\n",
    "- Project each `token embedding` into three vectors **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">query</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">key</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>**\n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** (nxn)\n",
    "\n",
    "    - (we determine how much the query & key vectors relate to eachother using a similarity function)\n",
    "    - Similarity function for scaled dot-product attention - dot product\n",
    "    - queries & keys that are similar will have large dot product & visa versa\n",
    "    - Outputs from this step - attention scores\n",
    "    \n",
    "    \n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weight</mark>** (wij)\n",
    "\n",
    "    - dot products produce large numbers \n",
    "    - attention scores first multiplied by a scaling factor to normalise their variance\n",
    "    - Then normalised with softmax to ensure all column values sum to 1\n",
    "    \n",
    "    \n",
    "- Update the token embeddings (hidden state)\n",
    "\n",
    "    - multiply the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">weights</mark>** by the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>** vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55217be8",
   "metadata": {
    "papermill": {
     "duration": 0.009999,
     "end_time": "2023-11-07T12:11:42.577461",
     "exception": false,
     "start_time": "2023-11-07T12:11:42.567462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>SIMPLE ATTENTION FORMULATION</span></b></p></div>\n",
    "\n",
    "\n",
    "- Well look at a simple example, and summarise the attention mechanism in one function\n",
    "- `bert-base-uncased` model will be used to extract different model settings (eg. number of attention heads), so we will be building a similar model \n",
    "\n",
    "<br>\n",
    "\n",
    "##### **1. DOCUMENT TOKENISATION**\n",
    "\n",
    "- Each token in the sentence has been mapped to a **unique identifier** from a **vocabulary** or **dictionary**\n",
    "- We start off by using the `bert-base-uncased` pretrained tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35551bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:11:42.597284Z",
     "iopub.status.busy": "2023-11-07T12:11:42.596990Z",
     "iopub.status.idle": "2023-11-07T12:12:00.483141Z",
     "shell.execute_reply": "2023-11-07T12:12:00.482187Z"
    },
    "papermill": {
     "duration": 17.898714,
     "end_time": "2023-11-07T12:12:00.485317",
     "exception": false,
     "start_time": "2023-11-07T12:11:42.586603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from bertviz.transformers_neuron_view import BertModel\n",
    "\n",
    "# load tokeniser and model\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = BertModel.from_pretrained(model_ckpt)\n",
    "\n",
    "# document well be using as an exmaple\n",
    "text = \"the bark of a palm tree is very rough\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f10c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:00.517236Z",
     "iopub.status.busy": "2023-11-07T12:12:00.516931Z",
     "iopub.status.idle": "2023-11-07T12:12:00.533190Z",
     "shell.execute_reply": "2023-11-07T12:12:00.532308Z"
    },
    "papermill": {
     "duration": 0.034096,
     "end_time": "2023-11-07T12:12:00.535098",
     "exception": false,
     "start_time": "2023-11-07T12:12:00.501002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1996, 11286,  1997,  1037,  5340,  3392,  2003,  2200,  5931]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenise input (text)\n",
    "inputs = tokenizer(text, \n",
    "                   return_tensors=\"pt\",      # pytorc tensor\n",
    "                   add_special_tokens=False) # don't use pad, sep tokens\n",
    "\n",
    "print(inputs.input_ids)\n",
    "inputs.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb56d7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:00.568327Z",
     "iopub.status.busy": "2023-11-07T12:12:00.568012Z",
     "iopub.status.idle": "2023-11-07T12:12:06.186950Z",
     "shell.execute_reply": "2023-11-07T12:12:06.186030Z"
    },
    "papermill": {
     "duration": 5.637794,
     "end_time": "2023-11-07T12:12:06.188698",
     "exception": false,
     "start_time": "2023-11-07T12:12:00.550904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the bark of a palm tree is very rough'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode sequence\n",
    "tokenizer.decode(inputs['input_ids'].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e975fd",
   "metadata": {
    "papermill": {
     "duration": 0.014971,
     "end_time": "2023-11-07T12:12:06.218934",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.203963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At this point:\n",
    "\n",
    "- `inputs.inpits_ids` A tensor of id mapped tokens\n",
    "- Token embeddings are **independent of their context**\n",
    "- **Homonyms** (same spelling, but different meaning) have the same representation\n",
    "\n",
    "Role of subsequent attention layers:\n",
    "\n",
    "- Mix the **token embeddings** to disambiguate & inform the representation of each token with the context of its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8859aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.251254Z",
     "iopub.status.busy": "2023-11-07T12:12:06.250611Z",
     "iopub.status.idle": "2023-11-07T12:12:06.511660Z",
     "shell.execute_reply": "2023-11-07T12:12:06.510800Z"
    },
    "papermill": {
     "duration": 0.279247,
     "end_time": "2023-11-07T12:12:06.513439",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.234192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 hidden size\n",
      "30522 vocabulary size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Create an embedding layer\n",
    "\n",
    "'''\n",
    "\n",
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "\n",
    "print(config.hidden_size,\"hidden size\")\n",
    "print(config.vocab_size,\"vocabulary size\")\n",
    "\n",
    "# load sample embedding layer of size (30522,758) -> same as bert-base\n",
    "token_emb = nn.Embedding(config.vocab_size,\n",
    "                         config.hidden_size)\n",
    "token_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee78d5",
   "metadata": {
    "papermill": {
     "duration": 0.015119,
     "end_time": "2023-11-07T12:12:06.544245",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.529126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **2. EMBEDDING VECTORS**\n",
    "\n",
    "\n",
    "- Convert Tokenised data into embedding data (768 dimensions) using vocab of 30522 tokens\n",
    "- Each input_ids is **mapped to one of 30522 embedding vectors** stored in nn.embedding, each with a size of 768 \n",
    "- Our output will be [batch_size,seq_len,hidden_dim] by calling `nn.Embedding(hidden)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd751b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.576500Z",
     "iopub.status.busy": "2023-11-07T12:12:06.576191Z",
     "iopub.status.idle": "2023-11-07T12:12:06.586332Z",
     "shell.execute_reply": "2023-11-07T12:12:06.585567Z"
    },
    "papermill": {
     "duration": 0.028427,
     "end_time": "2023-11-07T12:12:06.588032",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.559605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Convert Tokens to Embedding Vectors\n",
    "utilising the existing model embedding embeddings\n",
    "\n",
    "'''\n",
    "\n",
    "inputs_embeds = token_emb(inputs.input_ids)\n",
    "inputs_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3feb8277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.620723Z",
     "iopub.status.busy": "2023-11-07T12:12:06.620434Z",
     "iopub.status.idle": "2023-11-07T12:12:06.627221Z",
     "shell.execute_reply": "2023-11-07T12:12:06.626491Z"
    },
    "papermill": {
     "duration": 0.024936,
     "end_time": "2023-11-07T12:12:06.628895",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.603959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1372, -0.1640, -0.5709,  ..., -0.3382, -0.5156, -0.9368],\n",
       "         [ 1.6893,  0.7558,  0.0126,  ..., -1.8282, -0.0124, -0.5235],\n",
       "         [-0.2811,  0.3767, -0.2336,  ...,  1.5930, -1.5876,  1.9867],\n",
       "         ...,\n",
       "         [-0.4095, -0.1513,  0.4900,  ..., -0.2493,  0.7508,  0.0295],\n",
       "         [-1.8162,  0.8497,  1.4001,  ..., -0.5877, -0.4474,  0.9935],\n",
       "         [-0.6127, -0.1215,  2.2074,  ...,  1.5790,  0.3022, -0.4228]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 embedding vectors of 768 dimensions\n",
    "inputs_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f90749",
   "metadata": {
    "papermill": {
     "duration": 0.014998,
     "end_time": "2023-11-07T12:12:06.659344",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.644346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **3. QUERY, KEY, VALUE VECTORS**\n",
    "\n",
    "- As the most simplistic case of attention, **we set them equal to one another**\n",
    "- Attention mechanism with equal query and key vectors will assign a **very large score to identical words in the context** (diagonal component of matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729ded24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.690843Z",
     "iopub.status.busy": "2023-11-07T12:12:06.690541Z",
     "iopub.status.idle": "2023-11-07T12:12:06.696736Z",
     "shell.execute_reply": "2023-11-07T12:12:06.696023Z"
    },
    "papermill": {
     "duration": 0.023794,
     "end_time": "2023-11-07T12:12:06.698387",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.674593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query and key components\n",
      "\n",
      "query size: torch.Size([1, 9, 768])\n",
      "key size: torch.Size([1, 768, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "\n",
    "# setting them equal to one another\n",
    "print(\"query and key components\\n\")\n",
    "query = key = value = inputs_embeds\n",
    "print('query size:',query.size())\n",
    "dim_k = key.size(-1)   # hidden dimension \n",
    "print('key size:',key.transpose(1,2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc551bd",
   "metadata": {
    "papermill": {
     "duration": 0.01558,
     "end_time": "2023-11-07T12:12:06.729699",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.714119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **4. COMPUTE ATTENTION SCORES**\n",
    "\n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** using the **dot product as the similarity function**\n",
    "- `torch.bmm` - batch matrix matrix product (as we work in batches during training)\n",
    "- If we need to transpose a vector `vector.transpose(1,2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514d67e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.762745Z",
     "iopub.status.busy": "2023-11-07T12:12:06.762404Z",
     "iopub.status.idle": "2023-11-07T12:12:06.776470Z",
     "shell.execute_reply": "2023-11-07T12:12:06.775853Z"
    },
    "papermill": {
     "duration": 0.032784,
     "end_time": "2023-11-07T12:12:06.778682",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.745898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dot product (attention scores)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product & apply normalisation\n",
    "print(\"\\ndot product (attention scores)\")\n",
    "scores = torch.bmm(query, key.transpose(1,2)) / sqrt(dim_k)\n",
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46d911a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.812364Z",
     "iopub.status.busy": "2023-11-07T12:12:06.812033Z",
     "iopub.status.idle": "2023-11-07T12:12:06.818346Z",
     "shell.execute_reply": "2023-11-07T12:12:06.817521Z"
    },
    "papermill": {
     "duration": 0.025187,
     "end_time": "2023-11-07T12:12:06.819967",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.794780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[28.2778, -0.0560, -0.5845,  0.8930, -0.1730, -0.6903,  1.4119,\n",
       "           2.5140, -1.2024],\n",
       "         [-0.0560, 27.7726,  0.7603,  0.1857, -0.3888, -0.9593,  0.7742,\n",
       "          -2.4892, -0.0420],\n",
       "         [-0.5845,  0.7603, 26.8805, -0.1206,  0.2067,  1.2373, -0.3023,\n",
       "          -2.0496, -0.1639],\n",
       "         [ 0.8930,  0.1857, -0.1206, 27.7590,  0.4918,  1.7533,  0.6470,\n",
       "           0.0552, -0.0448],\n",
       "         [-0.1730, -0.3888,  0.2067,  0.4918, 26.3990, -1.1320, -0.2163,\n",
       "           0.4334,  0.4951],\n",
       "         [-0.6903, -0.9593,  1.2373,  1.7533, -1.1320, 29.1548,  0.0852,\n",
       "          -0.6562,  0.2810],\n",
       "         [ 1.4119,  0.7742, -0.3023,  0.6470, -0.2163,  0.0852, 28.4623,\n",
       "          -0.1245, -0.7585],\n",
       "         [ 2.5140, -2.4892, -2.0496,  0.0552,  0.4334, -0.6562, -0.1245,\n",
       "          28.0784, -0.5796],\n",
       "         [-1.2024, -0.0420, -0.1639, -0.0448,  0.4951,  0.2810, -0.7585,\n",
       "          -0.5796, 27.5657]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291f7de",
   "metadata": {
    "papermill": {
     "duration": 0.015722,
     "end_time": "2023-11-07T12:12:06.851771",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.836049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **5. COMPUTE ATTENTION WEIGHTS (SOFTMAX FUNCTION)**\n",
    "\n",
    "\n",
    "\n",
    "- Created a 5x5 matrix of **attention scores** per sample in the batch\n",
    "- Apply the softmax for normalisation to get the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "848e4e3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.885652Z",
     "iopub.status.busy": "2023-11-07T12:12:06.885333Z",
     "iopub.status.idle": "2023-11-07T12:12:06.894232Z",
     "shell.execute_reply": "2023-11-07T12:12:06.893421Z"
    },
    "papermill": {
     "duration": 0.02817,
     "end_time": "2023-11-07T12:12:06.896060",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.867890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sotfmax applied, attention weights :\n",
      "\n",
      "torch.Size([1, 9, 9])\n",
      "tensor([[[1.0000e+00, 4.9519e-13, 2.9192e-13, 1.2792e-12, 4.4051e-13,\n",
      "          2.6260e-13, 2.1492e-12, 6.4703e-12, 1.5736e-13],\n",
      "         [8.2070e-13, 1.0000e+00, 1.8565e-12, 1.0451e-12, 5.8837e-13,\n",
      "          3.3259e-13, 1.8825e-12, 7.2022e-14, 8.3224e-13],\n",
      "         [1.1807e-12, 4.5303e-12, 1.0000e+00, 1.8776e-12, 2.6044e-12,\n",
      "          7.2997e-12, 1.5656e-12, 2.7277e-13, 1.7979e-12],\n",
      "         [2.1492e-12, 1.0595e-12, 7.7997e-13, 1.0000e+00, 1.4389e-12,\n",
      "          5.0805e-12, 1.6804e-12, 9.2980e-13, 8.4132e-13],\n",
      "         [2.8834e-12, 2.3237e-12, 4.2151e-12, 5.6058e-12, 1.0000e+00,\n",
      "          1.1052e-12, 2.7612e-12, 5.2877e-12, 5.6243e-12],\n",
      "         [1.0925e-13, 8.3488e-14, 7.5089e-13, 1.2580e-12, 7.0245e-14,\n",
      "          1.0000e+00, 2.3725e-13, 1.1305e-13, 2.8856e-13],\n",
      "         [1.7871e-12, 9.4449e-13, 3.2189e-13, 8.3169e-13, 3.5078e-13,\n",
      "          4.7422e-13, 1.0000e+00, 3.8450e-13, 2.0397e-13],\n",
      "         [7.8983e-12, 5.3048e-14, 8.2331e-14, 6.7556e-13, 9.8613e-13,\n",
      "          3.3170e-13, 5.6444e-13, 1.0000e+00, 3.5807e-13],\n",
      "         [3.2073e-13, 1.0235e-12, 9.0607e-13, 1.0206e-12, 1.7513e-12,\n",
      "          1.4137e-12, 4.9997e-13, 5.9788e-13, 1.0000e+00]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "sum of column values:/n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"sotfmax applied, attention weights :\\n\")\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "print(weights.size())\n",
    "print(weights)\n",
    "\n",
    "print(\"\\nsum of column values:/n\")\n",
    "weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf19419",
   "metadata": {
    "papermill": {
     "duration": 0.017197,
     "end_time": "2023-11-07T12:12:06.930058",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.912861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **6. UPDATE VALUES**\n",
    "\n",
    "Multiply the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>** matrix by the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">values</mark>** vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d827e60f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.963834Z",
     "iopub.status.busy": "2023-11-07T12:12:06.963500Z",
     "iopub.status.idle": "2023-11-07T12:12:06.970332Z",
     "shell.execute_reply": "2023-11-07T12:12:06.969370Z"
    },
    "papermill": {
     "duration": 0.025786,
     "end_time": "2023-11-07T12:12:06.972071",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.946285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1372, -0.1640, -0.5709,  ..., -0.3382, -0.5156, -0.9368],\n",
      "         [ 1.6893,  0.7558,  0.0126,  ..., -1.8282, -0.0124, -0.5235],\n",
      "         [-0.2811,  0.3767, -0.2336,  ...,  1.5930, -1.5876,  1.9867],\n",
      "         ...,\n",
      "         [-0.4095, -0.1513,  0.4900,  ..., -0.2493,  0.7508,  0.0295],\n",
      "         [-1.8162,  0.8497,  1.4001,  ..., -0.5877, -0.4474,  0.9935],\n",
      "         [-0.6127, -0.1215,  2.2074,  ...,  1.5790,  0.3022, -0.4228]]],\n",
      "       grad_fn=<BmmBackward0>)\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "attn_outputs = torch.bmm(weights, value)\n",
    "print(attn_outputs)\n",
    "print(attn_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c5cf7f",
   "metadata": {
    "papermill": {
     "duration": 0.016049,
     "end_time": "2023-11-07T12:12:07.004544",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.988495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we have a general function:\n",
    "- Which inputs vectors `query`, `key` & `value` \n",
    "- Calculates the scalar dot product attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadf54f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.039142Z",
     "iopub.status.busy": "2023-11-07T12:12:07.038780Z",
     "iopub.status.idle": "2023-11-07T12:12:07.044075Z",
     "shell.execute_reply": "2023-11-07T12:12:07.043479Z"
    },
    "papermill": {
     "duration": 0.024195,
     "end_time": "2023-11-07T12:12:07.045542",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.021347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Scalar Dot Product Attention\n",
    "scores = query*key.T / sqrt(dims)\n",
    "weight = softmax(scores) \n",
    "\n",
    "'''\n",
    "\n",
    "def sdp_attention(query, key, value):\n",
    "    dim_k = query.size(-1) # dimension component\n",
    "    sfact = sqrt(dim_k)     \n",
    "    scores = torch.bmm(query, key.transpose(1,2)) / sfact\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ff305",
   "metadata": {
    "papermill": {
     "duration": 0.0158,
     "end_time": "2023-11-07T12:12:07.077434",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.061634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>3 |</span></b> <b>MULTIHEAD SELF ATTENTION</b></div>\n",
    "\n",
    "\n",
    "- The meaning of the word will be better informed by **complementary words in the context** than by **identical words** (which gives 1)\n",
    "\n",
    "##### **SIMPLISTIC APPROACH**\n",
    "\n",
    "- We only used the embeddings \"as is\" (no linear transformation) to compute the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>**\n",
    "\n",
    "##### **BETTER APPROACH**\n",
    "\n",
    "- The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">self-attention</mark>** layer applies **three independent linear transformations (`nn.linear`) to each embedding** to generate **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">query</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">key</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>** \n",
    "- These transformations project the embeddings and **each projection carries its own set of learnable parameters** (**Weights**)\n",
    "- This **allows the self-attention layer to focus on different semantic aspects of the sequence**\n",
    "\n",
    "\n",
    "\n",
    "Its beneficial to have **multiple sets of linear projections** (each one represents an **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention head</mark>**)\n",
    "\n",
    "Why do we need more than one **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention head</mark>**?\n",
    "- The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">softmax</mark>** of one head tends to focus on mostly **one aspect of similarity**\n",
    "\n",
    "\n",
    "**Several heads** allows the model to **focus on several apsects at once**\n",
    "- Eg. one head can focus on subject-verb interaction, another finds nearby adjectives\n",
    "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">CV analogy</mark>**: filters; one filter responsible for detecting the head, another for facial features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae55c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.111569Z",
     "iopub.status.busy": "2023-11-07T12:12:07.110662Z",
     "iopub.status.idle": "2023-11-07T12:12:07.116625Z",
     "shell.execute_reply": "2023-11-07T12:12:07.116040Z"
    },
    "papermill": {
     "duration": 0.024562,
     "end_time": "2023-11-07T12:12:07.118152",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.093590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Attention Class\n",
    "\n",
    "# nn.linear : apply linear transformation to incoming data\n",
    "#             y = x * A^T + b\n",
    "# Ax = b where x is input, b is output, A is weight\n",
    "\n",
    "# calculate scaled dot product attention matrix\n",
    "# Requires embedding dimension \n",
    "# Each attention head is made of different q,k,v vectors\n",
    "\n",
    "'''\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    # initalisation \n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the three vectors\n",
    "        # input - embed_dim, output - head_dim\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    # main class operation\n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # calculate scaled dot product given a \n",
    "        attn_outputs = sdp_attention(\n",
    "            self.q(hidden_state), \n",
    "            self.k(hidden_state), \n",
    "            self.v(hidden_state))\n",
    "        \n",
    "        return attn_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647aecb",
   "metadata": {
    "papermill": {
     "duration": 0.015925,
     "end_time": "2023-11-07T12:12:07.150302",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.134377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`Attention` will be used in the construction of a model\n",
    "\n",
    "- We’ve **initialised three independent linear layers** that apply matrix multiplication to the embedding vectors to produce tensors of shape [batch_size, seq_len, head_dim]\n",
    "- Where head_dim is the number of dimensions we are projecting into\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f47172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.184165Z",
     "iopub.status.busy": "2023-11-07T12:12:07.183786Z",
     "iopub.status.idle": "2023-11-07T12:12:07.188846Z",
     "shell.execute_reply": "2023-11-07T12:12:07.187928Z"
    },
    "papermill": {
     "duration": 0.024268,
     "end_time": "2023-11-07T12:12:07.190719",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.166451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 heads\n",
      "768 hidden state embedding dimension\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print(config.num_attention_heads,'heads')\n",
    "print(config.hidden_size,'hidden state embedding dimension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dc47326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.224688Z",
     "iopub.status.busy": "2023-11-07T12:12:07.224386Z",
     "iopub.status.idle": "2023-11-07T12:12:07.230964Z",
     "shell.execute_reply": "2023-11-07T12:12:07.230200Z"
    },
    "papermill": {
     "duration": 0.025767,
     "end_time": "2023-11-07T12:12:07.232720",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.206953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (q): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (k): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (v): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Sample Initialisation '''\n",
    "\n",
    "# Initialised just one head, requires token embedding vector for forward operation\n",
    "\n",
    "embed_dim = config.hidden_size\n",
    "num_heads = config.num_attention_heads\n",
    "\n",
    "attention = Attention(embed_dim,num_heads)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da230f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.266405Z",
     "iopub.status.busy": "2023-11-07T12:12:07.265958Z",
     "iopub.status.idle": "2023-11-07T12:12:07.276364Z",
     "shell.execute_reply": "2023-11-07T12:12:07.275745Z"
    },
    "papermill": {
     "duration": 0.028895,
     "end_time": "2023-11-07T12:12:07.278006",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.249111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3785, -0.1225,  0.1665, -0.2492,  0.0298, -0.0010,  0.4590,\n",
       "           0.2504,  0.3419, -0.1287, -0.1394, -0.0081],\n",
       "         [-0.4377, -0.0131, -0.0385, -0.4269, -0.0143, -0.2199,  0.3435,\n",
       "           0.2661,  0.2000, -0.0322, -0.1178, -0.0684],\n",
       "         [-0.4217, -0.0546,  0.0053, -0.1888,  0.0211, -0.2245,  0.3599,\n",
       "           0.2941,  0.2816,  0.0566, -0.1054,  0.0277],\n",
       "         [-0.1829, -0.1457,  0.1940, -0.1023,  0.0994,  0.0569,  0.1223,\n",
       "           0.3326,  0.2057,  0.1363, -0.0909,  0.0537],\n",
       "         [-0.5145, -0.1693,  0.0426, -0.2721, -0.0756, -0.1849,  0.4172,\n",
       "           0.2842,  0.2850, -0.0334, -0.1068,  0.1154],\n",
       "         [-0.3539, -0.0502,  0.0768, -0.2742,  0.0889, -0.1206,  0.3454,\n",
       "           0.2391,  0.2898, -0.0085, -0.0863, -0.0209],\n",
       "         [-0.5372, -0.2052,  0.1084, -0.2576, -0.0576, -0.1253,  0.5218,\n",
       "           0.2485,  0.3603, -0.1158, -0.1089,  0.1241],\n",
       "         [-0.3806, -0.0407,  0.0601, -0.3340,  0.0367, -0.1459,  0.3445,\n",
       "           0.2424,  0.2543, -0.0352, -0.0955, -0.0328],\n",
       "         [-0.3776,  0.0047,  0.0028, -0.4158,  0.1387, -0.1608,  0.3675,\n",
       "           0.1977,  0.2328, -0.0861, -0.0563, -0.1697]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights are always initialised randomly, attention_outputs varies\n",
    "attention_outputs = attention(inputs_embeds)\n",
    "attention_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54eec369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.312835Z",
     "iopub.status.busy": "2023-11-07T12:12:07.312013Z",
     "iopub.status.idle": "2023-11-07T12:12:07.318401Z",
     "shell.execute_reply": "2023-11-07T12:12:07.317850Z"
    },
    "papermill": {
     "duration": 0.025446,
     "end_time": "2023-11-07T12:12:07.320076",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.294630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Multihead attention class\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class multiHeadAttention(nn.Module):\n",
    "    \n",
    "    # Config during initalisation\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # model params, read from config file\n",
    "        embed_dim = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # attention head (define only w/o hidden state)\n",
    "        # each attention head is initialised with embedd/heads head dimension\n",
    "        self.heads = nn.ModuleList(\n",
    "            [Attention(embed_dim, head_dim) for _ in range(num_heads)])\n",
    "        \n",
    "        # output uses whole embedding dimension for output\n",
    "        self.out_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    # Given a hidden state (embeddings)\n",
    "    # Apply operation for multihead attention\n",
    "        \n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # for each head embed_size/heads, calculate attention\n",
    "        heads = [head(hidden_state) for head in self.heads] \n",
    "        x = torch.cat(heads, dim=-1) # merge/concat head data together\n",
    "    \n",
    "        # apply linear transformation to multihead attension scalar product\n",
    "        x = self.out_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bba389d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.354402Z",
     "iopub.status.busy": "2023-11-07T12:12:07.353650Z",
     "iopub.status.idle": "2023-11-07T12:12:07.380981Z",
     "shell.execute_reply": "2023-11-07T12:12:07.379853Z"
    },
    "papermill": {
     "duration": 0.046191,
     "end_time": "2023-11-07T12:12:07.382557",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.336366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2038,  0.0492, -0.3806,  ...,  0.1021,  0.0149, -0.1455],\n",
      "         [-0.1592,  0.0654, -0.3598,  ...,  0.0183,  0.0195, -0.2444],\n",
      "         [-0.2921,  0.0971, -0.3893,  ..., -0.0356,  0.0129, -0.1618],\n",
      "         ...,\n",
      "         [-0.2515,  0.1114, -0.3912,  ...,  0.1206, -0.0399, -0.2125],\n",
      "         [-0.1645,  0.1249, -0.4061,  ...,  0.0065,  0.0102, -0.2034],\n",
      "         [-0.2588,  0.1445, -0.3431,  ...,  0.0014, -0.1113, -0.1206]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Sample Usage: Multi-Head Attention\n",
    "\n",
    "'''\n",
    "\n",
    "# Every time will be different due to randomised weights\n",
    "multihead_attn = multiHeadAttention(config) # initialisation with config\n",
    "attn_output = multihead_attn(inputs_embeds) # forward by inputting embedding vectors (one for each token)\n",
    "\n",
    "# Attention output (attention weights matrix x vector weights concat)\n",
    "print(attn_output)\n",
    "print(attn_output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2aebb7",
   "metadata": {
    "papermill": {
     "duration": 0.01628,
     "end_time": "2023-11-07T12:12:07.415605",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.399325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>4 |</span></b> <b>FEED FORWARD LAYER</b></div>\n",
    "\n",
    "**position-wise feed-forward layer**\n",
    "\n",
    "The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">feed-forward</mark>** sublayer in the encoder & decoder\n",
    "- **two layer fully connected neural network**\n",
    "\n",
    "\n",
    "However, instead of processing the whole sequence of embedding as a single vector, \n",
    "- it **processes each embedding** independently\n",
    "- Also see it referred to as a Conv1D with a kernel size of 1 (people with a CV background)\n",
    "\n",
    "\n",
    "The **hidden size** of the **1st layer = 4x size of the embeddings** & **GELU activation function**\n",
    "- Place where most of the capacity & memorization is hypothesized to happen\n",
    "- It is most often scaled, when scaling up the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab0da5c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.450016Z",
     "iopub.status.busy": "2023-11-07T12:12:07.449132Z",
     "iopub.status.idle": "2023-11-07T12:12:07.454841Z",
     "shell.execute_reply": "2023-11-07T12:12:07.454256Z"
    },
    "papermill": {
     "duration": 0.024374,
     "end_time": "2023-11-07T12:12:07.456328",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.431954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class feedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.linear2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    # define layer operations input x\n",
    "        \n",
    "    def forward(self, x):    # note must be forward\n",
    "        x = self.gelu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51b36e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.489862Z",
     "iopub.status.busy": "2023-11-07T12:12:07.489589Z",
     "iopub.status.idle": "2023-11-07T12:12:07.544434Z",
     "shell.execute_reply": "2023-11-07T12:12:07.543744Z"
    },
    "papermill": {
     "duration": 0.073582,
     "end_time": "2023-11-07T12:12:07.546107",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.472525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedForward(\n",
      "  (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (gelu): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0071, -0.0288, -0.0209,  ..., -0.0377,  0.0024,  0.0379],\n",
       "         [-0.0073, -0.0401, -0.0253,  ..., -0.0378,  0.0008,  0.0478],\n",
       "         [-0.0096, -0.0413, -0.0249,  ..., -0.0399,  0.0034,  0.0415],\n",
       "         ...,\n",
       "         [-0.0012, -0.0281, -0.0072,  ..., -0.0367,  0.0085,  0.0444],\n",
       "         [ 0.0059, -0.0000, -0.0209,  ..., -0.0402,  0.0091,  0.0407],\n",
       "         [ 0.0013, -0.0234, -0.0095,  ..., -0.0388,  0.0076,  0.0386]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initailise feedforward layer\n",
    "feed_forward = feedForward(config)              # initialise \n",
    "print(feed_forward,'\\n')\n",
    "\n",
    "# requires config & attn_outputs outputs\n",
    "ff_outputs = feed_forward(attn_output) # forward operation\n",
    "ff_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2fc03c",
   "metadata": {
    "papermill": {
     "duration": 0.016237,
     "end_time": "2023-11-07T12:12:07.579139",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.562902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>5 |</span></b> <b>NORMALISATION LAYERS</b></div>\n",
    "\n",
    "Transformer architecture also uses **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">layer normalisation</mark>** & **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">skip connections</mark>**\n",
    "- **normalisation** - normalises batch input to have zero mean & unit variance\n",
    "- **skip connections** - pass a tensor to the next level of the model w/o processing & adding it to the processed tensor\n",
    "\n",
    "Two main approaches, when it comes to normalisation layer placement in decoder, encoder:\n",
    "- **post layer** normalisation (transformer paper, layer normalisation b/w skip connections)\n",
    "- **pre layer** normalisation \n",
    "\n",
    "<br>\n",
    "\n",
    "| `post-layer` normalisation |  `pre-layer` normalisation in literature |\n",
    "| - | - |\n",
    "| Arrangement is tricky to train from scractch, as the gradients can diverge |  Most often found arrangement\n",
    "| Used with LR warm up (learning rate gradually increased, from small value to some maximum value during training) | Places layer normalization within the span of the skip connection |\n",
    "|  | Tends to be much more stable during training, and it does not usually require any learning rate warm-up |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc50d01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.613606Z",
     "iopub.status.busy": "2023-11-07T12:12:07.612856Z",
     "iopub.status.idle": "2023-11-07T12:12:07.618561Z",
     "shell.execute_reply": "2023-11-07T12:12:07.617989Z"
    },
    "papermill": {
     "duration": 0.024708,
     "end_time": "2023-11-07T12:12:07.620134",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.595426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class encoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = multiHeadAttention(config)    # multihead attention layer \n",
    "        self.feed_forward = feedForward(config)        # feed forward layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Apply layer norm. to hidden state, copy input into query, key, value\n",
    "        # Apply attention with a skip connection\n",
    "        x = x + self.attention(self.norm1(x))\n",
    "        \n",
    "        # Apply feed-forward layer with a skip connection\n",
    "        x = x + self.feed_forward(self.norm2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcecb13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.655181Z",
     "iopub.status.busy": "2023-11-07T12:12:07.654374Z",
     "iopub.status.idle": "2023-11-07T12:12:07.719063Z",
     "shell.execute_reply": "2023-11-07T12:12:07.718146Z"
    },
    "papermill": {
     "duration": 0.08428,
     "end_time": "2023-11-07T12:12:07.721179",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.636899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoderLayer(\n",
      "  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attention): multiHeadAttention(\n",
      "    (heads): ModuleList(\n",
      "      (0-11): 12 x Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (out_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (feed_forward): feedForward(\n",
      "    (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (gelu): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ") \n",
      "\n",
      "input torch.Size([1, 9, 768])\n",
      "output torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "# Transformer layer output\n",
    "encoder_layer = encoderLayer(config) # initialise encoder layer\n",
    "print(encoder_layer,'\\n')\n",
    "\n",
    "print('input',inputs_embeds.shape) \n",
    "print('output',encoder_layer(inputs_embeds).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7232eac0",
   "metadata": {
    "papermill": {
     "duration": 0.01686,
     "end_time": "2023-11-07T12:12:07.754870",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.738010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is an issue with the way we set up the **encoder layers** (which uses just embedding inputs)\n",
    "- they are totally **invariant to the position of the tokens**\n",
    "- Multi-head attention layer is effectively a weighted sum, the **information on token position is lost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ed26c",
   "metadata": {
    "papermill": {
     "duration": 0.016274,
     "end_time": "2023-11-07T12:12:07.787762",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.771488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>6 |</span></b> <b>POSITIONAL EMBEDDINGS</b></div>\n",
    "\n",
    "Let's incorporate positional information using **positional embeddings**\n",
    "\n",
    "\n",
    "**positional embeddings** are based on idea:\n",
    "  - Modify the **token embeddings** with a **position-dependent pattern** of values arranged in a vector\n",
    "  \n",
    "  \n",
    "If the pattern is characteristic for each position\n",
    "- the **attention heads** and **feed-forward layers** in each stack can learn to incorporate positional information into their transformations\n",
    "\n",
    "\n",
    "\n",
    "- There are several ways to achieve this, and one of the most popular approaches is to use a `learnable pattern`\n",
    "- This works exactly the same way as the token embeddings, but using the **position index** instead of the **token identifier** (from vocabulary dictionary) as input\n",
    "- An efficient way of encoding the positions of tokens is learned during pretraining\n",
    "\n",
    "Creating Custom `Embedding` class\n",
    "\n",
    "Let’s create a custom Embeddings module (**token embeddings + positional embeddings**)\n",
    " - That combines a token embedding layer that projects the input_ids to a dense hidden state \n",
    " - Together with the positional embedding that does the same for position_ids\n",
    " - The resulting embedding is simply the **sum of both embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "436fdf8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.823932Z",
     "iopub.status.busy": "2023-11-07T12:12:07.823592Z",
     "iopub.status.idle": "2023-11-07T12:12:07.831753Z",
     "shell.execute_reply": "2023-11-07T12:12:07.830873Z"
    },
    "papermill": {
     "duration": 0.02821,
     "end_time": "2023-11-07T12:12:07.833862",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.805652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Token + Position Embedding \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class tpEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):        \n",
    "        super().__init__()\n",
    "        \n",
    "        # token embedding layer\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size,\n",
    "                                             config.hidden_size)\n",
    "        \n",
    "        # positional embedding layer\n",
    "        # config.max_position_embeddings -> max number of positions in text 512 (tokens)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
    "                                                config.hidden_size)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \n",
    "        # Create position IDs for input sequence\n",
    "        seq_length = input_ids.size(1) # number of tokens\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long)[None,:] # range(0,9)\n",
    "        \n",
    "        # tensor([[ 1996, 11286,  1997,  1037,  5340,  3392,  2003,  2200,  5931]])\n",
    "        # tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8]])\n",
    "        \n",
    "        # Create token and position embeddings\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # Combine token and position embeddings\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        \n",
    "        # Add normalisation & dropout layers\n",
    "        embeddings = self.norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1eb5779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.870017Z",
     "iopub.status.busy": "2023-11-07T12:12:07.869347Z",
     "iopub.status.idle": "2023-11-07T12:12:08.024643Z",
     "shell.execute_reply": "2023-11-07T12:12:08.023751Z"
    },
    "papermill": {
     "duration": 0.175058,
     "end_time": "2023-11-07T12:12:08.026668",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.851610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.0403, -0.0000,  1.1722,  ..., -1.6743, -3.0759, -0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0780, -1.9838],\n",
       "         [ 2.4112, -0.0000,  0.9230,  ...,  0.0000, -3.2554, -3.6100],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000, -1.9303,  ...,  1.7901, -2.4660, -0.0000],\n",
       "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  2.1861, -0.9021],\n",
       "         [-0.0000,  0.0000, -5.8991,  ...,  0.0209,  0.0000, -0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token and Position Embeddings\n",
    "embedding_layer = tpEmbedding(config)\n",
    "embedding_layer(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae2413",
   "metadata": {
    "papermill": {
     "duration": 0.016522,
     "end_time": "2023-11-07T12:12:08.060364",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.043842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>7 |</span></b> <b>PUTTING IT ALL TOGETHER</b></div>\n",
    "\n",
    "- Constructing the Transformer **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">encoder</mark>**, combining the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">Embedding</mark>** and **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">Encoder</mark>**  layers\n",
    "- We utilise both **token** & **positional** embeddings using `tpEmbedding`\n",
    "- For a given number of heads, we store `encoderLayer`, which contains the **attention** & **feed-forward** layers (which are our layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6f1e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:08.094928Z",
     "iopub.status.busy": "2023-11-07T12:12:08.094587Z",
     "iopub.status.idle": "2023-11-07T12:12:08.100489Z",
     "shell.execute_reply": "2023-11-07T12:12:08.099664Z"
    },
    "papermill": {
     "duration": 0.024909,
     "end_time": "2023-11-07T12:12:08.102005",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.077096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full transformer encoder combining the `Embedding` with the ``Embedding` ` layers\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):       \n",
    "        super().__init__()\n",
    "        \n",
    "        # token & positional embedding layer\n",
    "        self.embeddings = tpEmbedding(config)\n",
    "        \n",
    "        # attention & forward feed layer \n",
    "        self.layers = nn.ModuleList([encoderLayer(config)\n",
    "                                     for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # embeddings layer output\n",
    "        x = self.embeddings(x)\n",
    "        \n",
    "        # cycle through all heads\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bbadb05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:08.136166Z",
     "iopub.status.busy": "2023-11-07T12:12:08.135908Z",
     "iopub.status.idle": "2023-11-07T12:12:08.948737Z",
     "shell.execute_reply": "2023-11-07T12:12:08.948016Z"
    },
    "papermill": {
     "duration": 0.831712,
     "end_time": "2023-11-07T12:12:08.950315",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.118603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6233, -0.7978, -2.4776,  ..., -0.4364, -0.0118, -1.8506],\n",
       "         [-3.6226, -1.5029,  0.7667,  ..., -1.8732,  3.5305, -2.8063],\n",
       "         [ 0.4178,  1.5879, -0.8017,  ..., -3.4680, -0.4882, -3.1883],\n",
       "         ...,\n",
       "         [ 0.2196, -0.0766,  2.8025,  ...,  3.6958,  0.7566, -4.5964],\n",
       "         [ 0.4364,  1.1692, -0.8789,  ...,  1.1547,  4.6363, -1.0828],\n",
       "         [ 1.8008, -1.3734, -2.4738,  ...,  0.4895, -0.9201, -3.4636]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoder initialisation & output\n",
    "encoder = TransformerEncoder(config)\n",
    "encoder_output = encoder(inputs.input_ids)\n",
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50cb84d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:08.986890Z",
     "iopub.status.busy": "2023-11-07T12:12:08.985912Z",
     "iopub.status.idle": "2023-11-07T12:12:08.991281Z",
     "shell.execute_reply": "2023-11-07T12:12:08.990709Z"
    },
    "papermill": {
     "duration": 0.024749,
     "end_time": "2023-11-07T12:12:08.992754",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.968005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden state for each token in a batch\n",
    "encoder_output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4161345",
   "metadata": {
    "papermill": {
     "duration": 0.016716,
     "end_time": "2023-11-07T12:12:09.026352",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.009636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>8 |</span></b> <b>CLASSIFICATION HEAD</b></div>\n",
    "\n",
    "Quite often, transformers are divided into:\n",
    "- Task independent body (`TransformerEncoder`)\n",
    "- Task dependent head (`TransformerClassifier`)\n",
    "\n",
    "Select one of the token outputs:\n",
    "- The first token in such models is often used for the prediction **[CLS] token**\n",
    "- Can attach a `dropout` and a `linear` transformation layer to make a classification prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50466a72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:09.063655Z",
     "iopub.status.busy": "2023-11-07T12:12:09.063083Z",
     "iopub.status.idle": "2023-11-07T12:12:09.068612Z",
     "shell.execute_reply": "2023-11-07T12:12:09.068049Z"
    },
    "papermill": {
     "duration": 0.025845,
     "end_time": "2023-11-07T12:12:09.070128",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.044283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        \n",
    "        # Classification Head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[:, 0, :] # select hidden state of [CLS] token\n",
    "        x = self.dropout(x)\n",
    "#         x = self.classifier(x) # 768 -> 3 \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a5f09",
   "metadata": {
    "papermill": {
     "duration": 0.016599,
     "end_time": "2023-11-07T12:12:09.103550",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.086951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- For each sample in the batch we get the **unnormalized logits** for each class in the output, which corresponds to the BERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74c29271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:09.138526Z",
     "iopub.status.busy": "2023-11-07T12:12:09.138069Z",
     "iopub.status.idle": "2023-11-07T12:12:10.191689Z",
     "shell.execute_reply": "2023-11-07T12:12:10.191034Z"
    },
    "papermill": {
     "duration": 1.073469,
     "end_time": "2023-11-07T12:12:10.193779",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.120310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.1553e-01, -1.7779e+00, -3.4208e-02, -1.5725e+00,  1.5272e+00,\n",
       "          5.5688e-02,  2.1623e+00, -9.2517e-01,  4.2432e+00,  1.0977e+00,\n",
       "          7.2258e-01,  2.9132e-01,  6.5986e-01, -2.9696e+00, -2.3944e-01,\n",
       "          7.3569e-01,  5.1722e-02, -1.4560e+00, -1.2628e+00, -3.4061e-01,\n",
       "         -5.0842e-01,  1.3868e+00, -1.7132e+00, -9.0613e-01,  8.9519e-01,\n",
       "          2.3405e-02, -0.0000e+00,  0.0000e+00,  2.9278e+00,  3.6302e-01,\n",
       "          8.1827e+00, -1.7514e+00, -1.0893e-01,  7.3937e-01,  6.2112e+00,\n",
       "          1.8388e+00,  1.0489e+00,  0.0000e+00, -3.0690e-01,  3.2668e+00,\n",
       "         -2.5848e-01,  2.1166e-01, -2.9154e-01, -9.5935e-01,  1.0442e+00,\n",
       "          2.5670e+00,  4.2931e+00, -6.0419e-01, -1.0419e+00, -0.0000e+00,\n",
       "         -1.6406e+00,  3.1523e+00,  0.0000e+00, -9.6796e-01,  4.7432e+00,\n",
       "         -1.3599e+00,  2.0513e+00, -1.1294e+00, -2.6898e+00, -9.1189e-01,\n",
       "          1.0854e+00, -1.3970e+00, -2.7155e+00, -5.8152e+00, -0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  5.2163e-01,  3.9960e+00, -2.0367e+00,\n",
       "          2.1635e+00, -0.0000e+00, -1.2469e+00,  2.0678e-01, -2.8911e+00,\n",
       "         -3.3194e-01,  1.3749e+00, -1.5924e+00,  2.9928e-01,  4.5182e+00,\n",
       "          2.4715e-01,  1.8851e+00, -0.0000e+00,  6.3173e-01,  4.0984e+00,\n",
       "          1.2747e+00,  1.1808e+00,  8.5775e-01,  2.6918e-01, -5.6975e-01,\n",
       "          3.9663e-01, -2.4811e+00,  6.9491e-01, -4.2416e-01,  3.1886e+00,\n",
       "         -2.5580e+00, -1.8114e+00,  2.3578e+00,  1.6497e+00, -3.8802e+00,\n",
       "         -9.2340e-01, -7.8336e-01, -1.1197e+00,  0.0000e+00,  3.7501e-01,\n",
       "          3.7780e-01, -1.3282e+00, -0.0000e+00, -1.1100e+00, -1.6576e+00,\n",
       "         -4.4977e-01,  4.4545e-01, -1.9972e+00,  0.0000e+00, -1.2676e+00,\n",
       "          1.2899e+00,  9.1478e-01, -5.1516e-01,  0.0000e+00,  2.3717e-01,\n",
       "          3.7520e-01,  3.2646e-01, -1.9226e+00, -2.6644e-01,  6.5408e-02,\n",
       "          2.3406e-01, -1.1663e+00, -5.1070e-01, -4.5879e-01,  0.0000e+00,\n",
       "          9.8267e-01,  0.0000e+00,  7.4310e-01,  4.5586e-01, -4.9034e-01,\n",
       "         -0.0000e+00,  1.2221e+00,  5.1767e-02, -0.0000e+00,  4.4957e+00,\n",
       "         -3.4220e-01,  1.0049e+00,  1.7533e-01, -2.3019e-01, -1.4463e-01,\n",
       "          3.9850e+00, -1.2005e+00,  0.0000e+00, -0.0000e+00,  8.7356e-01,\n",
       "          5.9518e-01,  2.2412e+00,  3.1252e-01,  0.0000e+00, -7.9096e-01,\n",
       "         -9.4307e-01,  8.2380e-01,  1.5063e+00, -0.0000e+00,  3.5677e+00,\n",
       "          5.1475e-02,  4.1697e-01, -2.4545e+00,  7.1446e-01,  0.0000e+00,\n",
       "         -2.2412e+00,  3.4916e-01,  4.4705e-01,  5.2161e-01, -1.2533e+00,\n",
       "          1.7962e+00, -6.6468e-01,  1.7104e+00,  0.0000e+00, -4.6331e+00,\n",
       "         -2.3049e-02, -1.4408e+00,  1.3281e+00,  6.6857e-01,  2.2950e+00,\n",
       "          7.4079e-01,  0.0000e+00, -2.8768e+00, -4.4533e-01, -2.3869e+00,\n",
       "         -4.5429e+00, -7.2933e-01, -4.8842e-01,  5.7087e-01,  0.0000e+00,\n",
       "          6.6341e-02,  0.0000e+00, -2.5282e+00, -2.9266e+00,  5.4695e-01,\n",
       "          6.7780e-01,  3.8695e+00,  0.0000e+00, -4.5546e-01,  1.3973e+00,\n",
       "          0.0000e+00, -2.2727e+00, -1.4689e-01,  9.2738e-01, -1.0313e-01,\n",
       "         -0.0000e+00, -1.7526e+00, -1.0764e+00, -2.6860e+00,  1.6257e-02,\n",
       "          8.7452e-01,  1.8663e-01,  1.3555e+00,  1.1354e+00,  2.2239e+00,\n",
       "         -6.1232e-02,  1.0294e-01, -1.2706e+00,  1.6489e+00,  1.1290e+00,\n",
       "         -7.2783e-01,  0.0000e+00, -8.6633e-01, -6.8347e-01,  9.7548e-01,\n",
       "         -1.7727e+00, -4.3968e-01, -2.3774e+00,  7.5328e-01,  1.8980e+00,\n",
       "         -0.0000e+00,  7.7675e-01, -1.7363e-01,  3.8761e+00,  1.5194e+00,\n",
       "         -2.9981e-02,  0.0000e+00, -3.2643e-01, -5.4945e-01,  3.6521e+00,\n",
       "         -0.0000e+00, -2.4841e+00,  2.1243e+00,  0.0000e+00, -2.4589e+00,\n",
       "         -1.8124e+00,  5.7094e+00,  1.8733e+00, -4.5905e-01,  1.2490e+00,\n",
       "         -1.7885e+00,  0.0000e+00,  1.0738e+00, -9.5495e-01,  2.0938e+00,\n",
       "          4.5585e+00,  1.4121e+00, -1.4152e+00, -8.6751e-01,  5.2195e-01,\n",
       "         -1.5637e+00,  5.2337e-01, -5.7905e-02, -3.5421e-02, -9.3161e-01,\n",
       "          1.4342e-01,  2.9780e-01,  1.6441e-01, -1.6257e+00, -2.2809e-01,\n",
       "         -5.3345e-01, -7.2258e-01, -1.5847e+00,  3.4668e-01,  7.8105e-01,\n",
       "         -5.7963e-01, -7.9617e-01,  4.2920e-01, -7.6509e+00, -5.6029e-01,\n",
       "         -9.5981e-01, -6.1542e-01, -1.1948e+00, -0.0000e+00,  2.1584e-01,\n",
       "          1.1311e+00, -1.4582e+00, -8.7321e-01, -0.0000e+00, -1.1089e+00,\n",
       "         -1.2639e+00,  7.2546e-01, -2.8605e+00, -1.7032e+00,  2.8695e+00,\n",
       "          9.6728e-01,  3.7019e-01, -6.4679e-01,  2.5862e+00,  2.9746e+00,\n",
       "          1.8187e+00, -2.3922e-01,  4.8819e-01, -8.2596e-03, -2.9777e-01,\n",
       "          2.1981e+00, -1.5763e+00,  3.3154e-01, -3.0426e-01,  5.2551e-01,\n",
       "          3.6907e+00,  2.2850e+00, -7.7463e-01,  2.6416e+00,  0.0000e+00,\n",
       "         -5.9176e-01,  0.0000e+00, -0.0000e+00, -1.9811e+00, -1.6407e+00,\n",
       "          1.0065e+00, -5.7738e-01,  9.3319e-01,  2.3776e+00,  2.4359e+00,\n",
       "          1.9704e+00, -2.4063e+00, -2.2741e+00,  0.0000e+00, -4.9288e-01,\n",
       "          1.5338e+00, -7.9952e-01,  4.7835e-01,  2.5875e+00, -4.9167e-01,\n",
       "          4.9096e-02, -1.6042e+00, -4.0667e-01, -1.6601e-01,  9.1362e-01,\n",
       "          1.5737e+00,  3.3127e-01,  3.6308e+00, -1.0859e+00, -1.3562e+00,\n",
       "          1.3354e+00,  0.0000e+00, -2.1120e+00, -1.6732e+00,  1.7822e+00,\n",
       "         -1.8662e+00, -1.0969e-01, -4.0738e+00, -2.8166e-01, -1.4568e+00,\n",
       "          2.6243e+00, -1.9062e+00,  1.5299e+00, -0.0000e+00, -6.4092e-01,\n",
       "         -2.6210e-01, -3.1385e+00, -2.9296e+00, -5.0857e-01,  1.0223e+00,\n",
       "          3.0165e-01,  4.7707e-01,  6.5041e-01, -0.0000e+00, -1.6240e-01,\n",
       "          2.1502e+00, -9.2995e-01, -7.5582e-01, -3.9383e+00, -1.5941e-01,\n",
       "          1.7571e+00,  2.5125e-01, -0.0000e+00,  1.5278e+00, -3.4467e+00,\n",
       "         -1.0665e-02, -1.5723e+00,  2.6382e-01,  1.5762e+00,  1.6009e+00,\n",
       "         -2.8600e-01, -1.6064e+00, -4.8345e-01,  7.9330e-01, -1.1581e-02,\n",
       "          4.6046e+00,  2.1813e+00, -2.0197e+00,  2.6054e+00,  4.7500e-01,\n",
       "         -1.0990e+00, -5.5891e-01, -5.4976e-02, -4.2296e+00,  1.5062e-01,\n",
       "          2.8047e+00,  1.3004e+00,  0.0000e+00,  9.3354e-01,  2.3822e-01,\n",
       "         -8.3792e-01,  2.3545e-01,  1.7388e+00,  3.9058e+00,  1.3422e+00,\n",
       "          0.0000e+00,  8.0474e-02,  1.1877e-01,  2.0569e+00, -5.9923e-01,\n",
       "         -1.5395e+00, -1.3263e+00, -2.4398e+00, -1.2321e-02, -1.0168e+00,\n",
       "          3.4020e-01, -3.4028e+00, -9.2714e-01,  5.7534e-01,  1.9490e+00,\n",
       "          6.1380e-01, -4.0228e+00,  2.9129e+00, -3.0118e+00,  4.6423e-01,\n",
       "          0.0000e+00, -1.1270e-01, -7.5002e-01, -9.3956e+00,  1.1958e+00,\n",
       "          2.2136e+00, -0.0000e+00,  7.9041e-01,  2.1749e+00,  0.0000e+00,\n",
       "         -7.6184e-01, -3.9982e+00, -7.1748e+00,  0.0000e+00, -1.5125e+00,\n",
       "          0.0000e+00, -1.3467e+00, -3.1608e+00, -3.3239e+00, -1.3264e+00,\n",
       "          2.1136e+00,  3.8054e+00,  1.6273e+00, -1.6231e+00,  1.7325e+00,\n",
       "         -0.0000e+00, -1.8391e-01,  9.4087e-01, -7.2550e-01,  6.7369e-01,\n",
       "         -3.0709e-01, -1.5660e+00, -1.8160e+00, -0.0000e+00,  4.3260e+00,\n",
       "          6.1521e-01, -6.3040e-01,  2.3405e+00,  4.1544e-01,  1.0337e+00,\n",
       "          6.8843e-01,  3.9437e-01,  1.6638e+00, -6.5247e-01, -1.6561e+00,\n",
       "         -0.0000e+00,  5.5789e-01, -4.3549e-01, -4.5834e+00, -1.0779e+00,\n",
       "          5.9968e-01, -2.2890e-01, -3.9087e-01,  2.0539e+00, -1.1375e+00,\n",
       "          4.2395e-01, -2.6026e-01, -3.2794e-01,  4.1245e-01,  2.6443e+00,\n",
       "          1.2383e+00,  2.3526e+00, -0.0000e+00, -1.0971e+00,  4.1195e-01,\n",
       "         -1.9552e-01,  1.2049e+00,  1.5601e+00,  2.0641e-01, -3.3213e+00,\n",
       "          1.3954e+00, -1.9802e+00,  3.0425e+00,  0.0000e+00, -5.0158e-01,\n",
       "         -0.0000e+00, -1.7985e+00, -2.8736e-01,  9.8787e-01, -1.6399e-01,\n",
       "         -1.5808e+00,  1.8435e+00, -0.0000e+00,  2.0201e+00, -1.4515e+00,\n",
       "          2.8333e+00, -1.4581e+00,  0.0000e+00, -1.3885e+00, -2.0840e-01,\n",
       "         -1.1041e+00,  5.3391e-01,  0.0000e+00,  1.0518e+00,  2.4800e+00,\n",
       "         -2.7367e+00, -2.1395e+00,  6.2691e-01, -2.9026e+00,  4.4300e+00,\n",
       "          2.6431e-01,  6.7903e-01, -4.1395e+00,  1.1496e+00,  2.4196e-01,\n",
       "          1.1113e+00,  2.1393e-01,  7.0099e-01,  5.8019e-01, -4.4656e+00,\n",
       "         -6.2367e-01, -4.7281e-02,  6.2956e-01,  1.0074e+00,  1.9811e+00,\n",
       "          3.8159e+00, -9.7962e-02, -1.0982e-01,  3.6351e-01, -4.9218e-02,\n",
       "         -1.2404e+00,  1.0385e+00,  0.0000e+00,  0.0000e+00,  7.7056e-01,\n",
       "         -4.6504e-02,  0.0000e+00,  3.0084e-01,  3.5557e-01, -2.4259e+00,\n",
       "         -5.8283e-01,  2.0430e+00, -4.4414e+00,  9.6688e-02,  0.0000e+00,\n",
       "          3.1345e-01,  4.5101e+00, -3.5614e+00,  6.0918e+00,  2.1563e+00,\n",
       "          1.8549e+00,  1.7521e+00, -3.7184e-01, -1.2996e+00, -3.1278e+00,\n",
       "         -4.8464e-01, -2.4028e-01, -1.3511e+00,  1.8404e+00, -1.6907e+00,\n",
       "         -0.0000e+00, -3.6715e+00, -5.3783e+00,  4.4821e-01,  9.3456e-01,\n",
       "         -0.0000e+00, -1.5835e-01, -1.4207e+00, -1.6846e+00, -1.8207e+00,\n",
       "          1.9085e+00, -0.0000e+00,  3.2797e-01, -5.9432e-01,  2.5785e-01,\n",
       "         -3.0104e-01, -1.2298e+00,  5.7092e-01,  1.4489e+00, -1.7241e+00,\n",
       "         -3.4168e-01, -2.0842e+00, -1.1886e+00, -8.1624e-01, -0.0000e+00,\n",
       "          2.5508e+00,  0.0000e+00,  5.7439e-01,  9.6390e-01, -2.5983e-01,\n",
       "          5.8783e-01,  4.7859e-01,  3.8944e+00, -2.2158e+00, -1.8900e-01,\n",
       "         -1.3294e+00,  1.5722e+00, -7.3455e-02,  3.2419e+00,  6.3366e-01,\n",
       "          2.7712e+00,  3.2947e+00, -1.7163e+00,  6.1393e-01,  2.8546e+00,\n",
       "          3.9537e+00, -5.8689e-01,  1.5014e+00,  6.0680e+00, -1.2651e+00,\n",
       "          3.7737e+00, -5.0210e-01,  1.0136e+00,  1.2989e-01,  5.2093e-01,\n",
       "         -2.1768e+00, -2.3315e+00,  2.7214e-02, -1.9413e-01, -3.9145e+00,\n",
       "          4.8257e-01, -3.5968e+00,  3.5588e-01, -7.4633e-01,  6.2428e-01,\n",
       "          0.0000e+00,  1.4053e+00,  6.6922e+00,  1.0409e+00, -3.4299e+00,\n",
       "          1.6669e+00,  0.0000e+00,  5.0086e-01, -6.2916e+00, -1.1645e+00,\n",
       "         -1.8795e-01, -4.7711e+00, -5.6235e+00,  1.0462e-01,  0.0000e+00,\n",
       "         -3.3855e+00, -1.2584e-01,  7.5132e-01, -5.1418e-01, -7.9072e-02,\n",
       "         -1.3669e+00, -8.2071e-02,  2.2745e+00,  4.7597e-02, -1.1313e+00,\n",
       "          1.3444e+00,  2.2927e-01, -5.5693e+00,  8.6745e-01, -1.4935e+00,\n",
       "          5.8608e-01, -1.7820e+00,  4.2953e-01,  5.5088e-01,  7.8915e-01,\n",
       "         -3.6056e-01,  3.2404e-01,  1.9725e+00,  8.4205e-01,  2.4060e+00,\n",
       "          1.9824e+00,  0.0000e+00, -5.2479e-01,  4.4190e+00,  0.0000e+00,\n",
       "         -0.0000e+00, -1.2909e+00,  2.0007e-01,  8.0283e-01, -9.8414e-01,\n",
       "         -1.5923e+00, -7.0970e-01,  8.1567e-02, -1.7892e+00, -4.0984e+00,\n",
       "         -0.0000e+00,  4.2409e-01, -1.1037e-01,  2.6810e-02,  2.7929e+00,\n",
       "         -1.3581e+00, -1.4272e+00,  4.5590e+00,  1.4864e+00,  2.5795e-01,\n",
       "         -1.7189e+00, -2.0648e+00, -1.6002e+00,  3.3985e+00,  1.5326e+00,\n",
       "          1.4183e+00,  5.6709e-01, -8.0095e-01, -4.1657e-01,  2.1727e+00,\n",
       "          1.5316e+00,  1.4007e+00,  2.9690e+00, -3.1193e+00, -5.4649e-01,\n",
       "         -1.7358e+00, -6.1068e-01,  2.1238e+00, -7.3485e-01, -1.7075e-01,\n",
       "          2.9615e-02,  6.2984e-01,  1.0997e-01, -8.8476e+00, -1.0659e+00,\n",
       "         -1.1460e+00, -9.5554e-01, -3.4493e-01,  5.6766e+00,  4.9996e-01,\n",
       "          3.1927e-01, -9.3057e-01, -1.8540e+00,  6.4764e-01,  1.6296e-02,\n",
       "          1.4169e+00, -3.0865e+00, -8.0077e-01,  2.1591e+00, -7.5948e-01,\n",
       "          1.7373e+00,  7.2283e-01, -7.8982e-02,  7.5783e-01, -5.0699e-01,\n",
       "         -3.2662e-01,  2.1178e+00, -6.5913e-01, -2.0299e+00,  4.4490e+00,\n",
       "         -1.7604e+00, -1.3400e+00,  5.7211e-01,  1.3904e+00, -8.8917e-01,\n",
       "         -1.5312e+00, -6.4370e+00,  1.0731e+00]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.num_labels = 3\n",
    "encoder_classifier = TransformerClassifier(config)\n",
    "output = encoder_classifier(inputs.input_ids)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9203c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    output = encoder_classifier(inputs.input_ids)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e739be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.261257,
   "end_time": "2023-11-07T12:12:13.753168",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-07T12:11:25.491911",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f54ff68288a47e4ab08fe1bbfc33d55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_23e2a9ed016a4afcbce85d623df9d64e",
       "max": 28,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fa9b11bb2bba4257a632795bfe9f9b6e",
       "value": 28
      }
     },
     "0f6539d2bc1244888a6850ce92c31d4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ac3fe35df01454abc6b7a3bfdf4df94",
        "IPY_MODEL_dcad6910ef2b43e7a8001ab17ab10112",
        "IPY_MODEL_57bbb2ada9f0494aa4335a1418e1809e"
       ],
       "layout": "IPY_MODEL_79f1527694f74b80a5330cf6f99ea84e"
      }
     },
     "0fb39f643b2f4811be0d0c3409323d80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "17348793a7bb456bbb5ace7f13f537f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_98d3a93be64a4c01a2d1c98d00515f5a",
       "placeholder": "​",
       "style": "IPY_MODEL_4698dfa31864465ab5841f5b2d8c6e5c",
       "value": " 570/570 [00:00&lt;00:00, 25.3kB/s]"
      }
     },
     "1ac3fe35df01454abc6b7a3bfdf4df94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f5a281ae964e44528a7773b0213cb3a9",
       "placeholder": "​",
       "style": "IPY_MODEL_4c762ca4426949989ec3bf96ef853188",
       "value": "Downloading: 100%"
      }
     },
     "23e2a9ed016a4afcbce85d623df9d64e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c55c0d364b742ed8da1f4194e9d73db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ecc0ca0282a4b51a9f47f299ddb0e25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "402bec0969c2439d9fe12534438cfd18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4698dfa31864465ab5841f5b2d8c6e5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c762ca4426949989ec3bf96ef853188": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "508357fee53643ae9bbc41e2cbb0c6b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52ea49af22194ceeb7d0014756942b23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5653cd0054e34263946603a7d6c3e3b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "57bbb2ada9f0494aa4335a1418e1809e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_caf3de995ab1481fadb9cf72b9c573fc",
       "placeholder": "​",
       "style": "IPY_MODEL_0fb39f643b2f4811be0d0c3409323d80",
       "value": " 226k/226k [00:00&lt;00:00, 4.39MB/s]"
      }
     },
     "5865b31e0bf24e4e80dd75fa252761e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58ec168261d746b2a2a803f6a87449c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "656311e69fa04ec7b6ddb361d470b11b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67c471286bcd4dcbb385a93887879a02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "694fd1a41ff147edb6eb32dd33fdb7c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b365053df97498e956e67bbe6b9ccfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2ecc0ca0282a4b51a9f47f299ddb0e25",
       "placeholder": "​",
       "style": "IPY_MODEL_5653cd0054e34263946603a7d6c3e3b8",
       "value": "Downloading: 100%"
      }
     },
     "6d448241463c48228efdfbe658d57acf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6d59d2793acc4f30a0537f06d94c947b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "76a8d4885d704b68a49cc354bd98162d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_67c471286bcd4dcbb385a93887879a02",
       "placeholder": "​",
       "style": "IPY_MODEL_834207598a374281ab4b2457b33ac1f1",
       "value": "Downloading: 100%"
      }
     },
     "7909f11c3d9d4884bef998dc86c6c433": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_694fd1a41ff147edb6eb32dd33fdb7c7",
       "placeholder": "​",
       "style": "IPY_MODEL_402bec0969c2439d9fe12534438cfd18",
       "value": " 455k/455k [00:00&lt;00:00, 5.73MB/s]"
      }
     },
     "79f1527694f74b80a5330cf6f99ea84e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d3e823820b9404eb59a5fc22f235788": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7efc71dd48044f4182faee7196648d75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_656311e69fa04ec7b6ddb361d470b11b",
       "max": 570,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_52ea49af22194ceeb7d0014756942b23",
       "value": 570
      }
     },
     "834207598a374281ab4b2457b33ac1f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9444d2913a734d248a9741f3727b10f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98d3a93be64a4c01a2d1c98d00515f5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c01269053814648ac62141686c8ff2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a28f0dbdde2448c4b1a3290a62c43eba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6b365053df97498e956e67bbe6b9ccfd",
        "IPY_MODEL_7efc71dd48044f4182faee7196648d75",
        "IPY_MODEL_17348793a7bb456bbb5ace7f13f537f6"
       ],
       "layout": "IPY_MODEL_7d3e823820b9404eb59a5fc22f235788"
      }
     },
     "a80cfef718d84bc8967f53cdf83a5986": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_508357fee53643ae9bbc41e2cbb0c6b0",
       "max": 466062,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6d59d2793acc4f30a0537f06d94c947b",
       "value": 466062
      }
     },
     "acf742bc1b9b4f71ae1f9ec994d85847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b8784b0f034242d3b9551a4b45615e53",
       "placeholder": "​",
       "style": "IPY_MODEL_9c01269053814648ac62141686c8ff2a",
       "value": " 28.0/28.0 [00:00&lt;00:00, 1.15kB/s]"
      }
     },
     "b4e4504a77a3486b9f66e38cebc63182": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8784b0f034242d3b9551a4b45615e53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c067bf2601a84417bf052635a54ef790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ce198efee07e4dd582a7c889f3b5f6d9",
        "IPY_MODEL_a80cfef718d84bc8967f53cdf83a5986",
        "IPY_MODEL_7909f11c3d9d4884bef998dc86c6c433"
       ],
       "layout": "IPY_MODEL_9444d2913a734d248a9741f3727b10f9"
      }
     },
     "c61426e6570245e6b1c07b09149e61bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_76a8d4885d704b68a49cc354bd98162d",
        "IPY_MODEL_0f54ff68288a47e4ab08fe1bbfc33d55",
        "IPY_MODEL_acf742bc1b9b4f71ae1f9ec994d85847"
       ],
       "layout": "IPY_MODEL_5865b31e0bf24e4e80dd75fa252761e1"
      }
     },
     "caf3de995ab1481fadb9cf72b9c573fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce198efee07e4dd582a7c889f3b5f6d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2c55c0d364b742ed8da1f4194e9d73db",
       "placeholder": "​",
       "style": "IPY_MODEL_6d448241463c48228efdfbe658d57acf",
       "value": "Downloading: 100%"
      }
     },
     "dcad6910ef2b43e7a8001ab17ab10112": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b4e4504a77a3486b9f66e38cebc63182",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_58ec168261d746b2a2a803f6a87449c5",
       "value": 231508
      }
     },
     "f5a281ae964e44528a7773b0213cb3a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa9b11bb2bba4257a632795bfe9f9b6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
