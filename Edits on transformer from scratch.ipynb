{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e9a7e8",
   "metadata": {
    "papermill": {
     "duration": 0.009019,
     "end_time": "2023-11-07T12:11:42.558290",
     "exception": false,
     "start_time": "2023-11-07T12:11:42.549271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>1 |</span></b> <b>BACKGROUND</b></div>\n",
    "\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>ENCODER BASE</span></b></p></div>\n",
    "\n",
    "In the following notebook, we'll look at the following components of the Transformer Encoder structure\n",
    "\n",
    "<div style=\" background-color:#3b3745; padding: 13px 13px; border-radius: 8px; color: white\">\n",
    "    \n",
    "<ul>\n",
    "<li>Simple Attention</li>\n",
    "<li>Multi-Head Self Attention</li>\n",
    "<li>Feed Forward Layer</li>\n",
    "<li>Normalisation</li>\n",
    "<li>Skip Connection</li>\n",
    "<li>Position Embeddings</li>\n",
    "<li>Transformer Encoder</li>\n",
    "<li>Classifier Head</li>\n",
    "</ul> \n",
    "</div> \n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>ENCODER BASE</span></b></p></div>\n",
    "\n",
    "Encoder simply put:\n",
    "- Converts a **series tokens** into a **series of embedding vectors** (hidden state)\n",
    "- The encoder (neural network) consists of **multiple layers** (**blocks**) constructed together \n",
    "\n",
    "The encoder structure:\n",
    "- Composed of multiple encoder layers (blocks) stacked next to each other (similar to CNN layer stacks)\n",
    "- Each encoder block contains **multi-head self attention** & **fully connected feed forward layer** (for each input embedding)\n",
    "\n",
    "Purpose of the Encoder\n",
    "- Input tokens are encoded & modified into a form that **stores some contextual information** in the sequence\n",
    "\n",
    "The example we'll use:\n",
    "\n",
    "> the bark of a palm tree is very rough\n",
    "\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>CLASSIFICATION HEAD</span></b></p></div>\n",
    "\n",
    "- Transformers can be utilised for various application so they are created in a base form\n",
    "- If we want to utilise them for a specific task, we add an extra component **head** to the transformer\n",
    "- In this example, we'll utilise it for **classification** purposes, and look at how we can combine the base with the **head**\n",
    "\n",
    "\n",
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>2 |</span></b> <b>SIMPLE SELF ATTENTION</b></div>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>TYPES OF ATTENTION</span></b></p></div>\n",
    "\n",
    "**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention</mark>**\n",
    " \n",
    "- Mechanism which allows networks to assign **different weight distributions to each element** in a sequence \n",
    "- Elements in sequence - `token embeddings` (each token mapped to a vector of fixed dimension) (eg. BERT model - 768 dimensions)\n",
    " \n",
    " \n",
    "**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">self-attention</mark>**\n",
    "\n",
    "- Instead of using fixed embeddings for each token, can use whole sequence to **compute weighted average** of each `embedding`\n",
    "- One can think of self-attention as a form of averaging\n",
    "- Common form of `self-attention` **scaled dot-product attention** \n",
    "\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>FOUR MAIN STEPS</span></b></p></div>\n",
    "\n",
    "\n",
    "- Project each `token embedding` into three vectors **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">query</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">key</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>**\n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** (nxn)\n",
    "\n",
    "    - (we determine how much the query & key vectors relate to eachother using a similarity function)\n",
    "    - Similarity function for scaled dot-product attention - dot product\n",
    "    - queries & keys that are similar will have large dot product & visa versa\n",
    "    - Outputs from this step - attention scores\n",
    "    \n",
    "    \n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weight</mark>** (wij)\n",
    "\n",
    "    - dot products produce large numbers \n",
    "    - attention scores first multiplied by a scaling factor to normalise their variance\n",
    "    - Then normalised with softmax to ensure all column values sum to 1\n",
    "    \n",
    "    \n",
    "- Update the token embeddings (hidden state)\n",
    "\n",
    "    - multiply the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">weights</mark>** by the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>** vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55217be8",
   "metadata": {
    "papermill": {
     "duration": 0.009999,
     "end_time": "2023-11-07T12:11:42.577461",
     "exception": false,
     "start_time": "2023-11-07T12:11:42.567462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>SIMPLE ATTENTION FORMULATION</span></b></p></div>\n",
    "\n",
    "\n",
    "- Well look at a simple example, and summarise the attention mechanism in one function\n",
    "- `bert-base-uncased` model will be used to extract different model settings (eg. number of attention heads), so we will be building a similar model \n",
    "\n",
    "<br>\n",
    "\n",
    "##### **1. DOCUMENT TOKENISATION**\n",
    "\n",
    "- Each token in the sentence has been mapped to a **unique identifier** from a **vocabulary** or **dictionary**\n",
    "- We start off by using the `bert-base-uncased` pretrained tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35551bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:11:42.597284Z",
     "iopub.status.busy": "2023-11-07T12:11:42.596990Z",
     "iopub.status.idle": "2023-11-07T12:12:00.483141Z",
     "shell.execute_reply": "2023-11-07T12:12:00.482187Z"
    },
    "papermill": {
     "duration": 17.898714,
     "end_time": "2023-11-07T12:12:00.485317",
     "exception": false,
     "start_time": "2023-11-07T12:11:42.586603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from bertviz.transformers_neuron_view import BertModel\n",
    "\n",
    "# load tokeniser and model\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = BertModel.from_pretrained(model_ckpt)\n",
    "\n",
    "# document well be using as an exmaple\n",
    "text = \"the bark of a palm tree is very rough\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63f10c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:00.517236Z",
     "iopub.status.busy": "2023-11-07T12:12:00.516931Z",
     "iopub.status.idle": "2023-11-07T12:12:00.533190Z",
     "shell.execute_reply": "2023-11-07T12:12:00.532308Z"
    },
    "papermill": {
     "duration": 0.034096,
     "end_time": "2023-11-07T12:12:00.535098",
     "exception": false,
     "start_time": "2023-11-07T12:12:00.501002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1996, 11286,  1997,  1037,  5340,  3392,  2003,  2200,  5931]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenise input (text)\n",
    "inputs = tokenizer(text, \n",
    "                   return_tensors=\"pt\",      # pytorc tensor\n",
    "                   add_special_tokens=False) # don't use pad, sep tokens\n",
    "\n",
    "print(inputs.input_ids)\n",
    "inputs.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fcb56d7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:00.568327Z",
     "iopub.status.busy": "2023-11-07T12:12:00.568012Z",
     "iopub.status.idle": "2023-11-07T12:12:06.186950Z",
     "shell.execute_reply": "2023-11-07T12:12:06.186030Z"
    },
    "papermill": {
     "duration": 5.637794,
     "end_time": "2023-11-07T12:12:06.188698",
     "exception": false,
     "start_time": "2023-11-07T12:12:00.550904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the bark of a palm tree is very rough'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode sequence\n",
    "tokenizer.decode(inputs['input_ids'].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e975fd",
   "metadata": {
    "papermill": {
     "duration": 0.014971,
     "end_time": "2023-11-07T12:12:06.218934",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.203963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At this point:\n",
    "\n",
    "- `inputs.inpits_ids` A tensor of id mapped tokens\n",
    "- Token embeddings are **independent of their context**\n",
    "- **Homonyms** (same spelling, but different meaning) have the same representation\n",
    "\n",
    "Role of subsequent attention layers:\n",
    "\n",
    "- Mix the **token embeddings** to disambiguate & inform the representation of each token with the context of its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f8859aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.251254Z",
     "iopub.status.busy": "2023-11-07T12:12:06.250611Z",
     "iopub.status.idle": "2023-11-07T12:12:06.511660Z",
     "shell.execute_reply": "2023-11-07T12:12:06.510800Z"
    },
    "papermill": {
     "duration": 0.279247,
     "end_time": "2023-11-07T12:12:06.513439",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.234192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 hidden size\n",
      "30522 vocabulary size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Create an embedding layer\n",
    "\n",
    "'''\n",
    "\n",
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "\n",
    "print(config.hidden_size,\"hidden size\")\n",
    "print(config.vocab_size,\"vocabulary size\")\n",
    "\n",
    "# load sample embedding layer of size (30522,758) -> same as bert-base\n",
    "token_emb = nn.Embedding(config.vocab_size,\n",
    "                         config.hidden_size)\n",
    "token_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee78d5",
   "metadata": {
    "papermill": {
     "duration": 0.015119,
     "end_time": "2023-11-07T12:12:06.544245",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.529126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **2. EMBEDDING VECTORS**\n",
    "\n",
    "\n",
    "- Convert Tokenised data into embedding data (768 dimensions) using vocab of 30522 tokens\n",
    "- Each input_ids is **mapped to one of 30522 embedding vectors** stored in nn.embedding, each with a size of 768 \n",
    "- Our output will be [batch_size,seq_len,hidden_dim] by calling `nn.Embedding(hidden)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd751b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.576500Z",
     "iopub.status.busy": "2023-11-07T12:12:06.576191Z",
     "iopub.status.idle": "2023-11-07T12:12:06.586332Z",
     "shell.execute_reply": "2023-11-07T12:12:06.585567Z"
    },
    "papermill": {
     "duration": 0.028427,
     "end_time": "2023-11-07T12:12:06.588032",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.559605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Convert Tokens to Embedding Vectors\n",
    "utilising the existing model embedding embeddings\n",
    "\n",
    "'''\n",
    "\n",
    "inputs_embeds = token_emb(inputs.input_ids)\n",
    "inputs_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3feb8277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.620723Z",
     "iopub.status.busy": "2023-11-07T12:12:06.620434Z",
     "iopub.status.idle": "2023-11-07T12:12:06.627221Z",
     "shell.execute_reply": "2023-11-07T12:12:06.626491Z"
    },
    "papermill": {
     "duration": 0.024936,
     "end_time": "2023-11-07T12:12:06.628895",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.603959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6953,  0.1889,  0.1066,  ..., -0.3936, -0.7037,  0.0353],\n",
       "         [-1.7725, -0.7538, -0.4660,  ..., -1.3029, -0.6142, -0.3187],\n",
       "         [ 0.4180, -0.1114, -1.8086,  ...,  1.7038, -2.0903,  0.0084],\n",
       "         ...,\n",
       "         [-0.3142, -0.1601, -0.7460,  ...,  0.0048,  1.6216,  1.0151],\n",
       "         [ 0.2993,  0.1934, -0.8340,  ..., -1.2851, -0.8688,  0.5341],\n",
       "         [-1.8588,  0.5864, -0.1779,  ...,  0.3559,  1.8418, -0.1985]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 embedding vectors of 768 dimensions\n",
    "inputs_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f90749",
   "metadata": {
    "papermill": {
     "duration": 0.014998,
     "end_time": "2023-11-07T12:12:06.659344",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.644346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **3. QUERY, KEY, VALUE VECTORS**\n",
    "\n",
    "- As the most simplistic case of attention, **we set them equal to one another**\n",
    "- Attention mechanism with equal query and key vectors will assign a **very large score to identical words in the context** (diagonal component of matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729ded24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.690843Z",
     "iopub.status.busy": "2023-11-07T12:12:06.690541Z",
     "iopub.status.idle": "2023-11-07T12:12:06.696736Z",
     "shell.execute_reply": "2023-11-07T12:12:06.696023Z"
    },
    "papermill": {
     "duration": 0.023794,
     "end_time": "2023-11-07T12:12:06.698387",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.674593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query and key components\n",
      "\n",
      "query size: torch.Size([1, 9, 768])\n",
      "key size: torch.Size([1, 768, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "\n",
    "# setting them equal to one another\n",
    "print(\"query and key components\\n\")\n",
    "query = key = value = inputs_embeds\n",
    "print('query size:',query.size())\n",
    "dim_k = key.size(-1)   # hidden dimension \n",
    "print('key size:',key.transpose(1,2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc551bd",
   "metadata": {
    "papermill": {
     "duration": 0.01558,
     "end_time": "2023-11-07T12:12:06.729699",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.714119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **4. COMPUTE ATTENTION SCORES**\n",
    "\n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** using the **dot product as the similarity function**\n",
    "- `torch.bmm` - batch matrix matrix product (as we work in batches during training)\n",
    "- If we need to transpose a vector `vector.transpose(1,2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514d67e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.762745Z",
     "iopub.status.busy": "2023-11-07T12:12:06.762404Z",
     "iopub.status.idle": "2023-11-07T12:12:06.776470Z",
     "shell.execute_reply": "2023-11-07T12:12:06.775853Z"
    },
    "papermill": {
     "duration": 0.032784,
     "end_time": "2023-11-07T12:12:06.778682",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.745898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dot product (attention scores)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product & apply normalisation\n",
    "print(\"\\ndot product (attention scores)\")\n",
    "scores = torch.bmm(query, key.transpose(1,2)) / sqrt(dim_k)\n",
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46d911a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.812364Z",
     "iopub.status.busy": "2023-11-07T12:12:06.812033Z",
     "iopub.status.idle": "2023-11-07T12:12:06.818346Z",
     "shell.execute_reply": "2023-11-07T12:12:06.817521Z"
    },
    "papermill": {
     "duration": 0.025187,
     "end_time": "2023-11-07T12:12:06.819967",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.794780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[28.2778, -0.0560, -0.5845,  0.8930, -0.1730, -0.6903,  1.4119,\n",
       "           2.5140, -1.2024],\n",
       "         [-0.0560, 27.7726,  0.7603,  0.1857, -0.3888, -0.9593,  0.7742,\n",
       "          -2.4892, -0.0420],\n",
       "         [-0.5845,  0.7603, 26.8805, -0.1206,  0.2067,  1.2373, -0.3023,\n",
       "          -2.0496, -0.1639],\n",
       "         [ 0.8930,  0.1857, -0.1206, 27.7590,  0.4918,  1.7533,  0.6470,\n",
       "           0.0552, -0.0448],\n",
       "         [-0.1730, -0.3888,  0.2067,  0.4918, 26.3990, -1.1320, -0.2163,\n",
       "           0.4334,  0.4951],\n",
       "         [-0.6903, -0.9593,  1.2373,  1.7533, -1.1320, 29.1548,  0.0852,\n",
       "          -0.6562,  0.2810],\n",
       "         [ 1.4119,  0.7742, -0.3023,  0.6470, -0.2163,  0.0852, 28.4623,\n",
       "          -0.1245, -0.7585],\n",
       "         [ 2.5140, -2.4892, -2.0496,  0.0552,  0.4334, -0.6562, -0.1245,\n",
       "          28.0784, -0.5796],\n",
       "         [-1.2024, -0.0420, -0.1639, -0.0448,  0.4951,  0.2810, -0.7585,\n",
       "          -0.5796, 27.5657]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291f7de",
   "metadata": {
    "papermill": {
     "duration": 0.015722,
     "end_time": "2023-11-07T12:12:06.851771",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.836049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **5. COMPUTE ATTENTION WEIGHTS (SOFTMAX FUNCTION)**\n",
    "\n",
    "\n",
    "\n",
    "- Created a 5x5 matrix of **attention scores** per sample in the batch\n",
    "- Apply the softmax for normalisation to get the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "848e4e3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.885652Z",
     "iopub.status.busy": "2023-11-07T12:12:06.885333Z",
     "iopub.status.idle": "2023-11-07T12:12:06.894232Z",
     "shell.execute_reply": "2023-11-07T12:12:06.893421Z"
    },
    "papermill": {
     "duration": 0.02817,
     "end_time": "2023-11-07T12:12:06.896060",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.867890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sotfmax applied, attention weights :\n",
      "\n",
      "torch.Size([1, 9, 9])\n",
      "tensor([[[1.0000e+00, 4.9519e-13, 2.9192e-13, 1.2792e-12, 4.4051e-13,\n",
      "          2.6260e-13, 2.1492e-12, 6.4703e-12, 1.5736e-13],\n",
      "         [8.2070e-13, 1.0000e+00, 1.8565e-12, 1.0451e-12, 5.8837e-13,\n",
      "          3.3259e-13, 1.8825e-12, 7.2022e-14, 8.3224e-13],\n",
      "         [1.1807e-12, 4.5303e-12, 1.0000e+00, 1.8776e-12, 2.6044e-12,\n",
      "          7.2997e-12, 1.5656e-12, 2.7277e-13, 1.7979e-12],\n",
      "         [2.1492e-12, 1.0595e-12, 7.7997e-13, 1.0000e+00, 1.4389e-12,\n",
      "          5.0805e-12, 1.6804e-12, 9.2980e-13, 8.4132e-13],\n",
      "         [2.8834e-12, 2.3237e-12, 4.2151e-12, 5.6058e-12, 1.0000e+00,\n",
      "          1.1052e-12, 2.7612e-12, 5.2877e-12, 5.6243e-12],\n",
      "         [1.0925e-13, 8.3488e-14, 7.5089e-13, 1.2580e-12, 7.0245e-14,\n",
      "          1.0000e+00, 2.3725e-13, 1.1305e-13, 2.8856e-13],\n",
      "         [1.7871e-12, 9.4449e-13, 3.2189e-13, 8.3169e-13, 3.5078e-13,\n",
      "          4.7422e-13, 1.0000e+00, 3.8450e-13, 2.0397e-13],\n",
      "         [7.8983e-12, 5.3048e-14, 8.2331e-14, 6.7556e-13, 9.8613e-13,\n",
      "          3.3170e-13, 5.6444e-13, 1.0000e+00, 3.5807e-13],\n",
      "         [3.2073e-13, 1.0235e-12, 9.0607e-13, 1.0206e-12, 1.7513e-12,\n",
      "          1.4137e-12, 4.9997e-13, 5.9788e-13, 1.0000e+00]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "sum of column values:/n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"sotfmax applied, attention weights :\\n\")\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "print(weights.size())\n",
    "print(weights)\n",
    "\n",
    "print(\"\\nsum of column values:/n\")\n",
    "weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf19419",
   "metadata": {
    "papermill": {
     "duration": 0.017197,
     "end_time": "2023-11-07T12:12:06.930058",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.912861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **6. UPDATE VALUES**\n",
    "\n",
    "Multiply the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>** matrix by the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">values</mark>** vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d827e60f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.963834Z",
     "iopub.status.busy": "2023-11-07T12:12:06.963500Z",
     "iopub.status.idle": "2023-11-07T12:12:06.970332Z",
     "shell.execute_reply": "2023-11-07T12:12:06.969370Z"
    },
    "papermill": {
     "duration": 0.025786,
     "end_time": "2023-11-07T12:12:06.972071",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.946285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1372, -0.1640, -0.5709,  ..., -0.3382, -0.5156, -0.9368],\n",
      "         [ 1.6893,  0.7558,  0.0126,  ..., -1.8282, -0.0124, -0.5235],\n",
      "         [-0.2811,  0.3767, -0.2336,  ...,  1.5930, -1.5876,  1.9867],\n",
      "         ...,\n",
      "         [-0.4095, -0.1513,  0.4900,  ..., -0.2493,  0.7508,  0.0295],\n",
      "         [-1.8162,  0.8497,  1.4001,  ..., -0.5877, -0.4474,  0.9935],\n",
      "         [-0.6127, -0.1215,  2.2074,  ...,  1.5790,  0.3022, -0.4228]]],\n",
      "       grad_fn=<BmmBackward0>)\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "attn_outputs = torch.bmm(weights, value)\n",
    "print(attn_outputs)\n",
    "print(attn_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c5cf7f",
   "metadata": {
    "papermill": {
     "duration": 0.016049,
     "end_time": "2023-11-07T12:12:07.004544",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.988495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we have a general function:\n",
    "- Which inputs vectors `query`, `key` & `value` \n",
    "- Calculates the scalar dot product attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadf54f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.039142Z",
     "iopub.status.busy": "2023-11-07T12:12:07.038780Z",
     "iopub.status.idle": "2023-11-07T12:12:07.044075Z",
     "shell.execute_reply": "2023-11-07T12:12:07.043479Z"
    },
    "papermill": {
     "duration": 0.024195,
     "end_time": "2023-11-07T12:12:07.045542",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.021347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Scalar Dot Product Attention\n",
    "scores = query*key.T / sqrt(dims)\n",
    "weight = softmax(scores) \n",
    "\n",
    "'''\n",
    "\n",
    "def sdp_attention(query, key, value):\n",
    "    dim_k = query.size(-1) # dimension component\n",
    "    sfact = sqrt(dim_k)     \n",
    "    scores = torch.bmm(query, key.transpose(1,2)) / sfact\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ff305",
   "metadata": {
    "papermill": {
     "duration": 0.0158,
     "end_time": "2023-11-07T12:12:07.077434",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.061634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>3 |</span></b> <b>MULTIHEAD SELF ATTENTION</b></div>\n",
    "\n",
    "\n",
    "- The meaning of the word will be better informed by **complementary words in the context** than by **identical words** (which gives 1)\n",
    "\n",
    "##### **SIMPLISTIC APPROACH**\n",
    "\n",
    "- We only used the embeddings \"as is\" (no linear transformation) to compute the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>**\n",
    "\n",
    "##### **BETTER APPROACH**\n",
    "\n",
    "- The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">self-attention</mark>** layer applies **three independent linear transformations (`nn.linear`) to each embedding** to generate **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">query</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">key</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>** \n",
    "- These transformations project the embeddings and **each projection carries its own set of learnable parameters** (**Weights**)\n",
    "- This **allows the self-attention layer to focus on different semantic aspects of the sequence**\n",
    "\n",
    "\n",
    "\n",
    "Its beneficial to have **multiple sets of linear projections** (each one represents an **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention head</mark>**)\n",
    "\n",
    "Why do we need more than one **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention head</mark>**?\n",
    "- The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">softmax</mark>** of one head tends to focus on mostly **one aspect of similarity**\n",
    "\n",
    "\n",
    "**Several heads** allows the model to **focus on several apsects at once**\n",
    "- Eg. one head can focus on subject-verb interaction, another finds nearby adjectives\n",
    "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">CV analogy</mark>**: filters; one filter responsible for detecting the head, another for facial features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae55c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.111569Z",
     "iopub.status.busy": "2023-11-07T12:12:07.110662Z",
     "iopub.status.idle": "2023-11-07T12:12:07.116625Z",
     "shell.execute_reply": "2023-11-07T12:12:07.116040Z"
    },
    "papermill": {
     "duration": 0.024562,
     "end_time": "2023-11-07T12:12:07.118152",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.093590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Attention Class\n",
    "\n",
    "# nn.linear : apply linear transformation to incoming data\n",
    "#             y = x * A^T + b\n",
    "# Ax = b where x is input, b is output, A is weight\n",
    "\n",
    "# calculate scaled dot product attention matrix\n",
    "# Requires embedding dimension \n",
    "# Each attention head is made of different q,k,v vectors\n",
    "\n",
    "'''\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    # initalisation \n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the three vectors\n",
    "        # input - embed_dim, output - head_dim\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    # main class operation\n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # calculate scaled dot product given a \n",
    "        attn_outputs = sdp_attention(\n",
    "            self.q(hidden_state), \n",
    "            self.k(hidden_state), \n",
    "            self.v(hidden_state))\n",
    "        \n",
    "        return attn_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647aecb",
   "metadata": {
    "papermill": {
     "duration": 0.015925,
     "end_time": "2023-11-07T12:12:07.150302",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.134377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`Attention` will be used in the construction of a model\n",
    "\n",
    "- We’ve **initialised three independent linear layers** that apply matrix multiplication to the embedding vectors to produce tensors of shape [batch_size, seq_len, head_dim]\n",
    "- Where head_dim is the number of dimensions we are projecting into\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f47172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.184165Z",
     "iopub.status.busy": "2023-11-07T12:12:07.183786Z",
     "iopub.status.idle": "2023-11-07T12:12:07.188846Z",
     "shell.execute_reply": "2023-11-07T12:12:07.187928Z"
    },
    "papermill": {
     "duration": 0.024268,
     "end_time": "2023-11-07T12:12:07.190719",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.166451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 heads\n",
      "768 hidden state embedding dimension\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print(config.num_attention_heads,'heads')\n",
    "print(config.hidden_size,'hidden state embedding dimension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dc47326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.224688Z",
     "iopub.status.busy": "2023-11-07T12:12:07.224386Z",
     "iopub.status.idle": "2023-11-07T12:12:07.230964Z",
     "shell.execute_reply": "2023-11-07T12:12:07.230200Z"
    },
    "papermill": {
     "duration": 0.025767,
     "end_time": "2023-11-07T12:12:07.232720",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.206953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (q): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (k): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (v): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Sample Initialisation '''\n",
    "\n",
    "# Initialised just one head, requires token embedding vector for forward operation\n",
    "\n",
    "embed_dim = config.hidden_size\n",
    "num_heads = config.num_attention_heads\n",
    "\n",
    "attention = Attention(embed_dim,num_heads)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da230f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.266405Z",
     "iopub.status.busy": "2023-11-07T12:12:07.265958Z",
     "iopub.status.idle": "2023-11-07T12:12:07.276364Z",
     "shell.execute_reply": "2023-11-07T12:12:07.275745Z"
    },
    "papermill": {
     "duration": 0.028895,
     "end_time": "2023-11-07T12:12:07.278006",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.249111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3785, -0.1225,  0.1665, -0.2492,  0.0298, -0.0010,  0.4590,\n",
       "           0.2504,  0.3419, -0.1287, -0.1394, -0.0081],\n",
       "         [-0.4377, -0.0131, -0.0385, -0.4269, -0.0143, -0.2199,  0.3435,\n",
       "           0.2661,  0.2000, -0.0322, -0.1178, -0.0684],\n",
       "         [-0.4217, -0.0546,  0.0053, -0.1888,  0.0211, -0.2245,  0.3599,\n",
       "           0.2941,  0.2816,  0.0566, -0.1054,  0.0277],\n",
       "         [-0.1829, -0.1457,  0.1940, -0.1023,  0.0994,  0.0569,  0.1223,\n",
       "           0.3326,  0.2057,  0.1363, -0.0909,  0.0537],\n",
       "         [-0.5145, -0.1693,  0.0426, -0.2721, -0.0756, -0.1849,  0.4172,\n",
       "           0.2842,  0.2850, -0.0334, -0.1068,  0.1154],\n",
       "         [-0.3539, -0.0502,  0.0768, -0.2742,  0.0889, -0.1206,  0.3454,\n",
       "           0.2391,  0.2898, -0.0085, -0.0863, -0.0209],\n",
       "         [-0.5372, -0.2052,  0.1084, -0.2576, -0.0576, -0.1253,  0.5218,\n",
       "           0.2485,  0.3603, -0.1158, -0.1089,  0.1241],\n",
       "         [-0.3806, -0.0407,  0.0601, -0.3340,  0.0367, -0.1459,  0.3445,\n",
       "           0.2424,  0.2543, -0.0352, -0.0955, -0.0328],\n",
       "         [-0.3776,  0.0047,  0.0028, -0.4158,  0.1387, -0.1608,  0.3675,\n",
       "           0.1977,  0.2328, -0.0861, -0.0563, -0.1697]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights are always initialised randomly, attention_outputs varies\n",
    "attention_outputs = attention(inputs_embeds)\n",
    "attention_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54eec369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.312835Z",
     "iopub.status.busy": "2023-11-07T12:12:07.312013Z",
     "iopub.status.idle": "2023-11-07T12:12:07.318401Z",
     "shell.execute_reply": "2023-11-07T12:12:07.317850Z"
    },
    "papermill": {
     "duration": 0.025446,
     "end_time": "2023-11-07T12:12:07.320076",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.294630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Multihead attention class\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class multiHeadAttention(nn.Module):\n",
    "    \n",
    "    # Config during initalisation\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # model params, read from config file\n",
    "        embed_dim = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # attention head (define only w/o hidden state)\n",
    "        # each attention head is initialised with embedd/heads head dimension\n",
    "        self.heads = nn.ModuleList(\n",
    "            [Attention(embed_dim, head_dim) for _ in range(num_heads)])\n",
    "        \n",
    "        # output uses whole embedding dimension for output\n",
    "        self.out_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    # Given a hidden state (embeddings)\n",
    "    # Apply operation for multihead attention\n",
    "        \n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # for each head embed_size/heads, calculate attention\n",
    "        heads = [head(hidden_state) for head in self.heads] \n",
    "        x = torch.cat(heads, dim=-1) # merge/concat head data together\n",
    "    \n",
    "        # apply linear transformation to multihead attension scalar product\n",
    "        x = self.out_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bba389d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.354402Z",
     "iopub.status.busy": "2023-11-07T12:12:07.353650Z",
     "iopub.status.idle": "2023-11-07T12:12:07.380981Z",
     "shell.execute_reply": "2023-11-07T12:12:07.379853Z"
    },
    "papermill": {
     "duration": 0.046191,
     "end_time": "2023-11-07T12:12:07.382557",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.336366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2038,  0.0492, -0.3806,  ...,  0.1021,  0.0149, -0.1455],\n",
      "         [-0.1592,  0.0654, -0.3598,  ...,  0.0183,  0.0195, -0.2444],\n",
      "         [-0.2921,  0.0971, -0.3893,  ..., -0.0356,  0.0129, -0.1618],\n",
      "         ...,\n",
      "         [-0.2515,  0.1114, -0.3912,  ...,  0.1206, -0.0399, -0.2125],\n",
      "         [-0.1645,  0.1249, -0.4061,  ...,  0.0065,  0.0102, -0.2034],\n",
      "         [-0.2588,  0.1445, -0.3431,  ...,  0.0014, -0.1113, -0.1206]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Sample Usage: Multi-Head Attention\n",
    "\n",
    "'''\n",
    "\n",
    "# Every time will be different due to randomised weights\n",
    "multihead_attn = multiHeadAttention(config) # initialisation with config\n",
    "attn_output = multihead_attn(inputs_embeds) # forward by inputting embedding vectors (one for each token)\n",
    "\n",
    "# Attention output (attention weights matrix x vector weights concat)\n",
    "print(attn_output)\n",
    "print(attn_output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2aebb7",
   "metadata": {
    "papermill": {
     "duration": 0.01628,
     "end_time": "2023-11-07T12:12:07.415605",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.399325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>4 |</span></b> <b>FEED FORWARD LAYER</b></div>\n",
    "\n",
    "**position-wise feed-forward layer**\n",
    "\n",
    "The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">feed-forward</mark>** sublayer in the encoder & decoder\n",
    "- **two layer fully connected neural network**\n",
    "\n",
    "\n",
    "However, instead of processing the whole sequence of embedding as a single vector, \n",
    "- it **processes each embedding** independently\n",
    "- Also see it referred to as a Conv1D with a kernel size of 1 (people with a CV background)\n",
    "\n",
    "\n",
    "The **hidden size** of the **1st layer = 4x size of the embeddings** & **GELU activation function**\n",
    "- Place where most of the capacity & memorization is hypothesized to happen\n",
    "- It is most often scaled, when scaling up the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab0da5c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.450016Z",
     "iopub.status.busy": "2023-11-07T12:12:07.449132Z",
     "iopub.status.idle": "2023-11-07T12:12:07.454841Z",
     "shell.execute_reply": "2023-11-07T12:12:07.454256Z"
    },
    "papermill": {
     "duration": 0.024374,
     "end_time": "2023-11-07T12:12:07.456328",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.431954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class feedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.linear2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    # define layer operations input x\n",
    "        \n",
    "    def forward(self, x):    # note must be forward\n",
    "        x = self.gelu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51b36e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.489862Z",
     "iopub.status.busy": "2023-11-07T12:12:07.489589Z",
     "iopub.status.idle": "2023-11-07T12:12:07.544434Z",
     "shell.execute_reply": "2023-11-07T12:12:07.543744Z"
    },
    "papermill": {
     "duration": 0.073582,
     "end_time": "2023-11-07T12:12:07.546107",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.472525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedForward(\n",
      "  (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (gelu): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0071, -0.0288, -0.0209,  ..., -0.0377,  0.0024,  0.0379],\n",
       "         [-0.0073, -0.0401, -0.0253,  ..., -0.0378,  0.0008,  0.0478],\n",
       "         [-0.0096, -0.0413, -0.0249,  ..., -0.0399,  0.0034,  0.0415],\n",
       "         ...,\n",
       "         [-0.0012, -0.0281, -0.0072,  ..., -0.0367,  0.0085,  0.0444],\n",
       "         [ 0.0059, -0.0000, -0.0209,  ..., -0.0402,  0.0091,  0.0407],\n",
       "         [ 0.0013, -0.0234, -0.0095,  ..., -0.0388,  0.0076,  0.0386]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initailise feedforward layer\n",
    "feed_forward = feedForward(config)              # initialise \n",
    "print(feed_forward,'\\n')\n",
    "\n",
    "# requires config & attn_outputs outputs\n",
    "ff_outputs = feed_forward(attn_output) # forward operation\n",
    "ff_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2fc03c",
   "metadata": {
    "papermill": {
     "duration": 0.016237,
     "end_time": "2023-11-07T12:12:07.579139",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.562902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>5 |</span></b> <b>NORMALISATION LAYERS</b></div>\n",
    "\n",
    "Transformer architecture also uses **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">layer normalisation</mark>** & **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">skip connections</mark>**\n",
    "- **normalisation** - normalises batch input to have zero mean & unit variance\n",
    "- **skip connections** - pass a tensor to the next level of the model w/o processing & adding it to the processed tensor\n",
    "\n",
    "Two main approaches, when it comes to normalisation layer placement in decoder, encoder:\n",
    "- **post layer** normalisation (transformer paper, layer normalisation b/w skip connections)\n",
    "- **pre layer** normalisation \n",
    "\n",
    "<br>\n",
    "\n",
    "| `post-layer` normalisation |  `pre-layer` normalisation in literature |\n",
    "| - | - |\n",
    "| Arrangement is tricky to train from scractch, as the gradients can diverge |  Most often found arrangement\n",
    "| Used with LR warm up (learning rate gradually increased, from small value to some maximum value during training) | Places layer normalization within the span of the skip connection |\n",
    "|  | Tends to be much more stable during training, and it does not usually require any learning rate warm-up |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc50d01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.613606Z",
     "iopub.status.busy": "2023-11-07T12:12:07.612856Z",
     "iopub.status.idle": "2023-11-07T12:12:07.618561Z",
     "shell.execute_reply": "2023-11-07T12:12:07.617989Z"
    },
    "papermill": {
     "duration": 0.024708,
     "end_time": "2023-11-07T12:12:07.620134",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.595426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class encoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = multiHeadAttention(config)    # multihead attention layer \n",
    "        self.feed_forward = feedForward(config)        # feed forward layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Apply layer norm. to hidden state, copy input into query, key, value\n",
    "        # Apply attention with a skip connection\n",
    "        x = x + self.attention(self.norm1(x))\n",
    "        \n",
    "        # Apply feed-forward layer with a skip connection\n",
    "        x = x + self.feed_forward(self.norm2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcecb13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.655181Z",
     "iopub.status.busy": "2023-11-07T12:12:07.654374Z",
     "iopub.status.idle": "2023-11-07T12:12:07.719063Z",
     "shell.execute_reply": "2023-11-07T12:12:07.718146Z"
    },
    "papermill": {
     "duration": 0.08428,
     "end_time": "2023-11-07T12:12:07.721179",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.636899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoderLayer(\n",
      "  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attention): multiHeadAttention(\n",
      "    (heads): ModuleList(\n",
      "      (0-11): 12 x Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (out_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (feed_forward): feedForward(\n",
      "    (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (gelu): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ") \n",
      "\n",
      "input torch.Size([1, 9, 768])\n",
      "output torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "# Transformer layer output\n",
    "encoder_layer = encoderLayer(config) # initialise encoder layer\n",
    "print(encoder_layer,'\\n')\n",
    "\n",
    "print('input',inputs_embeds.shape) \n",
    "print('output',encoder_layer(inputs_embeds).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7232eac0",
   "metadata": {
    "papermill": {
     "duration": 0.01686,
     "end_time": "2023-11-07T12:12:07.754870",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.738010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is an issue with the way we set up the **encoder layers** (which uses just embedding inputs)\n",
    "- they are totally **invariant to the position of the tokens**\n",
    "- Multi-head attention layer is effectively a weighted sum, the **information on token position is lost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ed26c",
   "metadata": {
    "papermill": {
     "duration": 0.016274,
     "end_time": "2023-11-07T12:12:07.787762",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.771488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>6 |</span></b> <b>POSITIONAL EMBEDDINGS</b></div>\n",
    "\n",
    "Let's incorporate positional information using **positional embeddings**\n",
    "\n",
    "\n",
    "**positional embeddings** are based on idea:\n",
    "  - Modify the **token embeddings** with a **position-dependent pattern** of values arranged in a vector\n",
    "  \n",
    "  \n",
    "If the pattern is characteristic for each position\n",
    "- the **attention heads** and **feed-forward layers** in each stack can learn to incorporate positional information into their transformations\n",
    "\n",
    "\n",
    "\n",
    "- There are several ways to achieve this, and one of the most popular approaches is to use a `learnable pattern`\n",
    "- This works exactly the same way as the token embeddings, but using the **position index** instead of the **token identifier** (from vocabulary dictionary) as input\n",
    "- An efficient way of encoding the positions of tokens is learned during pretraining\n",
    "\n",
    "Creating Custom `Embedding` class\n",
    "\n",
    "Let’s create a custom Embeddings module (**token embeddings + positional embeddings**)\n",
    " - That combines a token embedding layer that projects the input_ids to a dense hidden state \n",
    " - Together with the positional embedding that does the same for position_ids\n",
    " - The resulting embedding is simply the **sum of both embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "436fdf8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.823932Z",
     "iopub.status.busy": "2023-11-07T12:12:07.823592Z",
     "iopub.status.idle": "2023-11-07T12:12:07.831753Z",
     "shell.execute_reply": "2023-11-07T12:12:07.830873Z"
    },
    "papermill": {
     "duration": 0.02821,
     "end_time": "2023-11-07T12:12:07.833862",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.805652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Token + Position Embedding \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class tpEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):        \n",
    "        super().__init__()\n",
    "        \n",
    "        # token embedding layer\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size,\n",
    "                                             config.hidden_size)\n",
    "        \n",
    "        # positional embedding layer\n",
    "        # config.max_position_embeddings -> max number of positions in text 512 (tokens)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
    "                                                config.hidden_size)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \n",
    "        # Create position IDs for input sequence\n",
    "        seq_length = input_ids.size(1) # number of tokens\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long)[None,:] # range(0,9)\n",
    "        \n",
    "        # tensor([[ 1996, 11286,  1997,  1037,  5340,  3392,  2003,  2200,  5931]])\n",
    "        # tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8]])\n",
    "        \n",
    "        # Create token and position embeddings\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # Combine token and position embeddings\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        \n",
    "        # Add normalisation & dropout layers\n",
    "        embeddings = self.norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1eb5779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.870017Z",
     "iopub.status.busy": "2023-11-07T12:12:07.869347Z",
     "iopub.status.idle": "2023-11-07T12:12:08.024643Z",
     "shell.execute_reply": "2023-11-07T12:12:08.023751Z"
    },
    "papermill": {
     "duration": 0.175058,
     "end_time": "2023-11-07T12:12:08.026668",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.851610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.0403, -0.0000,  1.1722,  ..., -1.6743, -3.0759, -0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0780, -1.9838],\n",
       "         [ 2.4112, -0.0000,  0.9230,  ...,  0.0000, -3.2554, -3.6100],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000, -1.9303,  ...,  1.7901, -2.4660, -0.0000],\n",
       "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  2.1861, -0.9021],\n",
       "         [-0.0000,  0.0000, -5.8991,  ...,  0.0209,  0.0000, -0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token and Position Embeddings\n",
    "embedding_layer = tpEmbedding(config)\n",
    "embedding_layer(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae2413",
   "metadata": {
    "papermill": {
     "duration": 0.016522,
     "end_time": "2023-11-07T12:12:08.060364",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.043842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>7 |</span></b> <b>PUTTING IT ALL TOGETHER</b></div>\n",
    "\n",
    "- Constructing the Transformer **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">encoder</mark>**, combining the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">Embedding</mark>** and **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">Encoder</mark>**  layers\n",
    "- We utilise both **token** & **positional** embeddings using `tpEmbedding`\n",
    "- For a given number of heads, we store `encoderLayer`, which contains the **attention** & **feed-forward** layers (which are our layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6f1e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:08.094928Z",
     "iopub.status.busy": "2023-11-07T12:12:08.094587Z",
     "iopub.status.idle": "2023-11-07T12:12:08.100489Z",
     "shell.execute_reply": "2023-11-07T12:12:08.099664Z"
    },
    "papermill": {
     "duration": 0.024909,
     "end_time": "2023-11-07T12:12:08.102005",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.077096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full transformer encoder combining the `Embedding` with the ``Embedding` ` layers\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):       \n",
    "        super().__init__()\n",
    "        \n",
    "        # token & positional embedding layer\n",
    "        self.embeddings = tpEmbedding(config)\n",
    "        \n",
    "        # attention & forward feed layer \n",
    "        self.layers = nn.ModuleList([encoderLayer(config)\n",
    "                                     for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # embeddings layer output\n",
    "        x = self.embeddings(x)\n",
    "        \n",
    "        # cycle through all heads\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bbadb05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:08.136166Z",
     "iopub.status.busy": "2023-11-07T12:12:08.135908Z",
     "iopub.status.idle": "2023-11-07T12:12:08.948737Z",
     "shell.execute_reply": "2023-11-07T12:12:08.948016Z"
    },
    "papermill": {
     "duration": 0.831712,
     "end_time": "2023-11-07T12:12:08.950315",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.118603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6233, -0.7978, -2.4776,  ..., -0.4364, -0.0118, -1.8506],\n",
       "         [-3.6226, -1.5029,  0.7667,  ..., -1.8732,  3.5305, -2.8063],\n",
       "         [ 0.4178,  1.5879, -0.8017,  ..., -3.4680, -0.4882, -3.1883],\n",
       "         ...,\n",
       "         [ 0.2196, -0.0766,  2.8025,  ...,  3.6958,  0.7566, -4.5964],\n",
       "         [ 0.4364,  1.1692, -0.8789,  ...,  1.1547,  4.6363, -1.0828],\n",
       "         [ 1.8008, -1.3734, -2.4738,  ...,  0.4895, -0.9201, -3.4636]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoder initialisation & output\n",
    "encoder = TransformerEncoder(config)\n",
    "encoder_output = encoder(inputs.input_ids)\n",
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50cb84d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:08.986890Z",
     "iopub.status.busy": "2023-11-07T12:12:08.985912Z",
     "iopub.status.idle": "2023-11-07T12:12:08.991281Z",
     "shell.execute_reply": "2023-11-07T12:12:08.990709Z"
    },
    "papermill": {
     "duration": 0.024749,
     "end_time": "2023-11-07T12:12:08.992754",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.968005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden state for each token in a batch\n",
    "encoder_output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4161345",
   "metadata": {
    "papermill": {
     "duration": 0.016716,
     "end_time": "2023-11-07T12:12:09.026352",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.009636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>8 |</span></b> <b>CLASSIFICATION HEAD</b></div>\n",
    "\n",
    "Quite often, transformers are divided into:\n",
    "- Task independent body (`TransformerEncoder`)\n",
    "- Task dependent head (`TransformerClassifier`)\n",
    "\n",
    "Select one of the token outputs:\n",
    "- The first token in such models is often used for the prediction **[CLS] token**\n",
    "- Can attach a `dropout` and a `linear` transformation layer to make a classification prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50466a72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:09.063655Z",
     "iopub.status.busy": "2023-11-07T12:12:09.063083Z",
     "iopub.status.idle": "2023-11-07T12:12:09.068612Z",
     "shell.execute_reply": "2023-11-07T12:12:09.068049Z"
    },
    "papermill": {
     "duration": 0.025845,
     "end_time": "2023-11-07T12:12:09.070128",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.044283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        \n",
    "        # Classification Head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[:, 0, :] # select hidden state of [CLS] token\n",
    "        x = self.dropout(x)\n",
    "#         x = self.classifier(x) # 768 -> 3 \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cc08ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class Embeddings():\n",
    "    def getTensor(self,text):\n",
    "        inputs = tokenizer(text, \n",
    "                   return_tensors=\"pt\",      # pytorc tensor\n",
    "                   add_special_tokens=False,\n",
    "                          padding=True) # don't use pad, sep tokens\n",
    "        return inputs.input_ids\n",
    "data = list(pd.read_csv(\"SEC-CompanyTicker.csv\",index_col=0).companyName[:100])\n",
    "inputs = Embeddings().getTensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a5f09",
   "metadata": {
    "papermill": {
     "duration": 0.016599,
     "end_time": "2023-11-07T12:12:09.103550",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.086951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- For each sample in the batch we get the **unnormalized logits** for each class in the output, which corresponds to the BERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "74c29271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:09.138526Z",
     "iopub.status.busy": "2023-11-07T12:12:09.138069Z",
     "iopub.status.idle": "2023-11-07T12:12:10.191689Z",
     "shell.execute_reply": "2023-11-07T12:12:10.191034Z"
    },
    "papermill": {
     "duration": 1.073469,
     "end_time": "2023-11-07T12:12:10.193779",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.120310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.3533,  0.8686,  1.3328,  ..., -0.1595, -1.0860,  0.0706],\n",
       "        [-0.0000, -0.0561, -1.5787,  ...,  0.0000,  0.0471, -1.3811],\n",
       "        [ 0.0000,  0.9671, -1.0112,  ...,  2.8010,  1.5144, -1.0039],\n",
       "        ...,\n",
       "        [-0.7198,  0.9421, -0.2193,  ...,  0.8811, -0.0000, -3.2116],\n",
       "        [-1.5848,  0.0000, -0.4742,  ...,  1.1263, -0.0000, -0.2135],\n",
       "        [-0.7677,  0.8380, -2.6805,  ...,  0.7196, -3.7764, -0.5905]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.num_labels = 3\n",
    "encoder_classifier = TransformerClassifier(config)\n",
    "output = encoder_classifier(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b23bbb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1550, -0.8370,  0.1463,  ...,  2.9710, -2.1226,  0.9835],\n",
       "        [-0.9236, -0.4818, -0.3254,  ...,  3.0201, -2.3562, -0.7856],\n",
       "        [-0.4130, -0.0390,  2.5468,  ...,  0.4699, -5.0520, -1.2381],\n",
       "        ...,\n",
       "        [ 1.7425,  2.1272, -0.5952,  ..., -0.3944, -2.8264, -2.4440],\n",
       "        [-3.3747,  1.8521, -0.0000,  ...,  1.3196,  0.1693, -0.8030],\n",
       "        [-0.0000,  0.0000, -0.4076,  ...,  2.8518, -3.9287, -0.2514]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    output = encoder_classifier(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c4164f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4437,  0.3313, -0.6277,  ...,  0.6206,  0.0000,  1.5203],\n",
       "        [-5.6815,  6.1352,  5.9350,  ...,  0.8245,  1.0475, -1.5590],\n",
       "        [-0.8428,  5.7313,  0.1390,  ...,  1.5924,  1.5136, -4.6436],\n",
       "        ...,\n",
       "        [ 2.4312,  0.1644,  0.2303,  ...,  1.7255,  0.4047, -0.1814],\n",
       "        [-5.8681,  0.4185,  4.6201,  ...,  6.0037,  0.3678, -1.6436],\n",
       "        [-1.9681,  0.0000,  5.1553,  ...,  0.7944,  1.8766, -3.0019]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    output = encoder_classifier(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "78fb41d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple Inc.',\n",
       " 'Microsoft Corp',\n",
       " 'Alphabet Inc.',\n",
       " 'Amazon Com Inc',\n",
       " 'Nvidia Corp',\n",
       " 'Tesla, Inc.',\n",
       " 'Berkshire Hathaway Inc',\n",
       " 'Meta Platforms, Inc.',\n",
       " 'Eli Lilly & Co',\n",
       " 'Visa Inc.',\n",
       " 'Taiwan Semiconductor Manufacturing Co Ltd',\n",
       " 'Exxon Mobil Corp',\n",
       " 'Unitedhealth Group Inc',\n",
       " 'Walmart Inc.',\n",
       " 'Novo Nordisk A S',\n",
       " 'Jpmorgan Chase & Co',\n",
       " 'Spdr S&P 500 Etf Trust',\n",
       " 'Johnson & Johnson',\n",
       " 'Mastercard Inc',\n",
       " 'Lvmh Moet Hennessy Louis Vuitton',\n",
       " 'Procter & Gamble Co',\n",
       " 'Broadcom Inc.',\n",
       " 'Latam Airlines Group S.A.',\n",
       " 'Home Depot, Inc.',\n",
       " 'Chevron Corp',\n",
       " 'Oracle Corp',\n",
       " 'Merck & Co., Inc.',\n",
       " 'Abbvie Inc.',\n",
       " 'Coca Cola Co',\n",
       " 'Adobe Inc.',\n",
       " 'Toyota Motor Corp/',\n",
       " 'Pepsico Inc',\n",
       " 'Costco Wholesale Corp /New',\n",
       " 'Asml Holding Nv',\n",
       " 'Bank Of America Corp /De/',\n",
       " 'Cisco Systems, Inc.',\n",
       " 'Alibaba Group Holding Ltd',\n",
       " 'Salesforce, Inc.',\n",
       " 'Shell Plc',\n",
       " 'Astrazeneca Plc',\n",
       " 'Novartis Ag',\n",
       " 'Mcdonalds Corp',\n",
       " 'Accenture Plc',\n",
       " 'Thermo Fisher Scientific Inc.',\n",
       " 'Mexican Economic Development Inc',\n",
       " 'Pfizer Inc',\n",
       " 'Linde Plc',\n",
       " 'Danaher Corp /De/',\n",
       " 'Comcast Corp',\n",
       " 'Netflix Inc',\n",
       " 'Abbott Laboratories',\n",
       " 'Advanced Micro Devices Inc',\n",
       " 'T-Mobile Us, Inc.',\n",
       " 'Hdfc Bank Ltd',\n",
       " 'Intel Corp',\n",
       " 'Sap Se',\n",
       " 'Totalenergies Se',\n",
       " 'Wells Fargo & Company/Mn',\n",
       " 'Walt Disney Co',\n",
       " 'Intuit Inc.',\n",
       " 'Hsbc Holdings Plc',\n",
       " 'Texas Instruments Inc',\n",
       " 'Philip Morris International Inc.',\n",
       " 'Nike, Inc.',\n",
       " 'Invesco Qqq Trust, Series 1',\n",
       " 'Conocophillips',\n",
       " 'Morgan Stanley',\n",
       " 'Bhp Group Ltd',\n",
       " 'Verizon Communications Inc',\n",
       " 'Caterpillar Inc',\n",
       " 'Nextera Energy Inc',\n",
       " 'Amgen Inc',\n",
       " 'Blackstone Inc.',\n",
       " 'Sanofi',\n",
       " 'United Parcel Service Inc',\n",
       " 'International Business Machines Corp',\n",
       " 'Lowes Companies Inc',\n",
       " 'Pdd Holdings Inc.',\n",
       " 'Union Pacific Corp',\n",
       " 'Honeywell International Inc',\n",
       " 'Unilever Plc',\n",
       " 'Qualcomm Inc/De',\n",
       " 'Boeing Co',\n",
       " 'Royal Bank Of Canada',\n",
       " 'Bristol Myers Squibb Co',\n",
       " 'S&P Global Inc.',\n",
       " 'General Electric Co',\n",
       " 'Applied Materials Inc /De',\n",
       " 'Rio Tinto Ltd',\n",
       " 'Servicenow, Inc.',\n",
       " 'American Express Co',\n",
       " 'Deere & Co',\n",
       " 'Airbus Se/Adr',\n",
       " 'Stryker Corp',\n",
       " 'Prologis, Inc.',\n",
       " 'Booking Holdings Inc.',\n",
       " 'Starbucks Corp',\n",
       " 'Anheuser-Busch Inbev Sa/Nv',\n",
       " 'Toronto Dominion Bank',\n",
       " 'Rtx Corp']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f6cd413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    q = Embeddings().getTensor([\"Rtx\"])\n",
    "    xb = encoder_classifier(inputs).cpu().detach().numpy()\n",
    "    xq = encoder_classifier(q).cpu().detach().numpy()\n",
    "    xq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3b8564fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "    \n",
    "class Faiss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def faiss(self,xb):\n",
    "        d = xb[0].size\n",
    "        M = 32\n",
    "        index = faiss.IndexHNSWFlat(d, M)            \n",
    "        index.hnsw.efConstruction = 40         # Setting the value for efConstruction.\n",
    "        index.hnsw.efSearch = 16               # Setting the value for efSearch.\n",
    "        index.add(xb)\n",
    "        return index\n",
    "    \n",
    "    def query(self,index,xq,k=3):\n",
    "        D, I = index.search(xq, k)   \n",
    "        return D, I\n",
    "    \n",
    "\n",
    "index = Faiss().faiss(xb)\n",
    "D,I = Faiss().query(index,xq)\n",
    "I = I[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9d236c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([99,  7, 15])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b5a3eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rtx Corp Meta Platforms, Inc. Jpmorgan Chase & Co\n"
     ]
    }
   ],
   "source": [
    "print(data[I[0]], data[I[1]], data[I[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f053fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerClassifier(config)\n",
    "\n",
    "# Save the entire model\n",
    "torch.save(model, '../model/transformer_classifier_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4782426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../model/transformer_classifier_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1aa5fa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3505496e+00, -0.0000000e+00,  1.0903112e+00,  2.2117975e+00,\n",
       "         8.6265182e-01,  2.8462455e+00, -1.8359869e+00, -1.2350719e+00,\n",
       "         6.0446796e+00, -0.0000000e+00,  8.6977065e-01, -2.1661969e-02,\n",
       "        -6.1760110e-01,  2.6821241e+00, -9.9749941e-01, -1.6994071e+00,\n",
       "        -1.2452182e+00,  1.7675917e+00, -3.3013339e+00,  2.3750708e+00,\n",
       "        -0.0000000e+00, -1.3645170e+00,  1.9900595e+00,  4.4813614e+00,\n",
       "         2.5450987e-01,  1.8310524e+00,  6.3948996e-02,  3.5722333e-01,\n",
       "        -4.7792560e-01,  6.1968966e+00, -8.1963480e-01,  1.4825616e+00,\n",
       "         3.2396233e+00, -0.0000000e+00,  7.6081905e+00,  4.7303388e-01,\n",
       "         9.6134752e-01, -1.8100398e+00,  2.3863897e+00,  3.1016536e+00,\n",
       "        -4.0779333e+00, -1.3829366e+00, -5.4978627e-01, -1.4381657e+00,\n",
       "        -1.9393079e+00,  7.0081747e-01,  3.2967257e+00,  5.9542090e-01,\n",
       "        -0.0000000e+00, -1.4870367e+00,  1.5988714e+00, -4.2289000e+00,\n",
       "        -2.6311826e-02, -6.3320732e-01,  2.5867221e-01,  3.7862086e-01,\n",
       "        -0.0000000e+00,  6.5280579e-02,  1.6337132e+00, -0.0000000e+00,\n",
       "         2.8429502e-01,  1.8625308e+00, -2.8504722e+00, -4.1602635e+00,\n",
       "        -1.1102424e+00, -1.6909477e+00, -0.0000000e+00,  1.3178442e+00,\n",
       "         4.0124779e+00, -3.5660443e+00,  0.0000000e+00,  3.6661294e-01,\n",
       "        -1.3632857e+00, -1.5987365e+00, -7.3488224e-01,  1.2632365e+00,\n",
       "         3.5990078e+00,  2.4528003e+00, -1.6798797e+00, -3.3861136e+00,\n",
       "        -3.2699387e+00,  5.0336742e-01, -8.7232029e-01,  1.4857818e+00,\n",
       "         2.2784462e+00,  2.6253253e-01,  4.0501988e-01,  1.2532208e-02,\n",
       "         4.4696331e+00, -1.8329495e+00, -9.4995695e-01,  2.0660741e+00,\n",
       "         1.0655316e+00, -2.0107861e+00, -8.6078758e+00, -4.7709292e-01,\n",
       "         1.1664181e+00, -0.0000000e+00,  2.9422314e+00,  2.0185187e-01,\n",
       "        -1.6515006e+00, -8.2072198e-01,  1.6321452e+00, -1.3345426e+00,\n",
       "         3.5053103e+00, -5.9259295e-01,  0.0000000e+00,  2.6050482e+00,\n",
       "        -1.8794405e-01, -1.4390234e+00, -9.9710906e-01, -0.0000000e+00,\n",
       "        -1.8882703e+00, -1.5041156e+00, -8.9921331e-01,  3.5171676e+00,\n",
       "        -2.5332108e-02, -1.7144113e+00, -1.0489183e-01,  0.0000000e+00,\n",
       "        -0.0000000e+00,  6.6898489e-01,  1.0629938e+00, -5.4820294e+00,\n",
       "        -5.2954614e-01,  2.1862769e+00, -3.4872327e+00,  3.4137657e+00,\n",
       "         4.7237429e-01, -5.0437655e+00,  1.9787066e+00, -2.9876254e+00,\n",
       "         1.7717425e+00,  0.0000000e+00,  3.0355415e+00, -2.2518253e+00,\n",
       "         3.7296665e+00,  1.9888624e+00, -8.7476218e-01,  0.0000000e+00,\n",
       "        -7.7013183e-01, -9.5161748e-01, -1.4809773e+00, -6.7603028e-01,\n",
       "        -1.8794456e+00,  1.0398974e+00, -2.2495367e-01, -4.3373957e+00,\n",
       "        -2.8689144e+00,  2.8040800e+00,  3.3509624e-01, -1.0502124e+00,\n",
       "         1.3053789e+00,  3.5932890e-01, -5.0185400e-01, -1.3772095e+00,\n",
       "        -4.0189597e-01,  0.0000000e+00, -2.0629203e+00,  2.1110797e+00,\n",
       "        -3.5104125e+00, -1.6595925e+00, -5.4182678e-01, -1.9784410e+00,\n",
       "         2.2006385e+00, -1.3818458e+00, -1.0869198e+00, -1.5149851e+00,\n",
       "         1.1311227e-01, -7.3789823e-01,  8.7987685e-01, -8.2646352e-01,\n",
       "        -5.6208291e+00,  3.2507415e+00,  8.5036278e-01,  2.0607121e-01,\n",
       "        -2.0594521e+00, -4.3655801e+00, -3.7881672e+00, -1.9908071e+00,\n",
       "        -5.5362421e-01, -2.9948184e-01, -3.3320673e+00,  0.0000000e+00,\n",
       "        -5.9803212e-01, -4.0030136e+00,  1.3107033e+00, -2.4114678e+00,\n",
       "        -1.6453034e+00, -2.8974798e-01, -4.6738238e+00, -0.0000000e+00,\n",
       "        -1.5864537e+00, -1.4274300e+00,  1.9782586e+00, -2.0265276e+00,\n",
       "        -8.6552960e-01,  3.7870094e-01, -1.7730801e-01, -2.0411577e+00,\n",
       "         9.9706727e-01,  4.1086927e-01, -2.7878516e+00,  1.8840122e+00,\n",
       "         5.6537974e-01, -6.6474611e-01, -9.4507158e-01,  2.8348944e-01,\n",
       "         0.0000000e+00,  5.7589442e-01,  9.9657559e-01,  2.3982127e+00,\n",
       "        -1.6364580e+00,  1.1750256e+00, -7.0779288e-01, -2.1624506e+00,\n",
       "        -5.1497130e+00, -7.0802915e-01, -5.5145085e-01, -2.0962752e-01,\n",
       "        -1.2034945e+00,  2.0677332e-02,  3.0878830e-01, -9.7250730e-01,\n",
       "        -6.0789913e-01, -5.1159799e-01,  1.5410554e+00,  1.2468163e+00,\n",
       "        -5.6428561e+00, -5.7892885e-02,  6.6572642e-01,  1.1158334e+00,\n",
       "        -3.6849725e+00, -4.9530715e-01,  1.2348461e+00,  5.2712665e+00,\n",
       "         1.6410772e+00, -8.5886824e-01,  5.1860249e-01, -1.8807796e+00,\n",
       "        -0.0000000e+00,  3.8518856e+00, -1.8790472e-01,  1.7013351e+00,\n",
       "         0.0000000e+00, -1.4152054e+00,  2.6752217e+00, -4.2564753e-02,\n",
       "        -1.2871541e+00, -3.8146669e-01, -2.6246378e-01, -2.4723864e+00,\n",
       "         6.8853170e-01, -2.5103600e+00,  4.5259547e-01, -1.8556533e-02,\n",
       "         2.0763955e+00, -6.6162863e+00, -2.3963439e+00,  1.3820746e+00,\n",
       "        -7.4405245e-02,  6.6568720e-01, -4.0096140e-01,  6.9418889e-01,\n",
       "         9.2739171e-01, -2.7336566e+00,  3.1114073e+00, -3.4362772e-01,\n",
       "        -2.2941284e+00, -9.6394026e-01,  1.2207913e+00, -1.9898607e+00,\n",
       "        -1.0646437e+00, -2.4016391e-01,  1.0530769e+00,  1.7569418e+00,\n",
       "        -3.6566715e+00, -1.8170968e+00,  0.0000000e+00,  9.2916900e-01,\n",
       "         6.4611882e-01,  2.9661167e-01, -2.7119645e-01,  1.4279042e-01,\n",
       "        -4.1704273e+00, -2.3262818e+00, -2.0110695e+00,  2.1420586e+00,\n",
       "         1.7340307e+00,  2.4157176e+00,  3.3744535e+00,  4.3216600e+00,\n",
       "        -2.3256834e-01, -9.1186875e-01,  4.5603100e-02,  1.1091365e+00,\n",
       "         1.5445809e-01, -1.4553014e+00, -1.1480343e+00,  1.2871773e+00,\n",
       "         0.0000000e+00,  1.1139142e-01, -2.5499341e+00,  1.4907311e-01,\n",
       "        -1.7147734e+00,  0.0000000e+00,  1.0855081e+00,  0.0000000e+00,\n",
       "         1.7986807e-01,  3.7608426e+00,  2.5973475e+00, -5.1578727e+00,\n",
       "        -2.9422467e+00, -0.0000000e+00,  8.7895580e-02, -7.7374619e-01,\n",
       "         4.0429282e-01, -1.5819197e+00,  1.2440348e+00, -1.5250539e+00,\n",
       "         5.2748197e-01, -4.0513405e-01,  1.1675254e+00,  3.1379209e+00,\n",
       "        -2.1622810e+00, -1.6639867e+00, -2.0461414e+00,  9.6735746e-01,\n",
       "         1.8028808e+00, -2.9185681e+00, -4.4209293e-01,  0.0000000e+00,\n",
       "        -1.2505462e+00, -1.4244881e-01,  2.7773640e+00,  4.6562880e-01,\n",
       "        -0.0000000e+00, -1.4478074e+00, -6.6151053e-01,  1.3546938e-01,\n",
       "        -1.9752375e+00, -0.0000000e+00,  2.4880877e+00,  1.4569677e+00,\n",
       "        -0.0000000e+00, -4.3155742e+00,  5.4556715e-01,  9.0153110e-01,\n",
       "        -2.7556413e-01,  4.2084032e-01,  1.1259015e+00, -2.9463041e-01,\n",
       "        -4.9945822e-01,  6.8527383e-01,  5.9323210e-01, -1.6974050e+00,\n",
       "        -4.6295825e-01, -1.5502043e-01, -1.3985238e+00, -1.6547048e+00,\n",
       "        -6.7959815e-01,  7.5674284e-01, -3.6049175e+00, -9.4730681e-01,\n",
       "         9.3674564e-01, -0.0000000e+00, -1.3346667e+00,  4.2689577e-02,\n",
       "        -4.4815204e-01, -5.7784624e+00, -1.3348666e+00, -6.4352834e-01,\n",
       "        -1.5075262e+00,  1.0118940e+00,  1.6596893e+00, -1.8041326e+00,\n",
       "         3.3323196e-01, -2.7964451e+00,  1.0855279e+00, -2.4392397e+00,\n",
       "        -0.0000000e+00,  2.8552158e+00,  2.3008759e+00,  9.0928090e-01,\n",
       "        -1.6047224e+00, -8.8534719e-01,  1.5571182e+00, -6.3587511e-01,\n",
       "         1.6728288e+00,  0.0000000e+00,  3.4188144e+00, -5.8234684e-02,\n",
       "         6.1872751e-01,  2.1156158e+00,  1.2577249e+00,  9.2930561e-01,\n",
       "         1.5020843e+00, -0.0000000e+00, -7.4088231e-02, -1.2175846e+00,\n",
       "        -9.3575829e-01, -3.8962197e+00, -8.9433771e-01,  0.0000000e+00,\n",
       "         2.4684634e+00,  2.2681773e+00, -0.0000000e+00,  6.6521174e-01,\n",
       "         8.2888854e-01,  2.2361526e+00, -1.6520334e+00,  5.4078990e-01,\n",
       "        -1.0054256e+00, -8.9700264e-01, -3.4120049e+00,  0.0000000e+00,\n",
       "         1.8644788e+00, -1.9156258e+00, -4.1696525e+00,  1.7403197e+00,\n",
       "         3.0162601e+00, -1.9483616e+00,  6.5985340e-01, -4.0409575e+00,\n",
       "        -7.7615929e-01,  3.0575490e+00,  8.0820352e-01, -1.2329929e+00,\n",
       "        -1.9295063e+00, -2.4109067e-01,  0.0000000e+00,  7.2570586e-01,\n",
       "         3.0720937e+00,  0.0000000e+00, -8.8735461e-02,  1.4073951e+00,\n",
       "        -1.9196107e+00, -9.6912396e-01,  1.5111691e+00, -1.2685920e+00,\n",
       "         5.3061992e-01, -1.0528033e+00, -4.3376536e+00,  9.0838772e-01,\n",
       "         2.4082382e+00,  9.1009599e-01,  1.2704030e+00, -0.0000000e+00,\n",
       "        -1.0463542e+00,  0.0000000e+00,  3.6779636e-01,  1.3656694e-01,\n",
       "         1.0550370e+00, -1.5174772e+00, -5.5893332e-01,  0.0000000e+00,\n",
       "         1.0252659e+00,  5.2125740e-01, -2.0020647e+00,  4.4612694e-01,\n",
       "        -3.6415825e+00, -2.0611510e+00, -0.0000000e+00, -3.9016023e+00,\n",
       "        -9.5556134e-01, -1.6090913e+00,  7.9685730e-01,  1.2962090e+00,\n",
       "        -4.1714311e+00,  3.3156557e+00,  1.0915025e+00, -1.8437685e+00,\n",
       "         2.6048514e-01,  0.0000000e+00,  9.6154743e-01,  0.0000000e+00,\n",
       "        -1.0572842e+00,  2.7738887e-01,  3.0044131e+00, -0.0000000e+00,\n",
       "         0.0000000e+00, -3.8079622e-01,  9.0644789e-01,  1.2826275e+00,\n",
       "         1.8151363e+00, -1.4954207e+00, -4.4653091e-01, -2.7407491e+00,\n",
       "         9.3329287e-01,  9.4834274e-01,  0.0000000e+00, -3.5264544e+00,\n",
       "        -1.7005577e+00,  4.0745586e-01, -2.6293093e-01,  1.2479341e+00,\n",
       "         9.2744273e-01,  3.2195222e-01, -1.2260821e+00, -2.2517684e-01,\n",
       "         9.6241373e-01, -6.2870163e-01, -1.4413307e+00, -5.0356120e-01,\n",
       "        -0.0000000e+00,  2.5853474e+00,  1.3281808e+00,  1.3549387e-01,\n",
       "         0.0000000e+00,  2.1242473e+00,  1.3573183e+00,  2.2375274e+00,\n",
       "        -1.4242312e+00,  1.4261230e+00, -0.0000000e+00,  5.9261131e-01,\n",
       "        -4.2213550e+00,  1.0690870e+00, -2.0461726e+00,  2.0529665e-01,\n",
       "        -6.0780466e-01, -2.6103570e+00,  2.3835275e+00, -5.6160655e-02,\n",
       "         1.6382653e+00, -5.6678641e-01, -1.0567712e+00, -1.5185739e+00,\n",
       "        -1.0463518e+00,  6.7856246e-01,  0.0000000e+00,  4.4364581e+00,\n",
       "        -1.7412502e+00,  3.2866182e+00,  2.7022654e-01, -4.3067643e-01,\n",
       "        -2.4910875e-01,  6.6850907e-01,  2.8601859e+00, -2.8243284e+00,\n",
       "         0.0000000e+00, -0.0000000e+00,  1.6076143e-01, -5.9229178e+00,\n",
       "        -0.0000000e+00, -4.3768449e+00, -2.5210998e+00,  0.0000000e+00,\n",
       "        -0.0000000e+00,  1.1731501e+00,  0.0000000e+00,  2.2221050e-01,\n",
       "         1.9507010e+00, -1.9709374e+00, -1.2982126e+00, -6.2005520e-01,\n",
       "         0.0000000e+00,  3.6390274e+00, -3.8634727e+00,  0.0000000e+00,\n",
       "        -3.9509121e-01,  4.8043342e+00,  1.1783450e+00, -2.2490396e+00,\n",
       "        -0.0000000e+00, -1.2319415e+00, -2.2939928e+00,  0.0000000e+00,\n",
       "         1.1083506e+00, -2.4834502e+00,  2.8621349e+00, -1.9515573e+00,\n",
       "         3.6186855e+00,  2.1137285e+00, -0.0000000e+00, -9.4616890e-01,\n",
       "         3.5455136e+00,  4.8315778e+00,  1.8244249e+00, -6.2140882e-02,\n",
       "         2.7764454e-01, -1.7906505e+00,  6.5718017e+00, -0.0000000e+00,\n",
       "         4.3985548e+00,  2.0830278e+00, -4.2008996e-01, -1.8079046e+00,\n",
       "        -0.0000000e+00,  7.5267380e-01,  1.7421784e+00, -3.8088310e-01,\n",
       "        -1.1004374e+00, -7.3821938e-01, -5.7378399e-01,  5.9328759e-01,\n",
       "        -1.1045234e+00, -3.1183829e+00, -1.4606656e+00, -3.9754970e+00,\n",
       "         2.7799776e-01,  1.6257781e+00, -0.0000000e+00,  1.9657303e+00,\n",
       "         2.2916005e+00, -1.5766384e-01,  3.5298853e+00,  1.4990323e+00,\n",
       "         8.0217457e-01, -2.4378600e+00, -1.1392403e-01,  1.6458231e+00,\n",
       "         2.4266775e+00,  3.4621501e+00,  6.8886608e-01,  5.9225373e+00,\n",
       "         6.4669514e-01, -1.4775335e+00,  6.6917396e-01, -4.8936163e-03,\n",
       "         9.0359849e-01,  1.6012267e+00,  2.0894781e-03, -7.7094746e-01,\n",
       "        -9.3654758e-01,  1.4656414e+00,  1.1613185e+00,  1.3492887e-01,\n",
       "        -1.4928941e+00, -1.6821700e-01, -0.0000000e+00,  3.4249103e+00,\n",
       "         2.6266773e+00, -2.5089695e+00, -8.8196433e-01,  2.3284662e+00,\n",
       "        -3.8798854e-01,  2.3688242e+00, -1.9169807e+00,  0.0000000e+00,\n",
       "         6.3551158e-02,  2.9513273e+00,  1.5619171e-01,  5.0672946e+00,\n",
       "         2.3480811e+00, -3.0020192e+00,  9.7514576e-01,  2.6343575e+00,\n",
       "        -5.7295179e-01,  7.7306566e+00,  3.4521074e+00, -5.4964596e-01,\n",
       "         8.2866329e-01,  4.5859936e-01,  9.2985117e-01,  2.0985833e-01,\n",
       "        -2.6378102e+00,  1.5660255e+00,  1.2973911e+00, -1.6545999e+00,\n",
       "         3.0806952e+00, -1.1345862e+00, -1.8186096e+00,  4.0246592e+00,\n",
       "         4.0081773e+00, -4.1190594e-01, -3.9660650e-01,  5.7662401e+00,\n",
       "        -7.8442030e+00, -9.1865623e-01, -2.0125492e+00,  1.4248543e+00,\n",
       "         2.2881978e+00, -8.0176342e-01,  1.2913258e+00,  2.4420230e+00,\n",
       "         3.3787818e+00, -3.7146199e-01, -4.9545991e-01,  1.0160041e+00,\n",
       "        -4.4993081e+00, -1.9576820e+00,  0.0000000e+00,  2.9562845e+00,\n",
       "        -6.3731307e-01,  4.3663816e+00, -1.0983988e+00, -1.0005041e+00,\n",
       "        -0.0000000e+00,  1.6259458e+00,  1.9370834e+00,  1.1616915e+00,\n",
       "        -2.5012653e+00,  6.9244772e-02,  3.4663394e-01, -1.9843100e+00,\n",
       "         1.1832154e+00, -3.4848325e+00, -0.0000000e+00, -1.5368168e+00,\n",
       "         2.1506267e+00, -1.8417206e+00, -1.5462571e+00,  3.3831590e-01,\n",
       "        -1.0081792e-01, -3.8270190e+00,  2.7563164e+00,  8.6709303e-01,\n",
       "         1.2864503e+00,  2.2984776e-01, -6.8486832e-02,  1.5072687e+00,\n",
       "        -1.6799216e+00, -1.3592523e+00, -2.7394526e+00,  1.0799149e+00,\n",
       "        -2.2910776e+00,  4.0969357e+00, -2.0470734e+00, -9.0679365e-01,\n",
       "        -4.4970770e+00, -5.6375299e+00, -7.8466392e-01, -7.0126796e-01,\n",
       "        -3.8779204e+00, -2.6306298e-01,  2.5086248e+00, -2.0168188e+00,\n",
       "         1.5207075e+00, -0.0000000e+00,  1.9482659e+00, -1.8504931e+00,\n",
       "        -4.3025482e-02, -1.1815121e-01, -8.4651220e-01,  3.0211875e+00,\n",
       "        -2.6536069e+00, -3.8217902e-02, -1.3618071e+00,  1.0805089e+00,\n",
       "        -1.5327730e+00,  3.0200718e-02, -2.6352608e-01,  0.0000000e+00,\n",
       "         7.7069432e-01,  2.4912114e+00,  0.0000000e+00, -1.7367233e-01,\n",
       "         4.4762503e-02, -1.2893622e+00,  4.2010176e-01,  2.6590519e+00,\n",
       "         2.9443903e+00,  2.6347377e+00, -3.2115823e-01, -7.5103617e+00,\n",
       "         8.3806135e-02,  3.0643268e+00, -2.5568597e+00,  1.4780993e+00,\n",
       "         7.8467214e-01,  8.7951761e-01, -0.0000000e+00, -9.0140742e-01,\n",
       "         1.9512515e+00,  5.8911552e+00, -8.3450592e-01,  8.9730084e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq = model(q).cpu().detach().numpy()\n",
    "xq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "db7a14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ccec12ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "with torch.no_grad():\n",
    "    output = model(q)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9d079a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.detach().numpy().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2da4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.261257,
   "end_time": "2023-11-07T12:12:13.753168",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-07T12:11:25.491911",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f54ff68288a47e4ab08fe1bbfc33d55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_23e2a9ed016a4afcbce85d623df9d64e",
       "max": 28,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fa9b11bb2bba4257a632795bfe9f9b6e",
       "value": 28
      }
     },
     "0f6539d2bc1244888a6850ce92c31d4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ac3fe35df01454abc6b7a3bfdf4df94",
        "IPY_MODEL_dcad6910ef2b43e7a8001ab17ab10112",
        "IPY_MODEL_57bbb2ada9f0494aa4335a1418e1809e"
       ],
       "layout": "IPY_MODEL_79f1527694f74b80a5330cf6f99ea84e"
      }
     },
     "0fb39f643b2f4811be0d0c3409323d80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "17348793a7bb456bbb5ace7f13f537f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_98d3a93be64a4c01a2d1c98d00515f5a",
       "placeholder": "​",
       "style": "IPY_MODEL_4698dfa31864465ab5841f5b2d8c6e5c",
       "value": " 570/570 [00:00&lt;00:00, 25.3kB/s]"
      }
     },
     "1ac3fe35df01454abc6b7a3bfdf4df94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f5a281ae964e44528a7773b0213cb3a9",
       "placeholder": "​",
       "style": "IPY_MODEL_4c762ca4426949989ec3bf96ef853188",
       "value": "Downloading: 100%"
      }
     },
     "23e2a9ed016a4afcbce85d623df9d64e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c55c0d364b742ed8da1f4194e9d73db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ecc0ca0282a4b51a9f47f299ddb0e25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "402bec0969c2439d9fe12534438cfd18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4698dfa31864465ab5841f5b2d8c6e5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c762ca4426949989ec3bf96ef853188": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "508357fee53643ae9bbc41e2cbb0c6b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52ea49af22194ceeb7d0014756942b23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5653cd0054e34263946603a7d6c3e3b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "57bbb2ada9f0494aa4335a1418e1809e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_caf3de995ab1481fadb9cf72b9c573fc",
       "placeholder": "​",
       "style": "IPY_MODEL_0fb39f643b2f4811be0d0c3409323d80",
       "value": " 226k/226k [00:00&lt;00:00, 4.39MB/s]"
      }
     },
     "5865b31e0bf24e4e80dd75fa252761e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58ec168261d746b2a2a803f6a87449c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "656311e69fa04ec7b6ddb361d470b11b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67c471286bcd4dcbb385a93887879a02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "694fd1a41ff147edb6eb32dd33fdb7c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b365053df97498e956e67bbe6b9ccfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2ecc0ca0282a4b51a9f47f299ddb0e25",
       "placeholder": "​",
       "style": "IPY_MODEL_5653cd0054e34263946603a7d6c3e3b8",
       "value": "Downloading: 100%"
      }
     },
     "6d448241463c48228efdfbe658d57acf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6d59d2793acc4f30a0537f06d94c947b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "76a8d4885d704b68a49cc354bd98162d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_67c471286bcd4dcbb385a93887879a02",
       "placeholder": "​",
       "style": "IPY_MODEL_834207598a374281ab4b2457b33ac1f1",
       "value": "Downloading: 100%"
      }
     },
     "7909f11c3d9d4884bef998dc86c6c433": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_694fd1a41ff147edb6eb32dd33fdb7c7",
       "placeholder": "​",
       "style": "IPY_MODEL_402bec0969c2439d9fe12534438cfd18",
       "value": " 455k/455k [00:00&lt;00:00, 5.73MB/s]"
      }
     },
     "79f1527694f74b80a5330cf6f99ea84e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d3e823820b9404eb59a5fc22f235788": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7efc71dd48044f4182faee7196648d75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_656311e69fa04ec7b6ddb361d470b11b",
       "max": 570,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_52ea49af22194ceeb7d0014756942b23",
       "value": 570
      }
     },
     "834207598a374281ab4b2457b33ac1f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9444d2913a734d248a9741f3727b10f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98d3a93be64a4c01a2d1c98d00515f5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c01269053814648ac62141686c8ff2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a28f0dbdde2448c4b1a3290a62c43eba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6b365053df97498e956e67bbe6b9ccfd",
        "IPY_MODEL_7efc71dd48044f4182faee7196648d75",
        "IPY_MODEL_17348793a7bb456bbb5ace7f13f537f6"
       ],
       "layout": "IPY_MODEL_7d3e823820b9404eb59a5fc22f235788"
      }
     },
     "a80cfef718d84bc8967f53cdf83a5986": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_508357fee53643ae9bbc41e2cbb0c6b0",
       "max": 466062,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6d59d2793acc4f30a0537f06d94c947b",
       "value": 466062
      }
     },
     "acf742bc1b9b4f71ae1f9ec994d85847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b8784b0f034242d3b9551a4b45615e53",
       "placeholder": "​",
       "style": "IPY_MODEL_9c01269053814648ac62141686c8ff2a",
       "value": " 28.0/28.0 [00:00&lt;00:00, 1.15kB/s]"
      }
     },
     "b4e4504a77a3486b9f66e38cebc63182": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8784b0f034242d3b9551a4b45615e53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c067bf2601a84417bf052635a54ef790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ce198efee07e4dd582a7c889f3b5f6d9",
        "IPY_MODEL_a80cfef718d84bc8967f53cdf83a5986",
        "IPY_MODEL_7909f11c3d9d4884bef998dc86c6c433"
       ],
       "layout": "IPY_MODEL_9444d2913a734d248a9741f3727b10f9"
      }
     },
     "c61426e6570245e6b1c07b09149e61bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_76a8d4885d704b68a49cc354bd98162d",
        "IPY_MODEL_0f54ff68288a47e4ab08fe1bbfc33d55",
        "IPY_MODEL_acf742bc1b9b4f71ae1f9ec994d85847"
       ],
       "layout": "IPY_MODEL_5865b31e0bf24e4e80dd75fa252761e1"
      }
     },
     "caf3de995ab1481fadb9cf72b9c573fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce198efee07e4dd582a7c889f3b5f6d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2c55c0d364b742ed8da1f4194e9d73db",
       "placeholder": "​",
       "style": "IPY_MODEL_6d448241463c48228efdfbe658d57acf",
       "value": "Downloading: 100%"
      }
     },
     "dcad6910ef2b43e7a8001ab17ab10112": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b4e4504a77a3486b9f66e38cebc63182",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_58ec168261d746b2a2a803f6a87449c5",
       "value": 231508
      }
     },
     "f5a281ae964e44528a7773b0213cb3a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa9b11bb2bba4257a632795bfe9f9b6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
