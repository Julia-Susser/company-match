{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e9a7e8",
   "metadata": {
    "papermill": {
     "duration": 0.009019,
     "end_time": "2023-11-07T12:11:42.558290",
     "exception": false,
     "start_time": "2023-11-07T12:11:42.549271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>1 |</span></b> <b>BACKGROUND</b></div>\n",
    "\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>ENCODER BASE</span></b></p></div>\n",
    "\n",
    "In the following notebook, we'll look at the following components of the Transformer Encoder structure\n",
    "\n",
    "<div style=\" background-color:#3b3745; padding: 13px 13px; border-radius: 8px; color: white\">\n",
    "    \n",
    "<ul>\n",
    "<li>Simple Attention</li>\n",
    "<li>Multi-Head Self Attention</li>\n",
    "<li>Feed Forward Layer</li>\n",
    "<li>Normalisation</li>\n",
    "<li>Skip Connection</li>\n",
    "<li>Position Embeddings</li>\n",
    "<li>Transformer Encoder</li>\n",
    "<li>Classifier Head</li>\n",
    "</ul> \n",
    "</div> \n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>ENCODER BASE</span></b></p></div>\n",
    "\n",
    "Encoder simply put:\n",
    "- Converts a **series tokens** into a **series of embedding vectors** (hidden state)\n",
    "- The encoder (neural network) consists of **multiple layers** (**blocks**) constructed together \n",
    "\n",
    "The encoder structure:\n",
    "- Composed of multiple encoder layers (blocks) stacked next to each other (similar to CNN layer stacks)\n",
    "- Each encoder block contains **multi-head self attention** & **fully connected feed forward layer** (for each input embedding)\n",
    "\n",
    "Purpose of the Encoder\n",
    "- Input tokens are encoded & modified into a form that **stores some contextual information** in the sequence\n",
    "\n",
    "The example we'll use:\n",
    "\n",
    "> the bark of a palm tree is very rough\n",
    "\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>CLASSIFICATION HEAD</span></b></p></div>\n",
    "\n",
    "- Transformers can be utilised for various application so they are created in a base form\n",
    "- If we want to utilise them for a specific task, we add an extra component **head** to the transformer\n",
    "- In this example, we'll utilise it for **classification** purposes, and look at how we can combine the base with the **head**\n",
    "\n",
    "\n",
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>2 |</span></b> <b>SIMPLE SELF ATTENTION</b></div>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>TYPES OF ATTENTION</span></b></p></div>\n",
    "\n",
    "**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention</mark>**\n",
    " \n",
    "- Mechanism which allows networks to assign **different weight distributions to each element** in a sequence \n",
    "- Elements in sequence - `token embeddings` (each token mapped to a vector of fixed dimension) (eg. BERT model - 768 dimensions)\n",
    " \n",
    " \n",
    "**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">self-attention</mark>**\n",
    "\n",
    "- Instead of using fixed embeddings for each token, can use whole sequence to **compute weighted average** of each `embedding`\n",
    "- One can think of self-attention as a form of averaging\n",
    "- Common form of `self-attention` **scaled dot-product attention** \n",
    "\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>FOUR MAIN STEPS</span></b></p></div>\n",
    "\n",
    "\n",
    "- Project each `token embedding` into three vectors **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">query</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">key</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>**\n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** (nxn)\n",
    "\n",
    "    - (we determine how much the query & key vectors relate to eachother using a similarity function)\n",
    "    - Similarity function for scaled dot-product attention - dot product\n",
    "    - queries & keys that are similar will have large dot product & visa versa\n",
    "    - Outputs from this step - attention scores\n",
    "    \n",
    "    \n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weight</mark>** (wij)\n",
    "\n",
    "    - dot products produce large numbers \n",
    "    - attention scores first multiplied by a scaling factor to normalise their variance\n",
    "    - Then normalised with softmax to ensure all column values sum to 1\n",
    "    \n",
    "    \n",
    "- Update the token embeddings (hidden state)\n",
    "\n",
    "    - multiply the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">weights</mark>** by the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>** vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55217be8",
   "metadata": {
    "papermill": {
     "duration": 0.009999,
     "end_time": "2023-11-07T12:11:42.577461",
     "exception": false,
     "start_time": "2023-11-07T12:11:42.567462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#F1A424;text-align:center'>SIMPLE ATTENTION FORMULATION</span></b></p></div>\n",
    "\n",
    "\n",
    "- Well look at a simple example, and summarise the attention mechanism in one function\n",
    "- `bert-base-uncased` model will be used to extract different model settings (eg. number of attention heads), so we will be building a similar model \n",
    "\n",
    "<br>\n",
    "\n",
    "##### **1. DOCUMENT TOKENISATION**\n",
    "\n",
    "- Each token in the sentence has been mapped to a **unique identifier** from a **vocabulary** or **dictionary**\n",
    "- We start off by using the `bert-base-uncased` pretrained tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "35551bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:11:42.597284Z",
     "iopub.status.busy": "2023-11-07T12:11:42.596990Z",
     "iopub.status.idle": "2023-11-07T12:12:00.483141Z",
     "shell.execute_reply": "2023-11-07T12:12:00.482187Z"
    },
    "papermill": {
     "duration": 17.898714,
     "end_time": "2023-11-07T12:12:00.485317",
     "exception": false,
     "start_time": "2023-11-07T12:11:42.586603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from bertviz.transformers_neuron_view import BertModel\n",
    "\n",
    "# load tokeniser and model\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = BertModel.from_pretrained(model_ckpt)\n",
    "\n",
    "# document well be using as an exmaple\n",
    "text = [\"the bark of a palm tree is very rough of off\", \"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "63f10c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:00.517236Z",
     "iopub.status.busy": "2023-11-07T12:12:00.516931Z",
     "iopub.status.idle": "2023-11-07T12:12:00.533190Z",
     "shell.execute_reply": "2023-11-07T12:12:00.532308Z"
    },
    "papermill": {
     "duration": 0.034096,
     "end_time": "2023-11-07T12:12:00.535098",
     "exception": false,
     "start_time": "2023-11-07T12:12:00.501002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:748\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 748\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:720\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 11 at dim 1 (got 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [174]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Tokenise input (text)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# pytorc tensor\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# don't use pad, sep tokens\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs\u001b[38;5;241m.\u001b[39minput_ids)\n\u001b[1;32m      7\u001b[0m inputs\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39msize()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2814\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2813\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2814\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2816\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2900\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2896\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2897\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2898\u001b[0m         )\n\u001b[1;32m   2899\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2921\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2922\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2938\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2939\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3091\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3082\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3083\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3084\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3088\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3089\u001b[0m )\n\u001b[0;32m-> 3091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3109\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:515\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:223\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    219\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:764\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    760\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    761\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    762\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    763\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    765\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    766\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    767\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    768\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    769\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "# Tokenise input (text)\n",
    "inputs = tokenizer(text, \n",
    "                   return_tensors=\"pt\",      # pytorc tensor\n",
    "                   add_special_tokens=False) # don't use pad, sep tokens\n",
    "\n",
    "print(inputs.input_ids)\n",
    "inputs.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8173f0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.is_nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637453b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb56d7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:00.568327Z",
     "iopub.status.busy": "2023-11-07T12:12:00.568012Z",
     "iopub.status.idle": "2023-11-07T12:12:06.186950Z",
     "shell.execute_reply": "2023-11-07T12:12:06.186030Z"
    },
    "papermill": {
     "duration": 5.637794,
     "end_time": "2023-11-07T12:12:06.188698",
     "exception": false,
     "start_time": "2023-11-07T12:12:00.550904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the bark of a palm tree is very rough'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode sequence\n",
    "tokenizer.decode(inputs['input_ids'].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e975fd",
   "metadata": {
    "papermill": {
     "duration": 0.014971,
     "end_time": "2023-11-07T12:12:06.218934",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.203963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At this point:\n",
    "\n",
    "- `inputs.inpits_ids` A tensor of id mapped tokens\n",
    "- Token embeddings are **independent of their context**\n",
    "- **Homonyms** (same spelling, but different meaning) have the same representation\n",
    "\n",
    "Role of subsequent attention layers:\n",
    "\n",
    "- Mix the **token embeddings** to disambiguate & inform the representation of each token with the context of its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8859aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.251254Z",
     "iopub.status.busy": "2023-11-07T12:12:06.250611Z",
     "iopub.status.idle": "2023-11-07T12:12:06.511660Z",
     "shell.execute_reply": "2023-11-07T12:12:06.510800Z"
    },
    "papermill": {
     "duration": 0.279247,
     "end_time": "2023-11-07T12:12:06.513439",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.234192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 hidden size\n",
      "30522 vocabulary size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Create an embedding layer\n",
    "\n",
    "'''\n",
    "\n",
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "\n",
    "print(config.hidden_size,\"hidden size\")\n",
    "print(config.vocab_size,\"vocabulary size\")\n",
    "\n",
    "# load sample embedding layer of size (30522,758) -> same as bert-base\n",
    "token_emb = nn.Embedding(config.vocab_size,\n",
    "                         config.hidden_size)\n",
    "token_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee78d5",
   "metadata": {
    "papermill": {
     "duration": 0.015119,
     "end_time": "2023-11-07T12:12:06.544245",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.529126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **2. EMBEDDING VECTORS**\n",
    "\n",
    "\n",
    "- Convert Tokenised data into embedding data (768 dimensions) using vocab of 30522 tokens\n",
    "- Each input_ids is **mapped to one of 30522 embedding vectors** stored in nn.embedding, each with a size of 768 \n",
    "- Our output will be [batch_size,seq_len,hidden_dim] by calling `nn.Embedding(hidden)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd751b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.576500Z",
     "iopub.status.busy": "2023-11-07T12:12:06.576191Z",
     "iopub.status.idle": "2023-11-07T12:12:06.586332Z",
     "shell.execute_reply": "2023-11-07T12:12:06.585567Z"
    },
    "papermill": {
     "duration": 0.028427,
     "end_time": "2023-11-07T12:12:06.588032",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.559605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Convert Tokens to Embedding Vectors\n",
    "utilising the existing model embedding embeddings\n",
    "\n",
    "'''\n",
    "\n",
    "inputs_embeds = token_emb(inputs.input_ids)\n",
    "inputs_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3feb8277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.620723Z",
     "iopub.status.busy": "2023-11-07T12:12:06.620434Z",
     "iopub.status.idle": "2023-11-07T12:12:06.627221Z",
     "shell.execute_reply": "2023-11-07T12:12:06.626491Z"
    },
    "papermill": {
     "duration": 0.024936,
     "end_time": "2023-11-07T12:12:06.628895",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.603959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4677, -0.4390, -0.2647,  ...,  0.7357,  0.2608,  0.7767],\n",
       "         [ 0.0355, -2.2300,  1.9929,  ..., -0.1363,  0.4968,  0.4577],\n",
       "         [ 0.1232,  0.4308,  0.3070,  ..., -0.3304,  0.8665, -0.5848],\n",
       "         ...,\n",
       "         [ 0.0763,  0.9183,  0.6317,  ..., -1.3229, -1.8031,  0.5473],\n",
       "         [ 1.4331, -2.0097,  2.0351,  ..., -0.7298,  0.6222,  0.1742],\n",
       "         [-0.1593,  1.3323, -2.2000,  ...,  0.5990, -0.2788,  0.0168]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 embedding vectors of 768 dimensions\n",
    "inputs_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f90749",
   "metadata": {
    "papermill": {
     "duration": 0.014998,
     "end_time": "2023-11-07T12:12:06.659344",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.644346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **3. QUERY, KEY, VALUE VECTORS**\n",
    "\n",
    "- As the most simplistic case of attention, **we set them equal to one another**\n",
    "- Attention mechanism with equal query and key vectors will assign a **very large score to identical words in the context** (diagonal component of matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "729ded24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.690843Z",
     "iopub.status.busy": "2023-11-07T12:12:06.690541Z",
     "iopub.status.idle": "2023-11-07T12:12:06.696736Z",
     "shell.execute_reply": "2023-11-07T12:12:06.696023Z"
    },
    "papermill": {
     "duration": 0.023794,
     "end_time": "2023-11-07T12:12:06.698387",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.674593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query and key components\n",
      "\n",
      "query size: torch.Size([1, 9, 768])\n",
      "key size: torch.Size([1, 768, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "\n",
    "# setting them equal to one another\n",
    "print(\"query and key components\\n\")\n",
    "query = key = value = inputs_embeds\n",
    "print('query size:',query.size())\n",
    "dim_k = key.size(-1)   # hidden dimension \n",
    "print('key size:',key.transpose(1,2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc551bd",
   "metadata": {
    "papermill": {
     "duration": 0.01558,
     "end_time": "2023-11-07T12:12:06.729699",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.714119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **4. COMPUTE ATTENTION SCORES**\n",
    "\n",
    "- Compute **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** using the **dot product as the similarity function**\n",
    "- `torch.bmm` - batch matrix matrix product (as we work in batches during training)\n",
    "- If we need to transpose a vector `vector.transpose(1,2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514d67e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.762745Z",
     "iopub.status.busy": "2023-11-07T12:12:06.762404Z",
     "iopub.status.idle": "2023-11-07T12:12:06.776470Z",
     "shell.execute_reply": "2023-11-07T12:12:06.775853Z"
    },
    "papermill": {
     "duration": 0.032784,
     "end_time": "2023-11-07T12:12:06.778682",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.745898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dot product (attention scores)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product & apply normalisation\n",
    "print(\"\\ndot product (attention scores)\")\n",
    "scores = torch.bmm(query, key.transpose(1,2)) / sqrt(dim_k)\n",
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46d911a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.812364Z",
     "iopub.status.busy": "2023-11-07T12:12:06.812033Z",
     "iopub.status.idle": "2023-11-07T12:12:06.818346Z",
     "shell.execute_reply": "2023-11-07T12:12:06.817521Z"
    },
    "papermill": {
     "duration": 0.025187,
     "end_time": "2023-11-07T12:12:06.819967",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.794780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[26.5574,  1.9637, -1.6792,  0.6971,  0.6886, -0.4483, -0.4606,\n",
       "           0.3681,  0.2506],\n",
       "         [ 1.9637, 25.3258, -0.8987, -0.2280, -1.6313,  0.8909, -0.7721,\n",
       "           0.6595, -1.0236],\n",
       "         [-1.6792, -0.8987, 27.3665, -0.8606, -0.0365,  0.0332, -1.8328,\n",
       "          -0.6056,  0.1560],\n",
       "         [ 0.6971, -0.2280, -0.8606, 27.1989, -1.6901, -0.7582, -0.3339,\n",
       "           2.4001, -0.2466],\n",
       "         [ 0.6886, -1.6313, -0.0365, -1.6901, 26.4779,  1.2638,  0.4562,\n",
       "          -0.6473, -0.0399],\n",
       "         [-0.4483,  0.8909,  0.0332, -0.7582,  1.2638, 27.5632, -1.2946,\n",
       "          -0.0516, -0.5878],\n",
       "         [-0.4606, -0.7721, -1.8328, -0.3339,  0.4562, -1.2946, 26.2665,\n",
       "           1.1146,  0.7085],\n",
       "         [ 0.3681,  0.6595, -0.6056,  2.4001, -0.6473, -0.0516,  1.1146,\n",
       "          29.8054,  0.6989],\n",
       "         [ 0.2506, -1.0236,  0.1560, -0.2466, -0.0399, -0.5878,  0.7085,\n",
       "           0.6989, 27.8790]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291f7de",
   "metadata": {
    "papermill": {
     "duration": 0.015722,
     "end_time": "2023-11-07T12:12:06.851771",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.836049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **5. COMPUTE ATTENTION WEIGHTS (SOFTMAX FUNCTION)**\n",
    "\n",
    "\n",
    "\n",
    "- Created a 5x5 matrix of **attention scores** per sample in the batch\n",
    "- Apply the softmax for normalisation to get the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "848e4e3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.885652Z",
     "iopub.status.busy": "2023-11-07T12:12:06.885333Z",
     "iopub.status.idle": "2023-11-07T12:12:06.894232Z",
     "shell.execute_reply": "2023-11-07T12:12:06.893421Z"
    },
    "papermill": {
     "duration": 0.02817,
     "end_time": "2023-11-07T12:12:06.896060",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.867890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sotfmax applied, attention weights :\n",
      "\n",
      "torch.Size([1, 9, 9])\n",
      "tensor([[[1.0000e+00, 2.0851e-11, 5.4578e-13, 5.8754e-12, 5.8255e-12,\n",
      "          1.8690e-12, 1.8461e-12, 4.2283e-12, 3.7595e-12],\n",
      "         [7.1446e-11, 1.0000e+00, 4.0815e-12, 7.9819e-12, 1.9618e-12,\n",
      "          2.4436e-11, 4.6325e-12, 1.9389e-11, 3.6024e-12],\n",
      "         [2.4299e-13, 5.3033e-13, 1.0000e+00, 5.5093e-13, 1.2560e-12,\n",
      "          1.3468e-12, 2.0838e-13, 7.1097e-13, 1.5227e-12],\n",
      "         [3.0934e-12, 1.2264e-12, 6.5150e-13, 1.0000e+00, 2.8424e-13,\n",
      "          7.2177e-13, 1.1033e-12, 1.6983e-11, 1.2039e-12],\n",
      "         [6.3071e-12, 6.1987e-13, 3.0543e-12, 5.8452e-13, 1.0000e+00,\n",
      "          1.1211e-11, 4.9993e-12, 1.6584e-12, 3.0442e-12],\n",
      "         [6.8354e-13, 2.6082e-12, 1.1063e-12, 5.0137e-13, 3.7870e-12,\n",
      "          1.0000e+00, 2.9322e-13, 1.0163e-12, 5.9453e-13],\n",
      "         [2.4694e-12, 1.8084e-12, 6.2607e-13, 2.8030e-12, 6.1766e-12,\n",
      "          1.0724e-12, 1.0000e+00, 1.1931e-11, 7.9493e-12],\n",
      "         [1.6427e-13, 2.1983e-13, 6.2038e-14, 1.2532e-12, 5.9507e-14,\n",
      "          1.0796e-13, 3.4651e-13, 1.0000e+00, 2.2866e-13],\n",
      "         [1.0027e-12, 2.8040e-13, 9.1216e-13, 6.0984e-13, 7.4990e-13,\n",
      "          4.3356e-13, 1.5850e-12, 1.5698e-12, 1.0000e+00]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "sum of column values:/n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"sotfmax applied, attention weights :\\n\")\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "print(weights.size())\n",
    "print(weights)\n",
    "\n",
    "print(\"\\nsum of column values:/n\")\n",
    "weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf19419",
   "metadata": {
    "papermill": {
     "duration": 0.017197,
     "end_time": "2023-11-07T12:12:06.930058",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.912861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **6. UPDATE VALUES**\n",
    "\n",
    "Multiply the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>** matrix by the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">values</mark>** vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d827e60f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:06.963834Z",
     "iopub.status.busy": "2023-11-07T12:12:06.963500Z",
     "iopub.status.idle": "2023-11-07T12:12:06.970332Z",
     "shell.execute_reply": "2023-11-07T12:12:06.969370Z"
    },
    "papermill": {
     "duration": 0.025786,
     "end_time": "2023-11-07T12:12:06.972071",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.946285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4677, -0.4390, -0.2647,  ...,  0.7357,  0.2608,  0.7767],\n",
      "         [ 0.0355, -2.2300,  1.9929,  ..., -0.1363,  0.4968,  0.4577],\n",
      "         [ 0.1232,  0.4308,  0.3070,  ..., -0.3304,  0.8665, -0.5848],\n",
      "         ...,\n",
      "         [ 0.0763,  0.9183,  0.6317,  ..., -1.3229, -1.8031,  0.5473],\n",
      "         [ 1.4331, -2.0097,  2.0351,  ..., -0.7298,  0.6222,  0.1742],\n",
      "         [-0.1593,  1.3323, -2.2000,  ...,  0.5990, -0.2788,  0.0168]]],\n",
      "       grad_fn=<BmmBackward0>)\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "attn_outputs = torch.bmm(weights, value)\n",
    "print(attn_outputs)\n",
    "print(attn_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c5cf7f",
   "metadata": {
    "papermill": {
     "duration": 0.016049,
     "end_time": "2023-11-07T12:12:07.004544",
     "exception": false,
     "start_time": "2023-11-07T12:12:06.988495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we have a general function:\n",
    "- Which inputs vectors `query`, `key` & `value` \n",
    "- Calculates the scalar dot product attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fadf54f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.039142Z",
     "iopub.status.busy": "2023-11-07T12:12:07.038780Z",
     "iopub.status.idle": "2023-11-07T12:12:07.044075Z",
     "shell.execute_reply": "2023-11-07T12:12:07.043479Z"
    },
    "papermill": {
     "duration": 0.024195,
     "end_time": "2023-11-07T12:12:07.045542",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.021347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Scalar Dot Product Attention\n",
    "scores = query*key.T / sqrt(dims)\n",
    "weight = softmax(scores) \n",
    "\n",
    "'''\n",
    "\n",
    "def sdp_attention(query, key, value):\n",
    "    dim_k = query.size(-1) # dimension component\n",
    "    sfact = sqrt(dim_k)     \n",
    "    scores = torch.bmm(query, key.transpose(1,2)) / sfact\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ff305",
   "metadata": {
    "papermill": {
     "duration": 0.0158,
     "end_time": "2023-11-07T12:12:07.077434",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.061634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>3 |</span></b> <b>MULTIHEAD SELF ATTENTION</b></div>\n",
    "\n",
    "\n",
    "- The meaning of the word will be better informed by **complementary words in the context** than by **identical words** (which gives 1)\n",
    "\n",
    "##### **SIMPLISTIC APPROACH**\n",
    "\n",
    "- We only used the embeddings \"as is\" (no linear transformation) to compute the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention scores</mark>** **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention weights</mark>**\n",
    "\n",
    "##### **BETTER APPROACH**\n",
    "\n",
    "- The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">self-attention</mark>** layer applies **three independent linear transformations (`nn.linear`) to each embedding** to generate **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">query</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">key</mark>**,**<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">value</mark>** \n",
    "- These transformations project the embeddings and **each projection carries its own set of learnable parameters** (**Weights**)\n",
    "- This **allows the self-attention layer to focus on different semantic aspects of the sequence**\n",
    "\n",
    "\n",
    "\n",
    "Its beneficial to have **multiple sets of linear projections** (each one represents an **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention head</mark>**)\n",
    "\n",
    "Why do we need more than one **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">attention head</mark>**?\n",
    "- The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">softmax</mark>** of one head tends to focus on mostly **one aspect of similarity**\n",
    "\n",
    "\n",
    "**Several heads** allows the model to **focus on several apsects at once**\n",
    "- Eg. one head can focus on subject-verb interaction, another finds nearby adjectives\n",
    "- **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">CV analogy</mark>**: filters; one filter responsible for detecting the head, another for facial features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae55c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.111569Z",
     "iopub.status.busy": "2023-11-07T12:12:07.110662Z",
     "iopub.status.idle": "2023-11-07T12:12:07.116625Z",
     "shell.execute_reply": "2023-11-07T12:12:07.116040Z"
    },
    "papermill": {
     "duration": 0.024562,
     "end_time": "2023-11-07T12:12:07.118152",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.093590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Attention Class\n",
    "\n",
    "# nn.linear : apply linear transformation to incoming data\n",
    "#             y = x * A^T + b\n",
    "# Ax = b where x is input, b is output, A is weight\n",
    "\n",
    "# calculate scaled dot product attention matrix\n",
    "# Requires embedding dimension \n",
    "# Each attention head is made of different q,k,v vectors\n",
    "\n",
    "'''\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    # initalisation \n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the three vectors\n",
    "        # input - embed_dim, output - head_dim\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    # main class operation\n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # calculate scaled dot product given a \n",
    "        attn_outputs = sdp_attention(\n",
    "            self.q(hidden_state), \n",
    "            self.k(hidden_state), \n",
    "            self.v(hidden_state))\n",
    "        \n",
    "        return attn_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647aecb",
   "metadata": {
    "papermill": {
     "duration": 0.015925,
     "end_time": "2023-11-07T12:12:07.150302",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.134377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`Attention` will be used in the construction of a model\n",
    "\n",
    "- We’ve **initialised three independent linear layers** that apply matrix multiplication to the embedding vectors to produce tensors of shape [batch_size, seq_len, head_dim]\n",
    "- Where head_dim is the number of dimensions we are projecting into\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9f47172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.184165Z",
     "iopub.status.busy": "2023-11-07T12:12:07.183786Z",
     "iopub.status.idle": "2023-11-07T12:12:07.188846Z",
     "shell.execute_reply": "2023-11-07T12:12:07.187928Z"
    },
    "papermill": {
     "duration": 0.024268,
     "end_time": "2023-11-07T12:12:07.190719",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.166451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 heads\n",
      "768 hidden state embedding dimension\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print(config.num_attention_heads,'heads')\n",
    "print(config.hidden_size,'hidden state embedding dimension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc47326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.224688Z",
     "iopub.status.busy": "2023-11-07T12:12:07.224386Z",
     "iopub.status.idle": "2023-11-07T12:12:07.230964Z",
     "shell.execute_reply": "2023-11-07T12:12:07.230200Z"
    },
    "papermill": {
     "duration": 0.025767,
     "end_time": "2023-11-07T12:12:07.232720",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.206953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (q): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (k): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (v): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Sample Initialisation '''\n",
    "\n",
    "# Initialised just one head, requires token embedding vector for forward operation\n",
    "\n",
    "embed_dim = config.hidden_size\n",
    "num_heads = config.num_attention_heads\n",
    "\n",
    "attention = Attention(embed_dim,num_heads)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da230f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.266405Z",
     "iopub.status.busy": "2023-11-07T12:12:07.265958Z",
     "iopub.status.idle": "2023-11-07T12:12:07.276364Z",
     "shell.execute_reply": "2023-11-07T12:12:07.275745Z"
    },
    "papermill": {
     "duration": 0.028895,
     "end_time": "2023-11-07T12:12:07.278006",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.249111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0466, -0.2470,  0.1237,  0.2201,  0.3026,  0.1393, -0.2491,\n",
       "          -0.3497, -0.1996,  0.0671,  0.2526,  0.2091],\n",
       "         [ 0.0140, -0.3049,  0.1017,  0.2228,  0.3752,  0.1384, -0.1850,\n",
       "          -0.3570, -0.1759,  0.0630,  0.1793,  0.1408],\n",
       "         [ 0.0551, -0.2393,  0.0875,  0.2590,  0.3480,  0.1496, -0.2562,\n",
       "          -0.3072, -0.2018,  0.0312,  0.2683,  0.2274],\n",
       "         [-0.0058, -0.2037,  0.1226,  0.3035,  0.2113,  0.0648, -0.2598,\n",
       "          -0.3115, -0.1923,  0.0440,  0.1671,  0.2235],\n",
       "         [ 0.0202, -0.2561,  0.1774,  0.2478,  0.2812,  0.0958, -0.2397,\n",
       "          -0.3498, -0.1908,  0.0311,  0.2039,  0.1867],\n",
       "         [-0.0334, -0.2440,  0.1358,  0.3071,  0.3303,  0.0442, -0.2407,\n",
       "          -0.2779, -0.2602, -0.0438,  0.3093,  0.1323],\n",
       "         [ 0.0623, -0.1823,  0.1767,  0.2959,  0.3191,  0.2003, -0.2686,\n",
       "          -0.3018, -0.1096,  0.1130,  0.3252,  0.3756],\n",
       "         [ 0.0675, -0.2814,  0.0038,  0.1822,  0.4222,  0.1896, -0.2177,\n",
       "          -0.3258, -0.2537,  0.0698,  0.3274,  0.1554],\n",
       "         [ 0.0100, -0.2249,  0.0855,  0.3042,  0.2913,  0.1001, -0.2706,\n",
       "          -0.3141, -0.1913,  0.0194,  0.1966,  0.2057]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights are always initialised randomly, attention_outputs varies\n",
    "attention_outputs = attention(inputs_embeds)\n",
    "attention_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54eec369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.312835Z",
     "iopub.status.busy": "2023-11-07T12:12:07.312013Z",
     "iopub.status.idle": "2023-11-07T12:12:07.318401Z",
     "shell.execute_reply": "2023-11-07T12:12:07.317850Z"
    },
    "papermill": {
     "duration": 0.025446,
     "end_time": "2023-11-07T12:12:07.320076",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.294630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Multihead attention class\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class multiHeadAttention(nn.Module):\n",
    "    \n",
    "    # Config during initalisation\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # model params, read from config file\n",
    "        embed_dim = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # attention head (define only w/o hidden state)\n",
    "        # each attention head is initialised with embedd/heads head dimension\n",
    "        self.heads = nn.ModuleList(\n",
    "            [Attention(embed_dim, head_dim) for _ in range(num_heads)])\n",
    "        \n",
    "        # output uses whole embedding dimension for output\n",
    "        self.out_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    # Given a hidden state (embeddings)\n",
    "    # Apply operation for multihead attention\n",
    "        \n",
    "    def forward(self, hidden_state):\n",
    "        \n",
    "        # for each head embed_size/heads, calculate attention\n",
    "        heads = [head(hidden_state) for head in self.heads] \n",
    "        x = torch.cat(heads, dim=-1) # merge/concat head data together\n",
    "    \n",
    "        # apply linear transformation to multihead attension scalar product\n",
    "        x = self.out_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bba389d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.354402Z",
     "iopub.status.busy": "2023-11-07T12:12:07.353650Z",
     "iopub.status.idle": "2023-11-07T12:12:07.380981Z",
     "shell.execute_reply": "2023-11-07T12:12:07.379853Z"
    },
    "papermill": {
     "duration": 0.046191,
     "end_time": "2023-11-07T12:12:07.382557",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.336366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0017, -0.1517, -0.1362,  ..., -0.0517, -0.0008,  0.0395],\n",
      "         [-0.0278, -0.0883, -0.1181,  ..., -0.0496,  0.0156,  0.0461],\n",
      "         [-0.0047, -0.1191, -0.0997,  ..., -0.0956,  0.0191, -0.0170],\n",
      "         ...,\n",
      "         [ 0.0495, -0.1500, -0.1984,  ..., -0.0973,  0.0834, -0.0297],\n",
      "         [ 0.0523, -0.0707, -0.1575,  ..., -0.0809,  0.0127,  0.0498],\n",
      "         [ 0.0189, -0.1377, -0.0465,  ..., -0.0361,  0.0369,  0.0354]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Sample Usage: Multi-Head Attention\n",
    "\n",
    "'''\n",
    "\n",
    "# Every time will be different due to randomised weights\n",
    "multihead_attn = multiHeadAttention(config) # initialisation with config\n",
    "attn_output = multihead_attn(inputs_embeds) # forward by inputting embedding vectors (one for each token)\n",
    "\n",
    "# Attention output (attention weights matrix x vector weights concat)\n",
    "print(attn_output)\n",
    "print(attn_output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2aebb7",
   "metadata": {
    "papermill": {
     "duration": 0.01628,
     "end_time": "2023-11-07T12:12:07.415605",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.399325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>4 |</span></b> <b>FEED FORWARD LAYER</b></div>\n",
    "\n",
    "**position-wise feed-forward layer**\n",
    "\n",
    "The **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">feed-forward</mark>** sublayer in the encoder & decoder\n",
    "- **two layer fully connected neural network**\n",
    "\n",
    "\n",
    "However, instead of processing the whole sequence of embedding as a single vector, \n",
    "- it **processes each embedding** independently\n",
    "- Also see it referred to as a Conv1D with a kernel size of 1 (people with a CV background)\n",
    "\n",
    "\n",
    "The **hidden size** of the **1st layer = 4x size of the embeddings** & **GELU activation function**\n",
    "- Place where most of the capacity & memorization is hypothesized to happen\n",
    "- It is most often scaled, when scaling up the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab0da5c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.450016Z",
     "iopub.status.busy": "2023-11-07T12:12:07.449132Z",
     "iopub.status.idle": "2023-11-07T12:12:07.454841Z",
     "shell.execute_reply": "2023-11-07T12:12:07.454256Z"
    },
    "papermill": {
     "duration": 0.024374,
     "end_time": "2023-11-07T12:12:07.456328",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.431954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class feedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.linear2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    # define layer operations input x\n",
    "        \n",
    "    def forward(self, x):    # note must be forward\n",
    "        x = self.gelu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51b36e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.489862Z",
     "iopub.status.busy": "2023-11-07T12:12:07.489589Z",
     "iopub.status.idle": "2023-11-07T12:12:07.544434Z",
     "shell.execute_reply": "2023-11-07T12:12:07.543744Z"
    },
    "papermill": {
     "duration": 0.073582,
     "end_time": "2023-11-07T12:12:07.546107",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.472525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedForward(\n",
      "  (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (gelu): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ") \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0221, -0.0033,  0.0176,  ..., -0.0263,  0.0332,  0.0323],\n",
       "         [ 0.0146,  0.0081,  0.0309,  ..., -0.0244,  0.0290,  0.0177],\n",
       "         [ 0.0168, -0.0034,  0.0257,  ..., -0.0133,  0.0470, -0.0018],\n",
       "         ...,\n",
       "         [ 0.0153, -0.0022,  0.0000,  ..., -0.0272,  0.0446,  0.0177],\n",
       "         [ 0.0140,  0.0049,  0.0292,  ..., -0.0321,  0.0360,  0.0117],\n",
       "         [ 0.0139,  0.0007,  0.0179,  ..., -0.0282,  0.0300,  0.0180]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initailise feedforward layer\n",
    "feed_forward = feedForward(config)              # initialise \n",
    "print(feed_forward,'\\n')\n",
    "\n",
    "# requires config & attn_outputs outputs\n",
    "ff_outputs = feed_forward(attn_output) # forward operation\n",
    "ff_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2fc03c",
   "metadata": {
    "papermill": {
     "duration": 0.016237,
     "end_time": "2023-11-07T12:12:07.579139",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.562902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>5 |</span></b> <b>NORMALISATION LAYERS</b></div>\n",
    "\n",
    "Transformer architecture also uses **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">layer normalisation</mark>** & **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">skip connections</mark>**\n",
    "- **normalisation** - normalises batch input to have zero mean & unit variance\n",
    "- **skip connections** - pass a tensor to the next level of the model w/o processing & adding it to the processed tensor\n",
    "\n",
    "Two main approaches, when it comes to normalisation layer placement in decoder, encoder:\n",
    "- **post layer** normalisation (transformer paper, layer normalisation b/w skip connections)\n",
    "- **pre layer** normalisation \n",
    "\n",
    "<br>\n",
    "\n",
    "| `post-layer` normalisation |  `pre-layer` normalisation in literature |\n",
    "| - | - |\n",
    "| Arrangement is tricky to train from scractch, as the gradients can diverge |  Most often found arrangement\n",
    "| Used with LR warm up (learning rate gradually increased, from small value to some maximum value during training) | Places layer normalization within the span of the skip connection |\n",
    "|  | Tends to be much more stable during training, and it does not usually require any learning rate warm-up |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc50d01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.613606Z",
     "iopub.status.busy": "2023-11-07T12:12:07.612856Z",
     "iopub.status.idle": "2023-11-07T12:12:07.618561Z",
     "shell.execute_reply": "2023-11-07T12:12:07.617989Z"
    },
    "papermill": {
     "duration": 0.024708,
     "end_time": "2023-11-07T12:12:07.620134",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.595426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class encoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = multiHeadAttention(config)    # multihead attention layer \n",
    "        self.feed_forward = feedForward(config)        # feed forward layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Apply layer norm. to hidden state, copy input into query, key, value\n",
    "        # Apply attention with a skip connection\n",
    "        x = x + self.attention(self.norm1(x))\n",
    "        \n",
    "        # Apply feed-forward layer with a skip connection\n",
    "        x = x + self.feed_forward(self.norm2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bcecb13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.655181Z",
     "iopub.status.busy": "2023-11-07T12:12:07.654374Z",
     "iopub.status.idle": "2023-11-07T12:12:07.719063Z",
     "shell.execute_reply": "2023-11-07T12:12:07.718146Z"
    },
    "papermill": {
     "duration": 0.08428,
     "end_time": "2023-11-07T12:12:07.721179",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.636899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoderLayer(\n",
      "  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attention): multiHeadAttention(\n",
      "    (heads): ModuleList(\n",
      "      (0-11): 12 x Attention(\n",
      "        (q): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (k): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (v): Linear(in_features=768, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (out_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (feed_forward): feedForward(\n",
      "    (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (gelu): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ") \n",
      "\n",
      "input torch.Size([1, 9, 768])\n",
      "output torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "# Transformer layer output\n",
    "encoder_layer = encoderLayer(config) # initialise encoder layer\n",
    "print(encoder_layer,'\\n')\n",
    "\n",
    "print('input',inputs_embeds.shape) \n",
    "print('output',encoder_layer(inputs_embeds).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7232eac0",
   "metadata": {
    "papermill": {
     "duration": 0.01686,
     "end_time": "2023-11-07T12:12:07.754870",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.738010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is an issue with the way we set up the **encoder layers** (which uses just embedding inputs)\n",
    "- they are totally **invariant to the position of the tokens**\n",
    "- Multi-head attention layer is effectively a weighted sum, the **information on token position is lost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ed26c",
   "metadata": {
    "papermill": {
     "duration": 0.016274,
     "end_time": "2023-11-07T12:12:07.787762",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.771488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>6 |</span></b> <b>POSITIONAL EMBEDDINGS</b></div>\n",
    "\n",
    "Let's incorporate positional information using **positional embeddings**\n",
    "\n",
    "\n",
    "**positional embeddings** are based on idea:\n",
    "  - Modify the **token embeddings** with a **position-dependent pattern** of values arranged in a vector\n",
    "  \n",
    "  \n",
    "If the pattern is characteristic for each position\n",
    "- the **attention heads** and **feed-forward layers** in each stack can learn to incorporate positional information into their transformations\n",
    "\n",
    "\n",
    "\n",
    "- There are several ways to achieve this, and one of the most popular approaches is to use a `learnable pattern`\n",
    "- This works exactly the same way as the token embeddings, but using the **position index** instead of the **token identifier** (from vocabulary dictionary) as input\n",
    "- An efficient way of encoding the positions of tokens is learned during pretraining\n",
    "\n",
    "Creating Custom `Embedding` class\n",
    "\n",
    "Let’s create a custom Embeddings module (**token embeddings + positional embeddings**)\n",
    " - That combines a token embedding layer that projects the input_ids to a dense hidden state \n",
    " - Together with the positional embedding that does the same for position_ids\n",
    " - The resulting embedding is simply the **sum of both embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "436fdf8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.823932Z",
     "iopub.status.busy": "2023-11-07T12:12:07.823592Z",
     "iopub.status.idle": "2023-11-07T12:12:07.831753Z",
     "shell.execute_reply": "2023-11-07T12:12:07.830873Z"
    },
    "papermill": {
     "duration": 0.02821,
     "end_time": "2023-11-07T12:12:07.833862",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.805652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Token + Position Embedding \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class tpEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):        \n",
    "        super().__init__()\n",
    "        \n",
    "        # token embedding layer\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size,\n",
    "                                             config.hidden_size)\n",
    "        \n",
    "        # positional embedding layer\n",
    "        # config.max_position_embeddings -> max number of positions in text 512 (tokens)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
    "                                                config.hidden_size)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \n",
    "        # Create position IDs for input sequence\n",
    "        seq_length = input_ids.size(1) # number of tokens\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long)[None,:] # range(0,9)\n",
    "        \n",
    "        # tensor([[ 1996, 11286,  1997,  1037,  5340,  3392,  2003,  2200,  5931]])\n",
    "        # tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8]])\n",
    "        \n",
    "        # Create token and position embeddings\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # Combine token and position embeddings\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        \n",
    "        # Add normalisation & dropout layers\n",
    "        embeddings = self.norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b1eb5779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:07.870017Z",
     "iopub.status.busy": "2023-11-07T12:12:07.869347Z",
     "iopub.status.idle": "2023-11-07T12:12:08.024643Z",
     "shell.execute_reply": "2023-11-07T12:12:08.023751Z"
    },
    "papermill": {
     "duration": 0.175058,
     "end_time": "2023-11-07T12:12:08.026668",
     "exception": false,
     "start_time": "2023-11-07T12:12:07.851610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3445,  0.0000, -0.0000, -0.0000,  0.0000, -0.1042, -0.2192,\n",
       "          -0.0000, -0.0000, -3.5667,  0.0000,  4.2198,  0.4537,  0.0000,\n",
       "          -4.2740, -1.7250, -0.7161, -0.0000,  1.1875, -1.1810, -0.0000,\n",
       "          -0.0000,  0.0000, -1.5592, -0.0000,  0.0000, -2.1069,  2.0811,\n",
       "          -1.1085, -0.6592, -0.0000, -2.1012,  3.2155,  0.0000,  0.3414,\n",
       "           0.0000,  0.0000,  2.3591,  0.0000,  3.7387, -1.7707, -1.3633,\n",
       "           1.9601,  0.0000,  4.1266,  3.6932, -2.3514, -3.0475, -1.9932,\n",
       "           2.1455,  0.0000, -0.0000,  0.7239, -0.0000,  0.0000, -1.0955,\n",
       "           2.1274, -1.5079,  0.0000,  2.9827,  0.0000, -0.0000, -6.0318,\n",
       "          -0.0000,  1.6531, -0.0000,  4.1636, -0.0000,  0.9650,  0.0000,\n",
       "           0.0000, -0.0000, -2.0467,  1.0195,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000, -1.1940,  0.7735,  0.0000,  0.0000, -0.0000,  0.2993,\n",
       "           0.0000, -1.7147, -3.9098, -0.5094, -0.0000, -0.0000, -1.2400,\n",
       "          -0.0000, -0.0000,  0.0000, -2.0943, -1.1707, -0.8221,  1.4961,\n",
       "          -1.5801,  0.0000,  0.8324,  0.0000,  4.0411,  1.1672, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -1.4490,  0.8229, -0.0000,  0.0000,\n",
       "           1.8747, -1.8030,  2.1833,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  4.3210,  0.0000, -0.0000, -1.5697, -0.0000,\n",
       "           3.9274,  0.5631, -0.0000,  0.0000,  0.4693,  0.9044,  0.0000,\n",
       "           0.0000,  1.2861, -1.3509, -3.5095,  0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.3650,  0.0000,  3.6474, -0.3228,  2.0208,\n",
       "           0.0000, -0.0623, -1.8903,  1.6569,  3.7949,  1.4833,  0.9993,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -2.4850,\n",
       "          -0.0000, -2.7426, -0.8282, -0.0000,  0.0000, -1.1140,  2.2223,\n",
       "          -0.0000, -0.2546, -0.0000, -0.0000, -0.7051,  0.0000, -2.4826,\n",
       "           2.3873,  0.0000, -3.7428, -0.8102, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000, -2.6334, -0.3816,  0.0000, -0.0695,\n",
       "          -0.2809,  4.9147, -0.0000, -0.7827, -0.0000,  0.0000,  0.0000,\n",
       "          -0.0165,  0.0000, -4.3691,  0.0000,  0.0000, -2.5448, -2.6790,\n",
       "          -0.0000,  0.0000, -0.0000, -0.1575, -2.3908,  0.0000,  0.0000,\n",
       "          -0.1255,  0.0000,  0.0000,  1.5447,  0.5666,  0.0000, -0.0000,\n",
       "          -1.8092, -2.5009,  1.7583,  0.0000,  0.2603, -0.0000,  0.0000,\n",
       "          -1.8194, -0.0000, -0.1266, -0.0000, -0.0000, -1.5672, -1.9930,\n",
       "          -0.7872,  0.0000, -0.0000, -0.0000, -2.6141, -0.0000,  0.0000,\n",
       "          -4.6290,  1.4878, -0.0000,  0.0000,  1.5061, -0.0000,  2.2569,\n",
       "          -0.0000,  0.8287, -0.0000,  0.0000, -1.7352, -1.6570, -0.0000,\n",
       "           0.0000,  1.2717, -0.0000,  0.0000, -1.8577,  0.0000, -2.4533,\n",
       "          -0.0000,  1.0002,  3.0770,  0.0000,  0.0000,  0.0000, -0.0000,\n",
       "           0.0000,  2.1265,  0.0000,  1.9673, -4.1940, -0.0591, -1.6289,\n",
       "          -0.0000, -0.0000, -0.0000, -2.0477,  0.0000,  1.6402,  0.0000,\n",
       "          -0.9369,  3.0131,  0.0000,  3.3918, -1.9931,  0.0000,  0.2270,\n",
       "          -0.0000,  0.0000, -0.0000, -0.0000, -4.3514,  0.0000,  0.0000,\n",
       "          -1.9840, -1.5063,  3.2798,  1.4956, -1.0905,  0.7842,  0.3723,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0000, -0.4676,  0.0000,  3.7009,  0.0000, -0.0000,  0.5294,\n",
       "           0.0000,  0.0000, -0.0000, -0.8687, -0.0000, -0.0000,  1.0544,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000,  2.5473,  3.0162, -0.0000,\n",
       "           0.0000, -3.1281,  0.4455, -3.4218,  0.3108, -6.3560,  1.7133,\n",
       "           2.0271,  0.2281, -1.6059,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.5778,  0.0000,  0.0000,  1.1481, -0.0990, -0.0000,\n",
       "           1.9146, -0.0000,  0.0000,  2.1087, -0.0000,  0.0000, -0.0000,\n",
       "           5.1506, -3.6834,  1.6176, -0.0000, -0.9541, -2.6021, -0.0000,\n",
       "           0.0000, -3.1501, -1.8990,  0.0000, -1.3268,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.1206,  0.0000,  0.0000, -0.3013,  0.0000,\n",
       "          -0.0577, -0.0000, -0.0000,  0.0000,  0.9014, -0.0000, -0.0000,\n",
       "           1.0370, -0.0000, -3.8387, -0.0000,  0.6953,  4.0858, -0.0000,\n",
       "           0.1027,  0.0000, -0.0000, -0.0000, -0.2180, -0.0000, -0.4173,\n",
       "          -0.0000, -0.3070,  0.0000,  0.0000, -0.0000, -0.0000, -0.1274,\n",
       "           3.9666,  0.0000,  0.0000, -0.0000, -0.0000, -0.6900,  1.4258,\n",
       "           0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -1.3504,  0.0000,\n",
       "           2.6712,  0.0000, -0.0000, -3.7252, -0.8319,  0.0000, -5.9663,\n",
       "          -3.2230,  2.1006,  3.5667,  2.5016, -0.0080,  0.0000,  0.6110,\n",
       "           0.0000, -0.0000,  0.0000,  4.0659, -0.0000,  0.0000, -0.4489,\n",
       "           0.0000,  0.0000, -1.3606,  0.0000, -2.8207,  1.6699,  0.0000,\n",
       "           0.0000, -0.0000, -0.0000,  2.6321,  0.0000,  0.0000,  1.7966,\n",
       "          -2.9745,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          -0.0000,  1.4413,  2.4687,  0.0000, -2.2730,  0.0000,  2.1839,\n",
       "           2.8482, -0.2659, -0.6487,  0.9074, -0.0000, -4.6174,  0.0000,\n",
       "           0.0000,  0.0000, -2.5534,  0.0000,  1.1770, -0.0000, -0.0000,\n",
       "          -0.4696,  0.0000,  0.0000, -2.1839,  0.0000, -0.0000, -0.3360,\n",
       "          -2.2503,  0.0000,  1.4340, -0.1927, -2.1331, -0.0890,  0.0000,\n",
       "          -0.0000,  0.7093, -0.0842, -0.1743, -0.0000, -0.4221, -2.5282,\n",
       "          -0.0000, -1.2469, -0.0000, -0.0000, -0.8742,  3.4838, -0.0000,\n",
       "           0.0000, -1.2490,  0.0000, -0.0000,  1.7722,  0.0000, -0.0000,\n",
       "          -1.4256, -0.0000,  0.2689, -0.2080, -0.0000, -1.2213,  0.0000,\n",
       "          -2.1740,  0.0000,  0.9321, -1.6002,  1.2804, -0.1811,  1.0304,\n",
       "           2.9642,  0.0000,  0.0000,  1.7440, -0.0000,  0.6955,  0.3784,\n",
       "           0.0000,  0.6986, -0.0000,  2.9247, -0.0000,  0.6941,  0.1416,\n",
       "          -2.8276, -0.0224, -1.6339, -1.9991,  0.0000, -0.0000, -1.4061,\n",
       "           0.0000,  0.5567, -2.2017, -0.0000,  1.2142,  0.0000,  1.7221,\n",
       "          -0.0000,  0.0000,  0.0000,  4.2191,  0.0000, -1.7318, -1.9524,\n",
       "          -1.0486, -0.0000, -1.9618,  2.6089,  0.0000,  0.0000, -0.0359,\n",
       "           0.0000, -1.7060,  0.0000,  0.0000, -0.0000, -1.1237,  0.0000,\n",
       "          -0.5249, -0.8483,  0.0000, -0.0000, -0.0000,  2.7083,  1.0878,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -1.9673, -0.0000,\n",
       "          -1.9280,  0.0000,  1.2616, -1.8661, -0.0000, -0.0000,  0.0000,\n",
       "          -0.0000,  1.6626,  3.8306, -0.0000, -0.0000,  0.0000, -2.1076,\n",
       "          -0.4273, -1.0944, -0.0000,  0.0000,  1.6911,  1.0654, -3.7872,\n",
       "          -0.0000,  0.7983,  0.4973,  4.5434,  0.2419, -3.8383,  2.0613,\n",
       "          -3.9296, -2.4594,  1.7327, -3.2626,  0.9493, -1.1560,  0.6263,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000,  1.6932,  1.7155, -0.0000,\n",
       "           0.9014,  0.3167,  1.0854,  0.0000, -0.0000,  2.9046,  2.9992,\n",
       "           0.0000, -0.1180, -0.0000,  0.0000,  0.0778, -0.0000, -1.8489,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  2.0203,\n",
       "           0.0000,  1.1604,  2.2622,  2.1986, -0.0000, -0.0000,  0.0000,\n",
       "          -0.0000,  0.0000, -0.2565, -1.4333,  0.0000, -1.1009,  0.0000,\n",
       "          -0.3849,  0.0000,  1.0044, -0.0000, -0.0000, -0.0000, -0.6476,\n",
       "          -0.0000,  0.0000,  0.0000, -3.2180,  0.0000,  1.1666, -1.4231,\n",
       "           0.0000,  0.0000, -0.3453,  0.1096,  3.6764,  1.1118, -2.6960,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "           2.4167,  2.4704, -4.5305, -0.9920,  2.9734, -1.0793, -0.5571,\n",
       "          -0.1313,  2.1079, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -1.6322, -0.0000, -0.0000,  0.0000, -0.0000, -2.8096,  0.0000,\n",
       "          -0.0000, -0.8981, -1.5600,  0.0000,  0.0000,  0.0000,  0.6065,\n",
       "           0.0000,  0.0000,  0.0000, -0.8788, -4.4115, -0.8955, -0.0000,\n",
       "          -0.0000,  2.4104,  2.3791,  0.0000, -0.0000,  0.0000,  0.1456,\n",
       "           0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.4985, -0.0000, -1.1287, -0.0000,\n",
       "          -0.0000, -0.0000,  0.5359, -1.5943,  0.0000, -2.6039,  0.0000,\n",
       "          -0.2968, -0.0000,  0.9431,  0.0000, -0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token and Position Embeddings\n",
    "embedding_layer = tpEmbedding(config)\n",
    "embedding_layer(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "89b398b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6423]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae2413",
   "metadata": {
    "papermill": {
     "duration": 0.016522,
     "end_time": "2023-11-07T12:12:08.060364",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.043842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>7 |</span></b> <b>PUTTING IT ALL TOGETHER</b></div>\n",
    "\n",
    "- Constructing the Transformer **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">encoder</mark>**, combining the **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">Embedding</mark>** and **<mark style=\"background-color:#FFC300;color:white;border-radius:5px;opacity:1.0\">Encoder</mark>**  layers\n",
    "- We utilise both **token** & **positional** embeddings using `tpEmbedding`\n",
    "- For a given number of heads, we store `encoderLayer`, which contains the **attention** & **feed-forward** layers (which are our layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6f1e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:08.094928Z",
     "iopub.status.busy": "2023-11-07T12:12:08.094587Z",
     "iopub.status.idle": "2023-11-07T12:12:08.100489Z",
     "shell.execute_reply": "2023-11-07T12:12:08.099664Z"
    },
    "papermill": {
     "duration": 0.024909,
     "end_time": "2023-11-07T12:12:08.102005",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.077096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full transformer encoder combining the `Embedding` with the ``Embedding` ` layers\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):       \n",
    "        super().__init__()\n",
    "        \n",
    "        # token & positional embedding layer\n",
    "        self.embeddings = tpEmbedding(config)\n",
    "        \n",
    "        # attention & forward feed layer \n",
    "        self.layers = nn.ModuleList([encoderLayer(config)\n",
    "                                     for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # embeddings layer output\n",
    "        x = self.embeddings(x)\n",
    "        \n",
    "        # cycle through all heads\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3bbadb05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:08.136166Z",
     "iopub.status.busy": "2023-11-07T12:12:08.135908Z",
     "iopub.status.idle": "2023-11-07T12:12:08.948737Z",
     "shell.execute_reply": "2023-11-07T12:12:08.948016Z"
    },
    "papermill": {
     "duration": 0.831712,
     "end_time": "2023-11-07T12:12:08.950315",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.118603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.0581e+00, -1.6299e-01, -2.9520e+00, -5.2393e-01,  8.3359e-01,\n",
      "          -3.3352e+00, -1.2720e-01, -7.9162e-01, -2.2214e+00, -2.7648e+00,\n",
      "          -6.4970e-01, -3.2357e+00,  5.3065e-01, -2.7389e+00, -1.3367e-01,\n",
      "          -2.3654e+00, -2.3908e+00,  2.9580e+00, -2.0250e+00, -5.0651e-01,\n",
      "           3.8579e-01, -1.0198e+00,  2.0577e+00, -2.8406e-02,  2.6890e+00,\n",
      "           2.6196e+00, -1.1550e+00,  5.7243e-01, -1.1750e+00,  2.3551e+00,\n",
      "           1.6403e+00,  3.5082e+00, -1.0916e-01, -1.5080e+00,  1.8043e+00,\n",
      "          -2.9783e+00,  4.0652e-01, -2.6620e+00, -1.6786e+00, -1.0035e+00,\n",
      "           6.6816e-01,  1.7701e+00,  4.6573e-01,  1.1439e+00, -2.3352e+00,\n",
      "           4.0620e-01, -1.3216e+00,  2.9990e+00,  1.0780e+00,  1.8285e+00,\n",
      "          -4.4860e-01,  4.1073e+00, -6.6948e-01,  9.8133e-01,  2.5430e+00,\n",
      "           9.5153e-01,  1.0964e-02,  1.4591e+00, -1.7102e+00, -1.1592e+00,\n",
      "          -2.8592e+00, -1.5909e+00, -7.0151e-01,  1.3612e+00,  2.3833e+00,\n",
      "          -1.9930e+00, -5.1488e-01, -5.6847e-01,  2.7698e-01, -1.3758e+00,\n",
      "           8.1695e-01, -1.7066e+00,  5.0570e+00, -3.3936e-01,  2.2565e+00,\n",
      "           5.8221e-02,  6.7646e-01,  1.3443e+00, -1.1594e+00,  3.2141e-02,\n",
      "           8.8871e-01,  4.9668e-01, -3.1154e+00,  2.0389e+00, -2.1653e+00,\n",
      "           2.3571e+00, -1.2227e+00, -9.6967e-01,  2.6086e+00,  9.9498e-01,\n",
      "           3.1361e-01, -2.1182e+00,  1.0425e+00, -4.4519e+00,  3.4816e+00,\n",
      "           3.5830e-01, -8.5785e-01, -4.3517e+00, -1.9353e+00, -1.3256e-01,\n",
      "          -1.3796e+00,  9.6398e-01,  8.2927e-01,  2.2073e+00,  2.2819e+00,\n",
      "          -6.5790e-01, -5.9524e-01, -2.1652e+00,  1.7489e+00,  9.2325e-02,\n",
      "           6.0037e+00, -6.7480e-01,  2.6888e+00, -1.7571e+00, -4.6782e+00,\n",
      "           1.7177e+00, -4.0460e+00, -3.7691e-01, -8.1704e-02,  2.3372e+00,\n",
      "          -3.3066e-01, -7.3705e-01,  3.6517e+00,  1.0021e+00, -9.2673e-01,\n",
      "          -2.6551e-01,  2.4245e+00, -6.0231e-01, -3.4883e-01,  1.2589e+00,\n",
      "          -7.4872e-01,  8.5135e-01,  1.0663e+00, -6.1576e-01,  1.3420e+00,\n",
      "           4.2581e+00, -6.2430e-01, -1.0095e+00,  2.2152e+00,  6.1554e-01,\n",
      "           7.4154e-01,  1.4532e+00,  8.3349e-01, -6.2951e-01,  3.7595e-01,\n",
      "           2.9994e+00, -1.0834e+00,  9.9328e-01, -1.5153e+00, -1.8906e-01,\n",
      "          -2.3266e+00, -2.5728e+00,  2.8888e+00, -7.6362e-02, -1.8319e-01,\n",
      "          -2.4179e+00,  1.2355e+00, -2.4849e+00,  1.2017e+00,  9.3922e-01,\n",
      "           7.0532e-01,  1.7379e+00,  3.2165e+00, -1.0438e+00, -6.1201e-02,\n",
      "          -1.9802e+00,  1.9531e+00, -2.6879e-01,  8.0436e-01,  2.9808e+00,\n",
      "          -2.5734e+00,  1.5823e+00,  3.0728e+00, -3.6195e+00,  1.3600e+00,\n",
      "          -1.6159e+00,  1.2275e-01, -1.2240e+00, -8.8136e+00,  1.0159e+00,\n",
      "           6.1299e-01, -1.9228e-01, -1.7141e+00,  3.3657e-01,  5.1007e-01,\n",
      "           4.9019e-01, -2.1179e+00,  2.3003e-01,  3.3767e-01, -4.0417e-01,\n",
      "           7.3985e-01, -6.7844e-01, -2.2313e+00, -1.9817e+00,  6.3853e-01,\n",
      "           5.5425e-01, -7.3747e-01,  5.9956e-01, -3.7545e-01, -2.6982e+00,\n",
      "           1.1178e+00,  9.1579e-01, -1.5634e+00,  5.5694e-01,  3.0024e+00,\n",
      "          -4.4706e-01, -1.6640e+00, -1.5708e+00, -2.2672e+00, -1.3925e-01,\n",
      "          -2.0317e-01, -2.8635e+00, -7.3508e-02, -9.8533e-01, -2.4101e+00,\n",
      "          -3.1565e-01, -1.1475e+00, -9.1112e-01, -7.9943e-02, -3.2565e+00,\n",
      "           1.3215e+00,  1.9624e+00,  1.1751e-01, -4.4948e-02, -1.1297e-01,\n",
      "           4.3099e+00,  1.7070e+00, -2.3057e+00,  1.8468e+00, -4.9105e-01,\n",
      "           1.7790e+00, -5.2746e-01,  2.8120e+00, -3.7071e+00, -3.6229e+00,\n",
      "           1.8388e+00, -9.8981e-01, -5.7664e-01, -3.8257e-01,  2.8902e+00,\n",
      "           5.1171e-02, -2.6290e+00, -1.3076e+00,  2.3636e+00,  1.1797e+00,\n",
      "          -2.6572e-01, -3.8470e+00, -6.0089e-01,  4.9800e-01, -4.2063e-01,\n",
      "           4.9078e-01,  3.2113e+00,  6.2240e-01, -1.2871e+00,  6.5881e+00,\n",
      "           3.0409e+00, -3.5282e+00,  1.0859e+00,  1.3033e+00, -9.1360e-01,\n",
      "           1.2156e+00,  4.2272e-01,  2.9132e+00,  1.3914e+00, -1.0237e+00,\n",
      "          -8.5495e-01, -6.1104e+00, -1.2711e+00,  2.7369e+00,  1.4282e+00,\n",
      "           1.3206e+00,  3.7792e-01,  2.0654e-01,  7.0442e-02,  2.9601e+00,\n",
      "          -3.0305e-01, -6.2264e-01, -4.2594e-01,  4.7344e-01,  3.1386e+00,\n",
      "          -3.1439e+00, -1.0298e+00, -2.9223e-01,  8.5006e-01,  4.0032e-01,\n",
      "          -2.3926e+00,  2.3110e+00, -5.6206e-01,  2.9074e+00,  1.7269e+00,\n",
      "          -7.7748e-02,  1.4490e+00,  9.8051e-01, -7.1668e-01,  1.1352e+00,\n",
      "           4.6730e+00,  4.5193e-01,  4.0721e-01,  2.5498e-01,  3.4814e+00,\n",
      "           2.8167e-01,  6.1290e-01, -1.5403e+00, -4.4544e-01,  1.1916e+00,\n",
      "           2.1356e+00,  1.8314e+00, -2.1331e+00,  8.3751e-01, -6.9543e+00,\n",
      "           3.9099e+00,  3.9545e-02,  6.2949e-01, -5.4392e-01, -1.8373e-01,\n",
      "           9.3614e-01,  1.5526e+00,  2.3166e-01, -1.6463e-01,  1.9933e+00,\n",
      "           1.3201e+00,  1.8462e+00, -3.8792e+00, -1.5337e-01, -3.2350e-01,\n",
      "          -5.4703e-01,  2.5099e-01,  1.7533e+00,  2.7976e+00, -2.4037e-02,\n",
      "          -5.1766e-01, -3.5869e+00,  1.0114e-01, -1.3001e+00,  6.4852e-02,\n",
      "          -1.1201e+00,  1.1763e+00, -2.8448e+00,  3.5114e-01, -3.4351e-01,\n",
      "           1.0255e+00, -1.5680e-01,  1.9838e+00,  9.6231e-01,  7.0414e+00,\n",
      "           2.6614e-03, -8.9431e-01, -5.9368e-01,  2.1790e+00, -1.4168e+00,\n",
      "           1.3077e+00,  5.3835e-01,  6.6362e-01,  6.5240e-01, -2.5101e+00,\n",
      "           3.5632e+00, -6.6108e-02, -5.8509e-01, -4.7394e-01, -1.4781e+00,\n",
      "          -6.9695e-01,  2.7101e+00, -6.9960e-01,  2.8583e+00,  3.2006e+00,\n",
      "           3.0785e+00,  5.7289e+00, -9.4457e-01, -2.5860e+00, -2.0656e+00,\n",
      "           1.7614e-01, -1.4724e+00,  2.0712e-01, -1.5254e+00,  1.2147e+00,\n",
      "          -1.4485e-02,  3.6571e-01,  5.7535e-01, -2.9379e-01, -2.3733e+00,\n",
      "           1.4316e+00, -2.6084e+00,  1.2195e+00,  3.0835e-01, -2.8498e-01,\n",
      "           1.7055e+00, -1.0265e+00,  3.5868e+00, -2.4481e-02,  2.1442e+00,\n",
      "           1.3157e+00,  6.7872e+00, -3.0119e+00,  1.2937e+00, -1.0102e+00,\n",
      "           5.4451e-01, -2.0909e+00, -1.1960e+00, -2.8436e-01,  4.6228e-01,\n",
      "           4.0491e-01, -8.6545e-02, -1.2370e+00, -1.5514e+00, -4.1352e-01,\n",
      "           1.4363e+00,  3.0714e-02, -2.5930e+00, -6.0833e-01,  4.3208e+00,\n",
      "          -5.3334e-01,  2.2184e+00, -8.8572e-01, -1.4023e+00, -6.0864e-01,\n",
      "           4.7138e-01, -1.9081e+00,  1.9216e+00,  4.9732e-01, -3.1736e-01,\n",
      "           1.3494e+00, -1.0987e-01, -1.7143e-01,  1.7270e+00, -1.3253e+00,\n",
      "          -1.6015e+00, -2.9860e+00,  6.0757e+00, -3.1153e-01, -3.3537e-01,\n",
      "          -3.8799e-01,  1.5466e+00,  3.4770e-01, -1.8829e+00,  2.4348e-01,\n",
      "          -5.4930e-01,  1.2523e+00, -1.0948e+00,  1.2746e+00, -4.5839e+00,\n",
      "           1.1770e+00,  2.5322e+00, -3.0239e-01, -1.8852e+00, -6.6845e-01,\n",
      "          -3.1933e+00, -6.8654e-01, -2.2168e+00,  2.8489e+00, -4.1390e+00,\n",
      "          -1.2837e+00,  1.1739e+00, -9.8953e-01,  5.0376e-01, -1.0329e+00,\n",
      "          -7.4864e-01,  3.0227e+00,  4.9463e-01, -2.3473e+00, -2.7923e+00,\n",
      "          -1.0274e+00,  6.1635e-01, -1.0525e-01, -4.4718e+00,  1.7906e-01,\n",
      "           6.5948e-01, -1.8373e+00, -1.4859e+00, -7.2096e-01, -2.0844e+00,\n",
      "           2.1391e+00,  7.8615e-01,  4.0896e-02,  1.8714e-01, -1.5027e+00,\n",
      "           1.0440e+00, -2.5779e-01,  2.0063e+00,  1.2867e+00, -3.2562e+00,\n",
      "          -9.0607e-01,  3.3929e+00, -7.5835e-01, -1.0832e-01, -5.9797e-01,\n",
      "           2.7677e-01, -4.9994e-01,  1.6172e-01, -8.9172e-02, -1.0193e+00,\n",
      "           7.4156e-01,  2.1635e+00,  1.5017e+00,  4.3496e-01, -8.1997e-01,\n",
      "           4.9544e+00,  2.2361e+00, -1.4128e+00,  1.1622e+00,  2.3986e-01,\n",
      "          -8.6590e-01,  1.9562e+00, -3.1732e-01, -2.3528e+00,  2.6417e+00,\n",
      "          -1.1484e+00, -1.4410e+00,  5.4039e-01, -3.1666e+00, -5.6188e-01,\n",
      "          -2.3928e+00, -7.4521e-01, -1.8537e+00,  4.1325e+00,  5.8176e-01,\n",
      "           3.9575e-02, -8.2735e-01,  1.8038e+00, -2.4998e+00,  1.6222e+00,\n",
      "           5.6605e-01, -9.6511e-01,  1.0847e-01, -1.8756e+00,  7.3242e-01,\n",
      "           5.8233e-01, -1.3525e+00,  5.7419e-01, -5.8688e-01, -6.2747e-01,\n",
      "           2.2619e+00,  5.2735e+00,  7.6944e-01,  3.0010e-01,  2.9500e-02,\n",
      "           6.3181e-01, -2.7081e+00,  2.6197e-01,  8.3917e-01, -1.7507e-01,\n",
      "          -7.6865e+00,  2.3566e+00,  2.4804e+00,  4.1165e+00,  6.3856e-01,\n",
      "          -1.0412e+00,  9.0219e-01, -1.5259e+00, -4.0992e-01, -4.6658e-01,\n",
      "           6.0860e-01,  5.9700e-01,  4.2228e-01, -1.2187e+00,  5.6963e-01,\n",
      "          -1.5381e+00, -2.0722e+00, -1.6262e-01, -1.7332e+00, -3.7140e-01,\n",
      "          -1.5338e+00, -2.7102e-01, -2.5757e+00, -3.3186e+00,  1.9405e+00,\n",
      "           2.2363e+00, -1.1247e+00,  1.0871e+00, -6.3798e-01, -4.6929e+00,\n",
      "           7.6731e-01,  6.6194e-01,  3.6035e+00, -5.0607e-01, -8.8095e-01,\n",
      "           2.4667e-01,  8.4774e-01, -2.3921e+00,  5.9792e-01, -1.4355e+00,\n",
      "          -2.9425e+00,  1.7954e-01, -1.6898e+00, -1.2581e+00,  1.6439e-01,\n",
      "           1.6201e+00, -5.3661e-01, -5.3798e-01,  2.5306e+00, -1.2607e+00,\n",
      "           3.3140e+00, -4.1180e+00,  9.8821e-01, -1.0045e+00, -3.6143e+00,\n",
      "           2.9938e+00, -3.0140e+00,  1.9483e+00, -1.5742e+00, -9.7815e-01,\n",
      "           1.8820e+00,  2.0957e+00,  2.0710e-01,  2.6355e+00, -2.6145e+00,\n",
      "           1.2707e+00,  1.6110e+00,  4.1893e-01, -5.1009e-01,  1.4242e-01,\n",
      "          -3.0379e+00, -2.9284e+00, -1.1055e+00, -6.6225e-01,  2.8311e-01,\n",
      "           4.6340e+00, -1.3538e+00, -2.2857e+00, -8.9632e-01,  1.5305e+00,\n",
      "          -1.2283e+00,  1.9740e+00, -1.3656e+00, -1.4262e+00,  1.8948e+00,\n",
      "          -5.0636e-01, -1.0241e+00,  1.7618e-01,  2.1711e+00,  7.6367e-01,\n",
      "           2.9906e-01,  9.7144e-02, -1.7410e+00, -5.1169e-01, -1.0193e+00,\n",
      "          -8.0271e-01, -2.8240e+00,  2.1780e+00, -3.0577e+00, -4.7419e+00,\n",
      "           1.6614e+00,  1.5497e-01, -2.9090e+00, -5.1669e-01,  1.8674e+00,\n",
      "           1.8191e+00, -2.1658e+00, -3.9795e-01,  7.6784e-01, -4.2496e+00,\n",
      "          -1.3559e+00,  2.7930e+00, -6.7860e-02,  3.8560e+00,  2.8738e-01,\n",
      "          -1.3647e+00,  1.2932e+00, -1.0682e-01,  3.2415e+00, -1.7266e+00,\n",
      "          -1.7580e+00,  1.2450e+00,  6.6489e-01,  2.8438e-01, -1.3487e+00,\n",
      "           6.2473e-01, -4.7261e-01, -1.8936e+00, -1.0697e+00, -1.7954e+00,\n",
      "           5.5401e-01, -6.2966e-01,  4.6562e+00,  4.9581e-01, -1.0134e-01,\n",
      "           2.2497e+00,  1.8885e+00,  2.4616e+00, -4.9715e-01, -1.9108e+00,\n",
      "          -2.1591e-01,  1.0133e+00, -6.4888e-01, -6.5758e-02,  1.3914e+00,\n",
      "           1.0442e+00, -1.5619e+00, -3.4920e-01,  1.2530e+00, -3.6060e+00,\n",
      "          -4.6645e+00, -2.6175e-01,  3.1642e-02, -5.9902e-01,  1.3068e+00,\n",
      "           2.3554e+00,  1.0025e+00,  2.6216e-02,  1.9090e+00,  3.7473e+00,\n",
      "           2.2862e+00, -3.8202e-01,  1.0412e+00,  2.2260e+00,  3.0511e-01,\n",
      "           5.9166e+00,  8.0121e-01,  1.4281e+00, -4.6147e-02,  5.2406e-01,\n",
      "          -1.1554e+00,  2.8596e+00,  2.8073e+00, -2.9818e+00, -5.0332e-01,\n",
      "           2.3956e+00, -1.6954e+00,  1.0451e+00,  5.6013e-01,  1.5071e+00,\n",
      "          -6.6678e-01,  1.5147e+00,  1.1382e+00, -1.0111e+00,  3.2913e+00,\n",
      "          -1.0476e+00,  1.3469e-01,  1.1668e+00,  2.9839e+00,  4.5291e-01,\n",
      "          -6.3453e-01, -8.0397e-01,  1.0417e+00, -2.7465e-01, -1.2706e+00,\n",
      "           1.0271e+00, -5.0112e-01, -1.7470e+00, -1.4287e+00, -1.3914e+00,\n",
      "          -2.8980e+00, -9.1972e-01, -2.8727e+00,  1.9352e-01, -8.0617e-02,\n",
      "           1.1017e+00,  1.4107e+00, -1.8281e+00,  3.3514e+00,  6.4934e+00,\n",
      "           8.9819e-01, -1.7062e+00,  1.9437e-01,  1.1475e+00,  7.7663e-01,\n",
      "           3.0303e+00,  1.2387e+00,  4.4741e-01, -6.1370e-01, -5.7549e-01,\n",
      "          -1.9788e+00,  4.0155e-01, -1.8358e+00,  1.7952e-01,  9.6277e-01,\n",
      "          -1.2918e+00, -2.5125e+00, -1.9560e+00]]])\n",
      "tensor([[[-2.8056e+00,  1.4641e+00,  3.8870e-01, -2.7619e-01, -1.1840e+00,\n",
      "          -3.5017e-01, -4.3814e-01, -2.2000e+00, -3.5958e+00, -5.2393e-01,\n",
      "          -3.0016e-01, -2.2601e+00, -1.4508e+00, -2.1891e+00, -4.8312e+00,\n",
      "          -3.4155e+00,  1.5393e+00,  2.5557e+00, -3.0602e+00, -2.5980e-01,\n",
      "          -1.6698e-01, -4.6677e+00,  3.0493e+00, -4.9012e-02, -2.5338e+00,\n",
      "          -8.1426e-01, -1.0836e+00,  4.8138e-01,  8.0206e-01,  2.2479e-01,\n",
      "           2.8770e-01,  3.6256e+00, -1.9232e+00, -9.7304e-01, -1.8623e-01,\n",
      "          -1.1651e+00, -7.9507e-01, -3.2534e+00,  1.4263e+00,  8.9719e-01,\n",
      "          -2.9538e+00,  1.3810e+00, -4.0435e-01, -3.9732e-01, -7.2722e-01,\n",
      "           2.8104e-01, -1.8067e+00,  3.3330e-01,  2.4301e-01,  5.0384e-01,\n",
      "           4.2659e-01,  7.2429e-01, -4.4054e+00,  1.8258e+00,  4.7907e-02,\n",
      "           1.0450e+00,  1.6111e+00,  2.2119e+00,  1.8323e+00,  3.7597e-01,\n",
      "          -2.6152e+00, -7.2830e-01, -1.6605e+00,  7.7510e-01,  2.0937e+00,\n",
      "          -1.2639e+00,  7.0617e-01,  1.4159e-01, -3.7556e+00, -5.2117e-03,\n",
      "           7.9884e-01, -3.7356e-01,  1.2561e+00, -4.4045e+00,  1.3167e+00,\n",
      "           3.8841e-01,  1.9178e-01, -1.4711e+00,  5.4551e-01, -1.1239e-01,\n",
      "          -2.7509e+00,  1.3618e+00, -7.9993e-01,  6.9770e-01, -3.8995e+00,\n",
      "           1.5300e+00, -1.2313e+00,  2.0080e+00,  3.0829e+00,  3.5404e-01,\n",
      "           1.7322e+00,  2.3467e-01,  1.3423e+00, -9.1250e-01,  1.0432e+00,\n",
      "          -3.9403e+00,  2.2505e+00, -4.1024e+00, -9.0399e-01, -1.8587e+00,\n",
      "          -2.3424e-01,  1.6336e+00, -5.0859e+00,  4.8916e-01,  1.5529e+00,\n",
      "          -2.8619e+00,  1.1652e+00, -4.9667e+00, -1.0972e+00,  4.1736e-01,\n",
      "           4.1006e+00,  1.9568e+00,  1.9837e+00, -8.7619e-02, -7.3355e-01,\n",
      "           2.0959e+00, -2.4853e+00,  2.9077e+00,  2.6254e+00, -1.8023e+00,\n",
      "           3.6957e+00, -1.1504e+00,  2.1051e+00,  1.1034e+00, -1.8073e+00,\n",
      "           1.6843e+00,  3.6750e-01, -2.8009e-01, -2.0011e+00,  1.3289e-01,\n",
      "           6.1380e-01, -1.0765e+00,  2.2465e-01, -4.5580e+00,  1.0117e-01,\n",
      "           5.6491e-01,  1.0095e+00, -1.1627e+00, -9.2261e-01,  1.2580e+00,\n",
      "           1.5208e+00,  5.2348e-01, -9.7377e-02, -5.6787e-01,  1.4735e+00,\n",
      "          -5.8450e-01,  1.3220e-01,  1.5924e+00, -9.8702e-01,  1.1625e+00,\n",
      "           9.1366e-01, -1.2229e+00,  3.2490e+00,  8.2910e-02, -2.9815e-02,\n",
      "           4.5042e+00,  1.3425e-01, -2.5782e+00,  2.0466e+00,  3.5163e+00,\n",
      "           1.5013e+00,  4.0290e+00,  2.2679e+00, -7.9256e-01,  1.3492e+00,\n",
      "          -6.9426e-01,  1.3870e+00,  3.4759e-01,  2.7455e-02,  3.2502e+00,\n",
      "          -2.1821e+00,  1.0225e+00,  2.0606e+00,  5.5072e-01,  1.5072e+00,\n",
      "           2.1935e+00,  4.1188e-01, -1.3477e+00, -2.5434e+00, -4.6333e-01,\n",
      "           2.5391e-01, -6.3901e-01, -1.0175e+00, -4.2462e-01,  1.7820e+00,\n",
      "           5.8296e+00, -1.2769e+00, -1.2013e+00, -2.1929e+00, -1.2694e+00,\n",
      "           6.7179e-01,  3.9912e-01, -2.8516e+00, -1.9907e+00,  6.7329e-01,\n",
      "          -6.7930e-01, -1.1555e+00, -1.1533e+00, -7.8097e-01, -1.4301e+00,\n",
      "           1.2223e+00,  1.6254e+00, -1.7153e+00, -1.1284e+00,  3.6471e-01,\n",
      "          -9.4794e-02, -4.0479e+00,  3.7924e+00, -5.8655e-01,  4.3885e-01,\n",
      "          -2.5271e+00, -1.4264e+00,  2.0825e+00, -1.6355e+00,  4.5926e-01,\n",
      "          -4.1985e+00, -6.7715e-01, -1.4990e+00,  7.5349e-01, -1.2190e+00,\n",
      "           2.8239e+00,  2.1172e+00,  5.2027e-01,  1.0126e+00,  6.7640e-01,\n",
      "           2.9832e+00,  6.8041e-01,  9.0942e-01,  2.3844e+00,  2.1622e+00,\n",
      "           3.3380e-02,  3.5552e-01, -1.1803e+00, -3.9450e+00,  2.5405e+00,\n",
      "           9.7293e-01, -2.6372e+00,  2.2416e+00,  1.6533e+00,  2.5272e+00,\n",
      "           2.2566e+00, -2.3694e-01, -3.0756e-01, -1.1798e+00,  5.8607e-01,\n",
      "          -3.7456e-01, -2.2150e+00, -2.8872e-01, -7.8231e-01, -2.5419e+00,\n",
      "           2.5478e-01,  3.6443e-01,  5.8051e-01, -1.2971e+00,  6.1598e+00,\n",
      "           2.3748e+00, -1.3977e+00,  6.5557e-01,  1.2999e+00, -6.8806e-01,\n",
      "          -1.1792e+00,  5.0926e-01, -1.7352e+00,  1.3760e+00,  2.7404e+00,\n",
      "          -1.0562e+00, -7.7429e+00, -1.7276e+00,  5.3179e+00, -2.2865e-01,\n",
      "           1.7071e+00,  3.5853e-01,  1.0764e+00, -4.8219e-01,  1.0227e+00,\n",
      "           9.7300e-01,  3.4641e+00, -1.2929e+00, -7.2128e-01, -1.8987e+00,\n",
      "          -2.5574e+00,  2.4454e-02,  1.3852e+00,  8.3445e-02, -1.6911e+00,\n",
      "          -4.9891e-01, -1.0207e+00, -1.4108e+00,  1.2745e+00, -4.0117e-01,\n",
      "           5.2602e-01, -2.2904e-02,  2.7441e+00, -4.5875e-01,  1.5494e+00,\n",
      "           1.2911e-01,  3.6603e-01, -1.5813e+00, -1.2804e+00,  2.7213e+00,\n",
      "          -1.3616e+00,  7.8201e-01, -1.2117e+00,  1.5302e+00, -6.4820e-02,\n",
      "           1.6240e+00,  1.1902e+00,  1.3247e+00, -6.5904e-01, -4.8758e-01,\n",
      "           2.6890e+00,  3.0167e+00,  1.8179e-01,  2.9349e+00, -2.0078e+00,\n",
      "           1.3766e+00,  9.0797e-01, -1.3049e-01,  7.9904e-03,  1.8572e+00,\n",
      "          -4.2146e-01,  3.8215e+00,  3.4488e-01, -2.3632e+00, -7.2011e-02,\n",
      "          -1.4166e+00,  1.1805e+00,  3.4064e+00,  3.4026e+00, -1.4205e+00,\n",
      "          -1.5008e+00,  1.3070e-02, -1.0184e+00,  1.0715e+00,  2.4171e+00,\n",
      "          -1.9679e-01,  1.4365e+00, -4.6205e+00, -1.4083e-01,  2.9433e+00,\n",
      "           5.9551e-01, -1.1345e+00,  4.6480e-01,  2.8901e+00,  2.1337e+00,\n",
      "           1.0175e-01, -4.3468e+00,  1.0493e+00,  1.1792e+00,  1.5581e+00,\n",
      "           3.6098e-01, -6.5403e-01, -1.9612e+00, -2.8756e+00, -3.3477e+00,\n",
      "           3.9265e+00,  6.3523e-01,  1.6990e+00, -1.6515e+00, -2.3595e+00,\n",
      "           6.9391e-01, -5.8355e-01,  8.1303e-01,  3.5018e+00,  3.6858e+00,\n",
      "           3.1943e+00,  2.5609e+00, -5.8545e-01,  1.4706e+00,  2.6792e+00,\n",
      "          -6.2387e-01, -3.2123e+00,  7.0907e-01,  5.5725e-01, -1.0861e+00,\n",
      "           1.0501e-01, -9.0459e-03,  5.6557e-01, -2.5201e+00, -5.0080e-01,\n",
      "           1.5972e-02, -6.5259e-02,  2.1266e-01,  5.0934e-01,  7.0529e-01,\n",
      "           1.9507e+00, -1.3727e+00,  4.0298e+00, -5.5628e-01,  1.2814e+00,\n",
      "           2.8900e+00,  9.9596e-01, -4.1844e+00,  1.2519e+00, -8.1927e-01,\n",
      "          -4.0429e-01, -1.4076e+00, -2.7453e-01, -2.3934e+00,  1.3343e+00,\n",
      "           1.0233e+00, -5.9723e-01,  9.9125e-01, -5.8433e+00,  2.8513e+00,\n",
      "           3.4115e+00, -7.6141e-02, -2.5777e+00,  9.3260e-01,  3.2878e+00,\n",
      "          -9.8486e-01,  1.2279e+00,  9.3539e-01, -7.6926e-01, -1.0924e+00,\n",
      "          -1.4431e-01,  6.1019e-01,  7.4696e-01,  3.4589e+00, -1.4270e+00,\n",
      "           1.6724e-01,  7.0957e-01,  1.7004e-01,  1.4237e-01,  1.2642e+00,\n",
      "          -2.2810e+00, -1.0390e+00,  1.1279e+00,  4.9193e-01, -2.2678e+00,\n",
      "          -4.3240e-01,  1.3090e+00, -5.4223e-01, -2.8996e+00, -3.8062e+00,\n",
      "          -2.2788e+00,  8.4623e-01, -2.9171e-02, -2.0726e+00, -4.5483e+00,\n",
      "           1.5924e+00,  1.4185e+00, -4.0113e-01, -1.2320e+00,  2.9847e-02,\n",
      "          -7.8366e-01, -7.6771e-01, -2.6965e+00,  3.8607e+00,  1.2803e+00,\n",
      "           1.0754e-01,  3.8149e-01, -1.0690e+00,  1.3253e+00, -1.0263e+00,\n",
      "           3.8291e-02,  2.7163e+00,  2.0126e+00, -8.1381e-01, -3.8339e+00,\n",
      "           2.9909e-02,  7.5545e-02,  5.0422e-01, -4.2067e+00, -8.6975e-01,\n",
      "           4.8479e+00, -9.7449e-01, -1.1914e+00,  1.4115e+00, -1.2133e+00,\n",
      "           7.4740e-01,  4.9918e-01, -4.2968e-01, -1.0613e+00,  7.2459e-02,\n",
      "           6.3352e+00,  4.9317e-01, -1.6632e+00,  1.8974e+00,  2.0249e-01,\n",
      "          -5.8771e-01,  2.7337e+00,  9.8475e-01,  2.1768e+00, -3.0621e+00,\n",
      "           4.0005e-01, -1.2370e-01, -1.0749e+00, -4.7068e+00, -1.6074e+00,\n",
      "           6.8981e-01,  2.2089e+00, -4.9760e-01,  1.1294e+00,  5.8991e-01,\n",
      "           7.8879e-01, -8.1022e-01,  1.0362e+00,  3.2173e+00, -1.4650e+00,\n",
      "           3.4953e-01,  1.0872e+00, -1.2937e+00,  2.3130e-01, -3.4947e+00,\n",
      "           6.3448e-01, -6.1745e-01,  2.1308e+00, -1.1518e+00, -2.1894e+00,\n",
      "           1.8389e+00, -3.2967e-02, -1.0116e+00,  3.0665e+00, -8.5510e-01,\n",
      "          -1.6320e+00, -5.9173e-01, -3.5989e-01,  3.7368e-01, -7.2873e-01,\n",
      "           1.2703e+00, -2.0833e+00, -6.8330e-01,  3.6590e-01,  1.4904e+00,\n",
      "          -3.4221e-01, -1.2100e-01,  6.1310e-02, -1.5281e+00,  1.0843e+00,\n",
      "          -4.3928e-01,  7.3449e-01, -1.4698e+00,  2.0352e+00,  8.9307e-01,\n",
      "           8.6141e-02,  1.4757e+00,  4.7336e-01,  2.0745e+00, -1.8993e-01,\n",
      "          -1.2920e+00, -4.8410e-02,  1.1352e+00, -2.3434e-01, -3.1512e-01,\n",
      "           5.6487e-01, -1.3007e-01, -1.1739e+00,  3.6403e+00, -1.7317e+00,\n",
      "          -1.1955e+00, -2.1465e+00,  2.2116e-03, -8.9060e-01, -6.3067e-01,\n",
      "          -2.2957e+00,  9.2122e-01,  1.3666e+00, -3.8168e+00, -2.7501e-01,\n",
      "           6.8000e-01,  4.5827e-01, -3.1810e-01,  3.4822e-01,  8.4880e-01,\n",
      "           3.2021e+00,  1.3813e+00,  9.8377e-01,  1.3028e+00, -2.6380e+00,\n",
      "          -1.3603e+00,  2.4498e+00, -1.2948e+00,  3.3326e-01, -2.1186e+00,\n",
      "          -1.6732e+00, -1.7230e+00,  1.7578e+00, -8.3307e-02, -7.8875e-01,\n",
      "          -8.3619e-01,  1.4179e+00, -1.6555e-02,  3.5981e-01,  3.8553e+00,\n",
      "           2.0205e+00, -3.7740e-01,  5.8009e-01,  1.9741e+00, -2.1839e+00,\n",
      "          -1.0915e+00, -3.1943e+00,  3.4373e-01,  1.8234e+00, -2.2991e+00,\n",
      "          -1.1159e+00,  6.1188e-01,  4.9436e-02, -8.3465e-01,  3.6380e+00,\n",
      "           6.7928e-01,  3.2477e+00,  5.3701e-01, -3.5460e-01, -1.7566e+00,\n",
      "           2.3947e-01,  2.1592e+00,  7.4266e-03, -1.2489e+00, -1.1103e+00,\n",
      "          -2.1047e+00, -1.1235e+00, -4.5901e-01, -1.5915e-01, -7.6279e-01,\n",
      "           4.2298e+00,  4.8075e-01,  2.9505e-01,  2.1434e+00, -1.9286e+00,\n",
      "           1.0912e-01,  2.4079e-01, -1.1851e+00, -2.8685e+00, -6.3007e-01,\n",
      "           4.6103e-01,  1.0537e+00, -2.1258e+00,  4.4225e-01, -8.7085e-01,\n",
      "          -1.0705e+00,  2.2739e-01, -1.6586e+00, -2.9000e+00,  2.5013e-01,\n",
      "           7.0689e-01,  2.0666e+00, -3.4098e-01, -4.0564e-01, -3.0525e-01,\n",
      "           6.3134e-01,  7.4034e-01, -3.8591e-01, -2.3779e-01,  8.8282e-01,\n",
      "          -2.0845e+00, -7.5079e-01, -2.5147e+00,  8.5066e-01, -1.6428e-01,\n",
      "           2.0453e-01, -1.5358e+00,  3.1515e-02,  4.1809e+00,  5.8152e-02,\n",
      "           1.9153e+00,  1.7420e+00, -2.1647e+00,  2.8672e-01, -3.7691e+00,\n",
      "          -2.4607e+00,  8.4368e-01, -2.3760e+00,  9.5803e-01, -9.6325e-01,\n",
      "          -3.7476e+00,  1.4739e+00,  1.5079e+00,  6.0902e-01, -9.1097e-01,\n",
      "           2.3664e+00,  8.8647e-01,  1.8817e+00, -8.8694e-03,  2.2003e+00,\n",
      "          -7.2742e-01,  2.3856e+00,  8.2830e-01,  3.5025e-01, -7.1167e-01,\n",
      "          -1.2443e-01, -2.4092e+00, -3.6617e+00,  1.4022e-01,  2.0373e-01,\n",
      "           1.1865e+00,  1.4083e+00, -2.0400e+00, -1.9358e-01, -3.7796e+00,\n",
      "          -1.8967e+00,  8.8843e-01, -9.8551e-02,  2.1183e+00,  2.2589e+00,\n",
      "           1.6636e-01,  6.2608e-01,  8.0621e-01,  1.4424e+00,  1.6107e+00,\n",
      "           2.8583e+00,  4.0652e-02,  1.1686e+00, -3.1463e-01, -3.7341e-01,\n",
      "          -8.6046e-01, -2.8559e+00,  1.5901e+00, -6.8293e-01,  3.5928e-01,\n",
      "          -1.1664e+00,  1.9927e+00,  1.3258e+00, -3.3007e+00, -5.1340e-01,\n",
      "          -6.3783e-01,  8.7948e-01,  1.9449e+00, -1.7095e+00,  7.0238e-01,\n",
      "          -1.0339e+00,  2.5628e+00,  4.3271e-01, -3.9213e-01, -2.3063e-01,\n",
      "          -1.6312e+00,  3.0279e+00, -5.9502e-01, -4.2948e-01,  2.1297e-01,\n",
      "          -3.3650e-02, -3.1501e+00,  1.7713e+00, -8.0074e-01, -1.0833e+00,\n",
      "           1.4278e+00,  4.7413e-01, -8.1637e-01, -1.9469e+00, -4.9553e-01,\n",
      "           9.4089e-01, -2.2411e+00, -1.2868e-01, -6.5669e-01,  1.2943e+00,\n",
      "          -2.5445e-01, -2.0197e-01, -8.1994e-02,  4.9483e-01,  4.9275e+00,\n",
      "           3.0671e+00, -1.1408e+00, -3.8526e-01,  9.4702e-01, -7.3782e-01,\n",
      "           5.7722e-01, -4.5287e+00, -2.4303e+00, -5.7874e-01,  8.7987e-01,\n",
      "           1.5433e+00,  2.3600e+00, -1.7629e+00, -6.4389e-01,  8.0755e-01,\n",
      "           5.7766e-01, -9.6277e-01, -1.2710e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# Encoder initialisation & output\n",
    "encoder = TransformerEncoder(config)\n",
    "\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for i in range(2):\n",
    "    encoder_output = encoder(inputs.input_ids)\n",
    "    print(encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "702bccc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.token_embeddings.weight: False\n",
      "embeddings.position_embeddings.weight: False\n",
      "embeddings.norm.weight: False\n",
      "embeddings.norm.bias: False\n",
      "layers.0.norm1.weight: False\n",
      "layers.0.norm1.bias: False\n",
      "layers.0.norm2.weight: False\n",
      "layers.0.norm2.bias: False\n",
      "layers.0.attention.heads.0.q.weight: False\n",
      "layers.0.attention.heads.0.q.bias: False\n",
      "layers.0.attention.heads.0.k.weight: False\n",
      "layers.0.attention.heads.0.k.bias: False\n",
      "layers.0.attention.heads.0.v.weight: False\n",
      "layers.0.attention.heads.0.v.bias: False\n",
      "layers.0.attention.heads.1.q.weight: False\n",
      "layers.0.attention.heads.1.q.bias: False\n",
      "layers.0.attention.heads.1.k.weight: False\n",
      "layers.0.attention.heads.1.k.bias: False\n",
      "layers.0.attention.heads.1.v.weight: False\n",
      "layers.0.attention.heads.1.v.bias: False\n",
      "layers.0.attention.heads.2.q.weight: False\n",
      "layers.0.attention.heads.2.q.bias: False\n",
      "layers.0.attention.heads.2.k.weight: False\n",
      "layers.0.attention.heads.2.k.bias: False\n",
      "layers.0.attention.heads.2.v.weight: False\n",
      "layers.0.attention.heads.2.v.bias: False\n",
      "layers.0.attention.heads.3.q.weight: False\n",
      "layers.0.attention.heads.3.q.bias: False\n",
      "layers.0.attention.heads.3.k.weight: False\n",
      "layers.0.attention.heads.3.k.bias: False\n",
      "layers.0.attention.heads.3.v.weight: False\n",
      "layers.0.attention.heads.3.v.bias: False\n",
      "layers.0.attention.heads.4.q.weight: False\n",
      "layers.0.attention.heads.4.q.bias: False\n",
      "layers.0.attention.heads.4.k.weight: False\n",
      "layers.0.attention.heads.4.k.bias: False\n",
      "layers.0.attention.heads.4.v.weight: False\n",
      "layers.0.attention.heads.4.v.bias: False\n",
      "layers.0.attention.heads.5.q.weight: False\n",
      "layers.0.attention.heads.5.q.bias: False\n",
      "layers.0.attention.heads.5.k.weight: False\n",
      "layers.0.attention.heads.5.k.bias: False\n",
      "layers.0.attention.heads.5.v.weight: False\n",
      "layers.0.attention.heads.5.v.bias: False\n",
      "layers.0.attention.heads.6.q.weight: False\n",
      "layers.0.attention.heads.6.q.bias: False\n",
      "layers.0.attention.heads.6.k.weight: False\n",
      "layers.0.attention.heads.6.k.bias: False\n",
      "layers.0.attention.heads.6.v.weight: False\n",
      "layers.0.attention.heads.6.v.bias: False\n",
      "layers.0.attention.heads.7.q.weight: False\n",
      "layers.0.attention.heads.7.q.bias: False\n",
      "layers.0.attention.heads.7.k.weight: False\n",
      "layers.0.attention.heads.7.k.bias: False\n",
      "layers.0.attention.heads.7.v.weight: False\n",
      "layers.0.attention.heads.7.v.bias: False\n",
      "layers.0.attention.heads.8.q.weight: False\n",
      "layers.0.attention.heads.8.q.bias: False\n",
      "layers.0.attention.heads.8.k.weight: False\n",
      "layers.0.attention.heads.8.k.bias: False\n",
      "layers.0.attention.heads.8.v.weight: False\n",
      "layers.0.attention.heads.8.v.bias: False\n",
      "layers.0.attention.heads.9.q.weight: False\n",
      "layers.0.attention.heads.9.q.bias: False\n",
      "layers.0.attention.heads.9.k.weight: False\n",
      "layers.0.attention.heads.9.k.bias: False\n",
      "layers.0.attention.heads.9.v.weight: False\n",
      "layers.0.attention.heads.9.v.bias: False\n",
      "layers.0.attention.heads.10.q.weight: False\n",
      "layers.0.attention.heads.10.q.bias: False\n",
      "layers.0.attention.heads.10.k.weight: False\n",
      "layers.0.attention.heads.10.k.bias: False\n",
      "layers.0.attention.heads.10.v.weight: False\n",
      "layers.0.attention.heads.10.v.bias: False\n",
      "layers.0.attention.heads.11.q.weight: False\n",
      "layers.0.attention.heads.11.q.bias: False\n",
      "layers.0.attention.heads.11.k.weight: False\n",
      "layers.0.attention.heads.11.k.bias: False\n",
      "layers.0.attention.heads.11.v.weight: False\n",
      "layers.0.attention.heads.11.v.bias: False\n",
      "layers.0.attention.out_linear.weight: False\n",
      "layers.0.attention.out_linear.bias: False\n",
      "layers.0.feed_forward.linear1.weight: False\n",
      "layers.0.feed_forward.linear1.bias: False\n",
      "layers.0.feed_forward.linear2.weight: False\n",
      "layers.0.feed_forward.linear2.bias: False\n",
      "layers.1.norm1.weight: False\n",
      "layers.1.norm1.bias: False\n",
      "layers.1.norm2.weight: False\n",
      "layers.1.norm2.bias: False\n",
      "layers.1.attention.heads.0.q.weight: False\n",
      "layers.1.attention.heads.0.q.bias: False\n",
      "layers.1.attention.heads.0.k.weight: False\n",
      "layers.1.attention.heads.0.k.bias: False\n",
      "layers.1.attention.heads.0.v.weight: False\n",
      "layers.1.attention.heads.0.v.bias: False\n",
      "layers.1.attention.heads.1.q.weight: False\n",
      "layers.1.attention.heads.1.q.bias: False\n",
      "layers.1.attention.heads.1.k.weight: False\n",
      "layers.1.attention.heads.1.k.bias: False\n",
      "layers.1.attention.heads.1.v.weight: False\n",
      "layers.1.attention.heads.1.v.bias: False\n",
      "layers.1.attention.heads.2.q.weight: False\n",
      "layers.1.attention.heads.2.q.bias: False\n",
      "layers.1.attention.heads.2.k.weight: False\n",
      "layers.1.attention.heads.2.k.bias: False\n",
      "layers.1.attention.heads.2.v.weight: False\n",
      "layers.1.attention.heads.2.v.bias: False\n",
      "layers.1.attention.heads.3.q.weight: False\n",
      "layers.1.attention.heads.3.q.bias: False\n",
      "layers.1.attention.heads.3.k.weight: False\n",
      "layers.1.attention.heads.3.k.bias: False\n",
      "layers.1.attention.heads.3.v.weight: False\n",
      "layers.1.attention.heads.3.v.bias: False\n",
      "layers.1.attention.heads.4.q.weight: False\n",
      "layers.1.attention.heads.4.q.bias: False\n",
      "layers.1.attention.heads.4.k.weight: False\n",
      "layers.1.attention.heads.4.k.bias: False\n",
      "layers.1.attention.heads.4.v.weight: False\n",
      "layers.1.attention.heads.4.v.bias: False\n",
      "layers.1.attention.heads.5.q.weight: False\n",
      "layers.1.attention.heads.5.q.bias: False\n",
      "layers.1.attention.heads.5.k.weight: False\n",
      "layers.1.attention.heads.5.k.bias: False\n",
      "layers.1.attention.heads.5.v.weight: False\n",
      "layers.1.attention.heads.5.v.bias: False\n",
      "layers.1.attention.heads.6.q.weight: False\n",
      "layers.1.attention.heads.6.q.bias: False\n",
      "layers.1.attention.heads.6.k.weight: False\n",
      "layers.1.attention.heads.6.k.bias: False\n",
      "layers.1.attention.heads.6.v.weight: False\n",
      "layers.1.attention.heads.6.v.bias: False\n",
      "layers.1.attention.heads.7.q.weight: False\n",
      "layers.1.attention.heads.7.q.bias: False\n",
      "layers.1.attention.heads.7.k.weight: False\n",
      "layers.1.attention.heads.7.k.bias: False\n",
      "layers.1.attention.heads.7.v.weight: False\n",
      "layers.1.attention.heads.7.v.bias: False\n",
      "layers.1.attention.heads.8.q.weight: False\n",
      "layers.1.attention.heads.8.q.bias: False\n",
      "layers.1.attention.heads.8.k.weight: False\n",
      "layers.1.attention.heads.8.k.bias: False\n",
      "layers.1.attention.heads.8.v.weight: False\n",
      "layers.1.attention.heads.8.v.bias: False\n",
      "layers.1.attention.heads.9.q.weight: False\n",
      "layers.1.attention.heads.9.q.bias: False\n",
      "layers.1.attention.heads.9.k.weight: False\n",
      "layers.1.attention.heads.9.k.bias: False\n",
      "layers.1.attention.heads.9.v.weight: False\n",
      "layers.1.attention.heads.9.v.bias: False\n",
      "layers.1.attention.heads.10.q.weight: False\n",
      "layers.1.attention.heads.10.q.bias: False\n",
      "layers.1.attention.heads.10.k.weight: False\n",
      "layers.1.attention.heads.10.k.bias: False\n",
      "layers.1.attention.heads.10.v.weight: False\n",
      "layers.1.attention.heads.10.v.bias: False\n",
      "layers.1.attention.heads.11.q.weight: False\n",
      "layers.1.attention.heads.11.q.bias: False\n",
      "layers.1.attention.heads.11.k.weight: False\n",
      "layers.1.attention.heads.11.k.bias: False\n",
      "layers.1.attention.heads.11.v.weight: False\n",
      "layers.1.attention.heads.11.v.bias: False\n",
      "layers.1.attention.out_linear.weight: False\n",
      "layers.1.attention.out_linear.bias: False\n",
      "layers.1.feed_forward.linear1.weight: False\n",
      "layers.1.feed_forward.linear1.bias: False\n",
      "layers.1.feed_forward.linear2.weight: False\n",
      "layers.1.feed_forward.linear2.bias: False\n",
      "layers.2.norm1.weight: False\n",
      "layers.2.norm1.bias: False\n",
      "layers.2.norm2.weight: False\n",
      "layers.2.norm2.bias: False\n",
      "layers.2.attention.heads.0.q.weight: False\n",
      "layers.2.attention.heads.0.q.bias: False\n",
      "layers.2.attention.heads.0.k.weight: False\n",
      "layers.2.attention.heads.0.k.bias: False\n",
      "layers.2.attention.heads.0.v.weight: False\n",
      "layers.2.attention.heads.0.v.bias: False\n",
      "layers.2.attention.heads.1.q.weight: False\n",
      "layers.2.attention.heads.1.q.bias: False\n",
      "layers.2.attention.heads.1.k.weight: False\n",
      "layers.2.attention.heads.1.k.bias: False\n",
      "layers.2.attention.heads.1.v.weight: False\n",
      "layers.2.attention.heads.1.v.bias: False\n",
      "layers.2.attention.heads.2.q.weight: False\n",
      "layers.2.attention.heads.2.q.bias: False\n",
      "layers.2.attention.heads.2.k.weight: False\n",
      "layers.2.attention.heads.2.k.bias: False\n",
      "layers.2.attention.heads.2.v.weight: False\n",
      "layers.2.attention.heads.2.v.bias: False\n",
      "layers.2.attention.heads.3.q.weight: False\n",
      "layers.2.attention.heads.3.q.bias: False\n",
      "layers.2.attention.heads.3.k.weight: False\n",
      "layers.2.attention.heads.3.k.bias: False\n",
      "layers.2.attention.heads.3.v.weight: False\n",
      "layers.2.attention.heads.3.v.bias: False\n",
      "layers.2.attention.heads.4.q.weight: False\n",
      "layers.2.attention.heads.4.q.bias: False\n",
      "layers.2.attention.heads.4.k.weight: False\n",
      "layers.2.attention.heads.4.k.bias: False\n",
      "layers.2.attention.heads.4.v.weight: False\n",
      "layers.2.attention.heads.4.v.bias: False\n",
      "layers.2.attention.heads.5.q.weight: False\n",
      "layers.2.attention.heads.5.q.bias: False\n",
      "layers.2.attention.heads.5.k.weight: False\n",
      "layers.2.attention.heads.5.k.bias: False\n",
      "layers.2.attention.heads.5.v.weight: False\n",
      "layers.2.attention.heads.5.v.bias: False\n",
      "layers.2.attention.heads.6.q.weight: False\n",
      "layers.2.attention.heads.6.q.bias: False\n",
      "layers.2.attention.heads.6.k.weight: False\n",
      "layers.2.attention.heads.6.k.bias: False\n",
      "layers.2.attention.heads.6.v.weight: False\n",
      "layers.2.attention.heads.6.v.bias: False\n",
      "layers.2.attention.heads.7.q.weight: False\n",
      "layers.2.attention.heads.7.q.bias: False\n",
      "layers.2.attention.heads.7.k.weight: False\n",
      "layers.2.attention.heads.7.k.bias: False\n",
      "layers.2.attention.heads.7.v.weight: False\n",
      "layers.2.attention.heads.7.v.bias: False\n",
      "layers.2.attention.heads.8.q.weight: False\n",
      "layers.2.attention.heads.8.q.bias: False\n",
      "layers.2.attention.heads.8.k.weight: False\n",
      "layers.2.attention.heads.8.k.bias: False\n",
      "layers.2.attention.heads.8.v.weight: False\n",
      "layers.2.attention.heads.8.v.bias: False\n",
      "layers.2.attention.heads.9.q.weight: False\n",
      "layers.2.attention.heads.9.q.bias: False\n",
      "layers.2.attention.heads.9.k.weight: False\n",
      "layers.2.attention.heads.9.k.bias: False\n",
      "layers.2.attention.heads.9.v.weight: False\n",
      "layers.2.attention.heads.9.v.bias: False\n",
      "layers.2.attention.heads.10.q.weight: False\n",
      "layers.2.attention.heads.10.q.bias: False\n",
      "layers.2.attention.heads.10.k.weight: False\n",
      "layers.2.attention.heads.10.k.bias: False\n",
      "layers.2.attention.heads.10.v.weight: False\n",
      "layers.2.attention.heads.10.v.bias: False\n",
      "layers.2.attention.heads.11.q.weight: False\n",
      "layers.2.attention.heads.11.q.bias: False\n",
      "layers.2.attention.heads.11.k.weight: False\n",
      "layers.2.attention.heads.11.k.bias: False\n",
      "layers.2.attention.heads.11.v.weight: False\n",
      "layers.2.attention.heads.11.v.bias: False\n",
      "layers.2.attention.out_linear.weight: False\n",
      "layers.2.attention.out_linear.bias: False\n",
      "layers.2.feed_forward.linear1.weight: False\n",
      "layers.2.feed_forward.linear1.bias: False\n",
      "layers.2.feed_forward.linear2.weight: False\n",
      "layers.2.feed_forward.linear2.bias: False\n",
      "layers.3.norm1.weight: False\n",
      "layers.3.norm1.bias: False\n",
      "layers.3.norm2.weight: False\n",
      "layers.3.norm2.bias: False\n",
      "layers.3.attention.heads.0.q.weight: False\n",
      "layers.3.attention.heads.0.q.bias: False\n",
      "layers.3.attention.heads.0.k.weight: False\n",
      "layers.3.attention.heads.0.k.bias: False\n",
      "layers.3.attention.heads.0.v.weight: False\n",
      "layers.3.attention.heads.0.v.bias: False\n",
      "layers.3.attention.heads.1.q.weight: False\n",
      "layers.3.attention.heads.1.q.bias: False\n",
      "layers.3.attention.heads.1.k.weight: False\n",
      "layers.3.attention.heads.1.k.bias: False\n",
      "layers.3.attention.heads.1.v.weight: False\n",
      "layers.3.attention.heads.1.v.bias: False\n",
      "layers.3.attention.heads.2.q.weight: False\n",
      "layers.3.attention.heads.2.q.bias: False\n",
      "layers.3.attention.heads.2.k.weight: False\n",
      "layers.3.attention.heads.2.k.bias: False\n",
      "layers.3.attention.heads.2.v.weight: False\n",
      "layers.3.attention.heads.2.v.bias: False\n",
      "layers.3.attention.heads.3.q.weight: False\n",
      "layers.3.attention.heads.3.q.bias: False\n",
      "layers.3.attention.heads.3.k.weight: False\n",
      "layers.3.attention.heads.3.k.bias: False\n",
      "layers.3.attention.heads.3.v.weight: False\n",
      "layers.3.attention.heads.3.v.bias: False\n",
      "layers.3.attention.heads.4.q.weight: False\n",
      "layers.3.attention.heads.4.q.bias: False\n",
      "layers.3.attention.heads.4.k.weight: False\n",
      "layers.3.attention.heads.4.k.bias: False\n",
      "layers.3.attention.heads.4.v.weight: False\n",
      "layers.3.attention.heads.4.v.bias: False\n",
      "layers.3.attention.heads.5.q.weight: False\n",
      "layers.3.attention.heads.5.q.bias: False\n",
      "layers.3.attention.heads.5.k.weight: False\n",
      "layers.3.attention.heads.5.k.bias: False\n",
      "layers.3.attention.heads.5.v.weight: False\n",
      "layers.3.attention.heads.5.v.bias: False\n",
      "layers.3.attention.heads.6.q.weight: False\n",
      "layers.3.attention.heads.6.q.bias: False\n",
      "layers.3.attention.heads.6.k.weight: False\n",
      "layers.3.attention.heads.6.k.bias: False\n",
      "layers.3.attention.heads.6.v.weight: False\n",
      "layers.3.attention.heads.6.v.bias: False\n",
      "layers.3.attention.heads.7.q.weight: False\n",
      "layers.3.attention.heads.7.q.bias: False\n",
      "layers.3.attention.heads.7.k.weight: False\n",
      "layers.3.attention.heads.7.k.bias: False\n",
      "layers.3.attention.heads.7.v.weight: False\n",
      "layers.3.attention.heads.7.v.bias: False\n",
      "layers.3.attention.heads.8.q.weight: False\n",
      "layers.3.attention.heads.8.q.bias: False\n",
      "layers.3.attention.heads.8.k.weight: False\n",
      "layers.3.attention.heads.8.k.bias: False\n",
      "layers.3.attention.heads.8.v.weight: False\n",
      "layers.3.attention.heads.8.v.bias: False\n",
      "layers.3.attention.heads.9.q.weight: False\n",
      "layers.3.attention.heads.9.q.bias: False\n",
      "layers.3.attention.heads.9.k.weight: False\n",
      "layers.3.attention.heads.9.k.bias: False\n",
      "layers.3.attention.heads.9.v.weight: False\n",
      "layers.3.attention.heads.9.v.bias: False\n",
      "layers.3.attention.heads.10.q.weight: False\n",
      "layers.3.attention.heads.10.q.bias: False\n",
      "layers.3.attention.heads.10.k.weight: False\n",
      "layers.3.attention.heads.10.k.bias: False\n",
      "layers.3.attention.heads.10.v.weight: False\n",
      "layers.3.attention.heads.10.v.bias: False\n",
      "layers.3.attention.heads.11.q.weight: False\n",
      "layers.3.attention.heads.11.q.bias: False\n",
      "layers.3.attention.heads.11.k.weight: False\n",
      "layers.3.attention.heads.11.k.bias: False\n",
      "layers.3.attention.heads.11.v.weight: False\n",
      "layers.3.attention.heads.11.v.bias: False\n",
      "layers.3.attention.out_linear.weight: False\n",
      "layers.3.attention.out_linear.bias: False\n",
      "layers.3.feed_forward.linear1.weight: False\n",
      "layers.3.feed_forward.linear1.bias: False\n",
      "layers.3.feed_forward.linear2.weight: False\n",
      "layers.3.feed_forward.linear2.bias: False\n",
      "layers.4.norm1.weight: False\n",
      "layers.4.norm1.bias: False\n",
      "layers.4.norm2.weight: False\n",
      "layers.4.norm2.bias: False\n",
      "layers.4.attention.heads.0.q.weight: False\n",
      "layers.4.attention.heads.0.q.bias: False\n",
      "layers.4.attention.heads.0.k.weight: False\n",
      "layers.4.attention.heads.0.k.bias: False\n",
      "layers.4.attention.heads.0.v.weight: False\n",
      "layers.4.attention.heads.0.v.bias: False\n",
      "layers.4.attention.heads.1.q.weight: False\n",
      "layers.4.attention.heads.1.q.bias: False\n",
      "layers.4.attention.heads.1.k.weight: False\n",
      "layers.4.attention.heads.1.k.bias: False\n",
      "layers.4.attention.heads.1.v.weight: False\n",
      "layers.4.attention.heads.1.v.bias: False\n",
      "layers.4.attention.heads.2.q.weight: False\n",
      "layers.4.attention.heads.2.q.bias: False\n",
      "layers.4.attention.heads.2.k.weight: False\n",
      "layers.4.attention.heads.2.k.bias: False\n",
      "layers.4.attention.heads.2.v.weight: False\n",
      "layers.4.attention.heads.2.v.bias: False\n",
      "layers.4.attention.heads.3.q.weight: False\n",
      "layers.4.attention.heads.3.q.bias: False\n",
      "layers.4.attention.heads.3.k.weight: False\n",
      "layers.4.attention.heads.3.k.bias: False\n",
      "layers.4.attention.heads.3.v.weight: False\n",
      "layers.4.attention.heads.3.v.bias: False\n",
      "layers.4.attention.heads.4.q.weight: False\n",
      "layers.4.attention.heads.4.q.bias: False\n",
      "layers.4.attention.heads.4.k.weight: False\n",
      "layers.4.attention.heads.4.k.bias: False\n",
      "layers.4.attention.heads.4.v.weight: False\n",
      "layers.4.attention.heads.4.v.bias: False\n",
      "layers.4.attention.heads.5.q.weight: False\n",
      "layers.4.attention.heads.5.q.bias: False\n",
      "layers.4.attention.heads.5.k.weight: False\n",
      "layers.4.attention.heads.5.k.bias: False\n",
      "layers.4.attention.heads.5.v.weight: False\n",
      "layers.4.attention.heads.5.v.bias: False\n",
      "layers.4.attention.heads.6.q.weight: False\n",
      "layers.4.attention.heads.6.q.bias: False\n",
      "layers.4.attention.heads.6.k.weight: False\n",
      "layers.4.attention.heads.6.k.bias: False\n",
      "layers.4.attention.heads.6.v.weight: False\n",
      "layers.4.attention.heads.6.v.bias: False\n",
      "layers.4.attention.heads.7.q.weight: False\n",
      "layers.4.attention.heads.7.q.bias: False\n",
      "layers.4.attention.heads.7.k.weight: False\n",
      "layers.4.attention.heads.7.k.bias: False\n",
      "layers.4.attention.heads.7.v.weight: False\n",
      "layers.4.attention.heads.7.v.bias: False\n",
      "layers.4.attention.heads.8.q.weight: False\n",
      "layers.4.attention.heads.8.q.bias: False\n",
      "layers.4.attention.heads.8.k.weight: False\n",
      "layers.4.attention.heads.8.k.bias: False\n",
      "layers.4.attention.heads.8.v.weight: False\n",
      "layers.4.attention.heads.8.v.bias: False\n",
      "layers.4.attention.heads.9.q.weight: False\n",
      "layers.4.attention.heads.9.q.bias: False\n",
      "layers.4.attention.heads.9.k.weight: False\n",
      "layers.4.attention.heads.9.k.bias: False\n",
      "layers.4.attention.heads.9.v.weight: False\n",
      "layers.4.attention.heads.9.v.bias: False\n",
      "layers.4.attention.heads.10.q.weight: False\n",
      "layers.4.attention.heads.10.q.bias: False\n",
      "layers.4.attention.heads.10.k.weight: False\n",
      "layers.4.attention.heads.10.k.bias: False\n",
      "layers.4.attention.heads.10.v.weight: False\n",
      "layers.4.attention.heads.10.v.bias: False\n",
      "layers.4.attention.heads.11.q.weight: False\n",
      "layers.4.attention.heads.11.q.bias: False\n",
      "layers.4.attention.heads.11.k.weight: False\n",
      "layers.4.attention.heads.11.k.bias: False\n",
      "layers.4.attention.heads.11.v.weight: False\n",
      "layers.4.attention.heads.11.v.bias: False\n",
      "layers.4.attention.out_linear.weight: False\n",
      "layers.4.attention.out_linear.bias: False\n",
      "layers.4.feed_forward.linear1.weight: False\n",
      "layers.4.feed_forward.linear1.bias: False\n",
      "layers.4.feed_forward.linear2.weight: False\n",
      "layers.4.feed_forward.linear2.bias: False\n",
      "layers.5.norm1.weight: False\n",
      "layers.5.norm1.bias: False\n",
      "layers.5.norm2.weight: False\n",
      "layers.5.norm2.bias: False\n",
      "layers.5.attention.heads.0.q.weight: False\n",
      "layers.5.attention.heads.0.q.bias: False\n",
      "layers.5.attention.heads.0.k.weight: False\n",
      "layers.5.attention.heads.0.k.bias: False\n",
      "layers.5.attention.heads.0.v.weight: False\n",
      "layers.5.attention.heads.0.v.bias: False\n",
      "layers.5.attention.heads.1.q.weight: False\n",
      "layers.5.attention.heads.1.q.bias: False\n",
      "layers.5.attention.heads.1.k.weight: False\n",
      "layers.5.attention.heads.1.k.bias: False\n",
      "layers.5.attention.heads.1.v.weight: False\n",
      "layers.5.attention.heads.1.v.bias: False\n",
      "layers.5.attention.heads.2.q.weight: False\n",
      "layers.5.attention.heads.2.q.bias: False\n",
      "layers.5.attention.heads.2.k.weight: False\n",
      "layers.5.attention.heads.2.k.bias: False\n",
      "layers.5.attention.heads.2.v.weight: False\n",
      "layers.5.attention.heads.2.v.bias: False\n",
      "layers.5.attention.heads.3.q.weight: False\n",
      "layers.5.attention.heads.3.q.bias: False\n",
      "layers.5.attention.heads.3.k.weight: False\n",
      "layers.5.attention.heads.3.k.bias: False\n",
      "layers.5.attention.heads.3.v.weight: False\n",
      "layers.5.attention.heads.3.v.bias: False\n",
      "layers.5.attention.heads.4.q.weight: False\n",
      "layers.5.attention.heads.4.q.bias: False\n",
      "layers.5.attention.heads.4.k.weight: False\n",
      "layers.5.attention.heads.4.k.bias: False\n",
      "layers.5.attention.heads.4.v.weight: False\n",
      "layers.5.attention.heads.4.v.bias: False\n",
      "layers.5.attention.heads.5.q.weight: False\n",
      "layers.5.attention.heads.5.q.bias: False\n",
      "layers.5.attention.heads.5.k.weight: False\n",
      "layers.5.attention.heads.5.k.bias: False\n",
      "layers.5.attention.heads.5.v.weight: False\n",
      "layers.5.attention.heads.5.v.bias: False\n",
      "layers.5.attention.heads.6.q.weight: False\n",
      "layers.5.attention.heads.6.q.bias: False\n",
      "layers.5.attention.heads.6.k.weight: False\n",
      "layers.5.attention.heads.6.k.bias: False\n",
      "layers.5.attention.heads.6.v.weight: False\n",
      "layers.5.attention.heads.6.v.bias: False\n",
      "layers.5.attention.heads.7.q.weight: False\n",
      "layers.5.attention.heads.7.q.bias: False\n",
      "layers.5.attention.heads.7.k.weight: False\n",
      "layers.5.attention.heads.7.k.bias: False\n",
      "layers.5.attention.heads.7.v.weight: False\n",
      "layers.5.attention.heads.7.v.bias: False\n",
      "layers.5.attention.heads.8.q.weight: False\n",
      "layers.5.attention.heads.8.q.bias: False\n",
      "layers.5.attention.heads.8.k.weight: False\n",
      "layers.5.attention.heads.8.k.bias: False\n",
      "layers.5.attention.heads.8.v.weight: False\n",
      "layers.5.attention.heads.8.v.bias: False\n",
      "layers.5.attention.heads.9.q.weight: False\n",
      "layers.5.attention.heads.9.q.bias: False\n",
      "layers.5.attention.heads.9.k.weight: False\n",
      "layers.5.attention.heads.9.k.bias: False\n",
      "layers.5.attention.heads.9.v.weight: False\n",
      "layers.5.attention.heads.9.v.bias: False\n",
      "layers.5.attention.heads.10.q.weight: False\n",
      "layers.5.attention.heads.10.q.bias: False\n",
      "layers.5.attention.heads.10.k.weight: False\n",
      "layers.5.attention.heads.10.k.bias: False\n",
      "layers.5.attention.heads.10.v.weight: False\n",
      "layers.5.attention.heads.10.v.bias: False\n",
      "layers.5.attention.heads.11.q.weight: False\n",
      "layers.5.attention.heads.11.q.bias: False\n",
      "layers.5.attention.heads.11.k.weight: False\n",
      "layers.5.attention.heads.11.k.bias: False\n",
      "layers.5.attention.heads.11.v.weight: False\n",
      "layers.5.attention.heads.11.v.bias: False\n",
      "layers.5.attention.out_linear.weight: False\n",
      "layers.5.attention.out_linear.bias: False\n",
      "layers.5.feed_forward.linear1.weight: False\n",
      "layers.5.feed_forward.linear1.bias: False\n",
      "layers.5.feed_forward.linear2.weight: False\n",
      "layers.5.feed_forward.linear2.bias: False\n",
      "layers.6.norm1.weight: False\n",
      "layers.6.norm1.bias: False\n",
      "layers.6.norm2.weight: False\n",
      "layers.6.norm2.bias: False\n",
      "layers.6.attention.heads.0.q.weight: False\n",
      "layers.6.attention.heads.0.q.bias: False\n",
      "layers.6.attention.heads.0.k.weight: False\n",
      "layers.6.attention.heads.0.k.bias: False\n",
      "layers.6.attention.heads.0.v.weight: False\n",
      "layers.6.attention.heads.0.v.bias: False\n",
      "layers.6.attention.heads.1.q.weight: False\n",
      "layers.6.attention.heads.1.q.bias: False\n",
      "layers.6.attention.heads.1.k.weight: False\n",
      "layers.6.attention.heads.1.k.bias: False\n",
      "layers.6.attention.heads.1.v.weight: False\n",
      "layers.6.attention.heads.1.v.bias: False\n",
      "layers.6.attention.heads.2.q.weight: False\n",
      "layers.6.attention.heads.2.q.bias: False\n",
      "layers.6.attention.heads.2.k.weight: False\n",
      "layers.6.attention.heads.2.k.bias: False\n",
      "layers.6.attention.heads.2.v.weight: False\n",
      "layers.6.attention.heads.2.v.bias: False\n",
      "layers.6.attention.heads.3.q.weight: False\n",
      "layers.6.attention.heads.3.q.bias: False\n",
      "layers.6.attention.heads.3.k.weight: False\n",
      "layers.6.attention.heads.3.k.bias: False\n",
      "layers.6.attention.heads.3.v.weight: False\n",
      "layers.6.attention.heads.3.v.bias: False\n",
      "layers.6.attention.heads.4.q.weight: False\n",
      "layers.6.attention.heads.4.q.bias: False\n",
      "layers.6.attention.heads.4.k.weight: False\n",
      "layers.6.attention.heads.4.k.bias: False\n",
      "layers.6.attention.heads.4.v.weight: False\n",
      "layers.6.attention.heads.4.v.bias: False\n",
      "layers.6.attention.heads.5.q.weight: False\n",
      "layers.6.attention.heads.5.q.bias: False\n",
      "layers.6.attention.heads.5.k.weight: False\n",
      "layers.6.attention.heads.5.k.bias: False\n",
      "layers.6.attention.heads.5.v.weight: False\n",
      "layers.6.attention.heads.5.v.bias: False\n",
      "layers.6.attention.heads.6.q.weight: False\n",
      "layers.6.attention.heads.6.q.bias: False\n",
      "layers.6.attention.heads.6.k.weight: False\n",
      "layers.6.attention.heads.6.k.bias: False\n",
      "layers.6.attention.heads.6.v.weight: False\n",
      "layers.6.attention.heads.6.v.bias: False\n",
      "layers.6.attention.heads.7.q.weight: False\n",
      "layers.6.attention.heads.7.q.bias: False\n",
      "layers.6.attention.heads.7.k.weight: False\n",
      "layers.6.attention.heads.7.k.bias: False\n",
      "layers.6.attention.heads.7.v.weight: False\n",
      "layers.6.attention.heads.7.v.bias: False\n",
      "layers.6.attention.heads.8.q.weight: False\n",
      "layers.6.attention.heads.8.q.bias: False\n",
      "layers.6.attention.heads.8.k.weight: False\n",
      "layers.6.attention.heads.8.k.bias: False\n",
      "layers.6.attention.heads.8.v.weight: False\n",
      "layers.6.attention.heads.8.v.bias: False\n",
      "layers.6.attention.heads.9.q.weight: False\n",
      "layers.6.attention.heads.9.q.bias: False\n",
      "layers.6.attention.heads.9.k.weight: False\n",
      "layers.6.attention.heads.9.k.bias: False\n",
      "layers.6.attention.heads.9.v.weight: False\n",
      "layers.6.attention.heads.9.v.bias: False\n",
      "layers.6.attention.heads.10.q.weight: False\n",
      "layers.6.attention.heads.10.q.bias: False\n",
      "layers.6.attention.heads.10.k.weight: False\n",
      "layers.6.attention.heads.10.k.bias: False\n",
      "layers.6.attention.heads.10.v.weight: False\n",
      "layers.6.attention.heads.10.v.bias: False\n",
      "layers.6.attention.heads.11.q.weight: False\n",
      "layers.6.attention.heads.11.q.bias: False\n",
      "layers.6.attention.heads.11.k.weight: False\n",
      "layers.6.attention.heads.11.k.bias: False\n",
      "layers.6.attention.heads.11.v.weight: False\n",
      "layers.6.attention.heads.11.v.bias: False\n",
      "layers.6.attention.out_linear.weight: False\n",
      "layers.6.attention.out_linear.bias: False\n",
      "layers.6.feed_forward.linear1.weight: False\n",
      "layers.6.feed_forward.linear1.bias: False\n",
      "layers.6.feed_forward.linear2.weight: False\n",
      "layers.6.feed_forward.linear2.bias: False\n",
      "layers.7.norm1.weight: False\n",
      "layers.7.norm1.bias: False\n",
      "layers.7.norm2.weight: False\n",
      "layers.7.norm2.bias: False\n",
      "layers.7.attention.heads.0.q.weight: False\n",
      "layers.7.attention.heads.0.q.bias: False\n",
      "layers.7.attention.heads.0.k.weight: False\n",
      "layers.7.attention.heads.0.k.bias: False\n",
      "layers.7.attention.heads.0.v.weight: False\n",
      "layers.7.attention.heads.0.v.bias: False\n",
      "layers.7.attention.heads.1.q.weight: False\n",
      "layers.7.attention.heads.1.q.bias: False\n",
      "layers.7.attention.heads.1.k.weight: False\n",
      "layers.7.attention.heads.1.k.bias: False\n",
      "layers.7.attention.heads.1.v.weight: False\n",
      "layers.7.attention.heads.1.v.bias: False\n",
      "layers.7.attention.heads.2.q.weight: False\n",
      "layers.7.attention.heads.2.q.bias: False\n",
      "layers.7.attention.heads.2.k.weight: False\n",
      "layers.7.attention.heads.2.k.bias: False\n",
      "layers.7.attention.heads.2.v.weight: False\n",
      "layers.7.attention.heads.2.v.bias: False\n",
      "layers.7.attention.heads.3.q.weight: False\n",
      "layers.7.attention.heads.3.q.bias: False\n",
      "layers.7.attention.heads.3.k.weight: False\n",
      "layers.7.attention.heads.3.k.bias: False\n",
      "layers.7.attention.heads.3.v.weight: False\n",
      "layers.7.attention.heads.3.v.bias: False\n",
      "layers.7.attention.heads.4.q.weight: False\n",
      "layers.7.attention.heads.4.q.bias: False\n",
      "layers.7.attention.heads.4.k.weight: False\n",
      "layers.7.attention.heads.4.k.bias: False\n",
      "layers.7.attention.heads.4.v.weight: False\n",
      "layers.7.attention.heads.4.v.bias: False\n",
      "layers.7.attention.heads.5.q.weight: False\n",
      "layers.7.attention.heads.5.q.bias: False\n",
      "layers.7.attention.heads.5.k.weight: False\n",
      "layers.7.attention.heads.5.k.bias: False\n",
      "layers.7.attention.heads.5.v.weight: False\n",
      "layers.7.attention.heads.5.v.bias: False\n",
      "layers.7.attention.heads.6.q.weight: False\n",
      "layers.7.attention.heads.6.q.bias: False\n",
      "layers.7.attention.heads.6.k.weight: False\n",
      "layers.7.attention.heads.6.k.bias: False\n",
      "layers.7.attention.heads.6.v.weight: False\n",
      "layers.7.attention.heads.6.v.bias: False\n",
      "layers.7.attention.heads.7.q.weight: False\n",
      "layers.7.attention.heads.7.q.bias: False\n",
      "layers.7.attention.heads.7.k.weight: False\n",
      "layers.7.attention.heads.7.k.bias: False\n",
      "layers.7.attention.heads.7.v.weight: False\n",
      "layers.7.attention.heads.7.v.bias: False\n",
      "layers.7.attention.heads.8.q.weight: False\n",
      "layers.7.attention.heads.8.q.bias: False\n",
      "layers.7.attention.heads.8.k.weight: False\n",
      "layers.7.attention.heads.8.k.bias: False\n",
      "layers.7.attention.heads.8.v.weight: False\n",
      "layers.7.attention.heads.8.v.bias: False\n",
      "layers.7.attention.heads.9.q.weight: False\n",
      "layers.7.attention.heads.9.q.bias: False\n",
      "layers.7.attention.heads.9.k.weight: False\n",
      "layers.7.attention.heads.9.k.bias: False\n",
      "layers.7.attention.heads.9.v.weight: False\n",
      "layers.7.attention.heads.9.v.bias: False\n",
      "layers.7.attention.heads.10.q.weight: False\n",
      "layers.7.attention.heads.10.q.bias: False\n",
      "layers.7.attention.heads.10.k.weight: False\n",
      "layers.7.attention.heads.10.k.bias: False\n",
      "layers.7.attention.heads.10.v.weight: False\n",
      "layers.7.attention.heads.10.v.bias: False\n",
      "layers.7.attention.heads.11.q.weight: False\n",
      "layers.7.attention.heads.11.q.bias: False\n",
      "layers.7.attention.heads.11.k.weight: False\n",
      "layers.7.attention.heads.11.k.bias: False\n",
      "layers.7.attention.heads.11.v.weight: False\n",
      "layers.7.attention.heads.11.v.bias: False\n",
      "layers.7.attention.out_linear.weight: False\n",
      "layers.7.attention.out_linear.bias: False\n",
      "layers.7.feed_forward.linear1.weight: False\n",
      "layers.7.feed_forward.linear1.bias: False\n",
      "layers.7.feed_forward.linear2.weight: False\n",
      "layers.7.feed_forward.linear2.bias: False\n",
      "layers.8.norm1.weight: False\n",
      "layers.8.norm1.bias: False\n",
      "layers.8.norm2.weight: False\n",
      "layers.8.norm2.bias: False\n",
      "layers.8.attention.heads.0.q.weight: False\n",
      "layers.8.attention.heads.0.q.bias: False\n",
      "layers.8.attention.heads.0.k.weight: False\n",
      "layers.8.attention.heads.0.k.bias: False\n",
      "layers.8.attention.heads.0.v.weight: False\n",
      "layers.8.attention.heads.0.v.bias: False\n",
      "layers.8.attention.heads.1.q.weight: False\n",
      "layers.8.attention.heads.1.q.bias: False\n",
      "layers.8.attention.heads.1.k.weight: False\n",
      "layers.8.attention.heads.1.k.bias: False\n",
      "layers.8.attention.heads.1.v.weight: False\n",
      "layers.8.attention.heads.1.v.bias: False\n",
      "layers.8.attention.heads.2.q.weight: False\n",
      "layers.8.attention.heads.2.q.bias: False\n",
      "layers.8.attention.heads.2.k.weight: False\n",
      "layers.8.attention.heads.2.k.bias: False\n",
      "layers.8.attention.heads.2.v.weight: False\n",
      "layers.8.attention.heads.2.v.bias: False\n",
      "layers.8.attention.heads.3.q.weight: False\n",
      "layers.8.attention.heads.3.q.bias: False\n",
      "layers.8.attention.heads.3.k.weight: False\n",
      "layers.8.attention.heads.3.k.bias: False\n",
      "layers.8.attention.heads.3.v.weight: False\n",
      "layers.8.attention.heads.3.v.bias: False\n",
      "layers.8.attention.heads.4.q.weight: False\n",
      "layers.8.attention.heads.4.q.bias: False\n",
      "layers.8.attention.heads.4.k.weight: False\n",
      "layers.8.attention.heads.4.k.bias: False\n",
      "layers.8.attention.heads.4.v.weight: False\n",
      "layers.8.attention.heads.4.v.bias: False\n",
      "layers.8.attention.heads.5.q.weight: False\n",
      "layers.8.attention.heads.5.q.bias: False\n",
      "layers.8.attention.heads.5.k.weight: False\n",
      "layers.8.attention.heads.5.k.bias: False\n",
      "layers.8.attention.heads.5.v.weight: False\n",
      "layers.8.attention.heads.5.v.bias: False\n",
      "layers.8.attention.heads.6.q.weight: False\n",
      "layers.8.attention.heads.6.q.bias: False\n",
      "layers.8.attention.heads.6.k.weight: False\n",
      "layers.8.attention.heads.6.k.bias: False\n",
      "layers.8.attention.heads.6.v.weight: False\n",
      "layers.8.attention.heads.6.v.bias: False\n",
      "layers.8.attention.heads.7.q.weight: False\n",
      "layers.8.attention.heads.7.q.bias: False\n",
      "layers.8.attention.heads.7.k.weight: False\n",
      "layers.8.attention.heads.7.k.bias: False\n",
      "layers.8.attention.heads.7.v.weight: False\n",
      "layers.8.attention.heads.7.v.bias: False\n",
      "layers.8.attention.heads.8.q.weight: False\n",
      "layers.8.attention.heads.8.q.bias: False\n",
      "layers.8.attention.heads.8.k.weight: False\n",
      "layers.8.attention.heads.8.k.bias: False\n",
      "layers.8.attention.heads.8.v.weight: False\n",
      "layers.8.attention.heads.8.v.bias: False\n",
      "layers.8.attention.heads.9.q.weight: False\n",
      "layers.8.attention.heads.9.q.bias: False\n",
      "layers.8.attention.heads.9.k.weight: False\n",
      "layers.8.attention.heads.9.k.bias: False\n",
      "layers.8.attention.heads.9.v.weight: False\n",
      "layers.8.attention.heads.9.v.bias: False\n",
      "layers.8.attention.heads.10.q.weight: False\n",
      "layers.8.attention.heads.10.q.bias: False\n",
      "layers.8.attention.heads.10.k.weight: False\n",
      "layers.8.attention.heads.10.k.bias: False\n",
      "layers.8.attention.heads.10.v.weight: False\n",
      "layers.8.attention.heads.10.v.bias: False\n",
      "layers.8.attention.heads.11.q.weight: False\n",
      "layers.8.attention.heads.11.q.bias: False\n",
      "layers.8.attention.heads.11.k.weight: False\n",
      "layers.8.attention.heads.11.k.bias: False\n",
      "layers.8.attention.heads.11.v.weight: False\n",
      "layers.8.attention.heads.11.v.bias: False\n",
      "layers.8.attention.out_linear.weight: False\n",
      "layers.8.attention.out_linear.bias: False\n",
      "layers.8.feed_forward.linear1.weight: False\n",
      "layers.8.feed_forward.linear1.bias: False\n",
      "layers.8.feed_forward.linear2.weight: False\n",
      "layers.8.feed_forward.linear2.bias: False\n",
      "layers.9.norm1.weight: False\n",
      "layers.9.norm1.bias: False\n",
      "layers.9.norm2.weight: False\n",
      "layers.9.norm2.bias: False\n",
      "layers.9.attention.heads.0.q.weight: False\n",
      "layers.9.attention.heads.0.q.bias: False\n",
      "layers.9.attention.heads.0.k.weight: False\n",
      "layers.9.attention.heads.0.k.bias: False\n",
      "layers.9.attention.heads.0.v.weight: False\n",
      "layers.9.attention.heads.0.v.bias: False\n",
      "layers.9.attention.heads.1.q.weight: False\n",
      "layers.9.attention.heads.1.q.bias: False\n",
      "layers.9.attention.heads.1.k.weight: False\n",
      "layers.9.attention.heads.1.k.bias: False\n",
      "layers.9.attention.heads.1.v.weight: False\n",
      "layers.9.attention.heads.1.v.bias: False\n",
      "layers.9.attention.heads.2.q.weight: False\n",
      "layers.9.attention.heads.2.q.bias: False\n",
      "layers.9.attention.heads.2.k.weight: False\n",
      "layers.9.attention.heads.2.k.bias: False\n",
      "layers.9.attention.heads.2.v.weight: False\n",
      "layers.9.attention.heads.2.v.bias: False\n",
      "layers.9.attention.heads.3.q.weight: False\n",
      "layers.9.attention.heads.3.q.bias: False\n",
      "layers.9.attention.heads.3.k.weight: False\n",
      "layers.9.attention.heads.3.k.bias: False\n",
      "layers.9.attention.heads.3.v.weight: False\n",
      "layers.9.attention.heads.3.v.bias: False\n",
      "layers.9.attention.heads.4.q.weight: False\n",
      "layers.9.attention.heads.4.q.bias: False\n",
      "layers.9.attention.heads.4.k.weight: False\n",
      "layers.9.attention.heads.4.k.bias: False\n",
      "layers.9.attention.heads.4.v.weight: False\n",
      "layers.9.attention.heads.4.v.bias: False\n",
      "layers.9.attention.heads.5.q.weight: False\n",
      "layers.9.attention.heads.5.q.bias: False\n",
      "layers.9.attention.heads.5.k.weight: False\n",
      "layers.9.attention.heads.5.k.bias: False\n",
      "layers.9.attention.heads.5.v.weight: False\n",
      "layers.9.attention.heads.5.v.bias: False\n",
      "layers.9.attention.heads.6.q.weight: False\n",
      "layers.9.attention.heads.6.q.bias: False\n",
      "layers.9.attention.heads.6.k.weight: False\n",
      "layers.9.attention.heads.6.k.bias: False\n",
      "layers.9.attention.heads.6.v.weight: False\n",
      "layers.9.attention.heads.6.v.bias: False\n",
      "layers.9.attention.heads.7.q.weight: False\n",
      "layers.9.attention.heads.7.q.bias: False\n",
      "layers.9.attention.heads.7.k.weight: False\n",
      "layers.9.attention.heads.7.k.bias: False\n",
      "layers.9.attention.heads.7.v.weight: False\n",
      "layers.9.attention.heads.7.v.bias: False\n",
      "layers.9.attention.heads.8.q.weight: False\n",
      "layers.9.attention.heads.8.q.bias: False\n",
      "layers.9.attention.heads.8.k.weight: False\n",
      "layers.9.attention.heads.8.k.bias: False\n",
      "layers.9.attention.heads.8.v.weight: False\n",
      "layers.9.attention.heads.8.v.bias: False\n",
      "layers.9.attention.heads.9.q.weight: False\n",
      "layers.9.attention.heads.9.q.bias: False\n",
      "layers.9.attention.heads.9.k.weight: False\n",
      "layers.9.attention.heads.9.k.bias: False\n",
      "layers.9.attention.heads.9.v.weight: False\n",
      "layers.9.attention.heads.9.v.bias: False\n",
      "layers.9.attention.heads.10.q.weight: False\n",
      "layers.9.attention.heads.10.q.bias: False\n",
      "layers.9.attention.heads.10.k.weight: False\n",
      "layers.9.attention.heads.10.k.bias: False\n",
      "layers.9.attention.heads.10.v.weight: False\n",
      "layers.9.attention.heads.10.v.bias: False\n",
      "layers.9.attention.heads.11.q.weight: False\n",
      "layers.9.attention.heads.11.q.bias: False\n",
      "layers.9.attention.heads.11.k.weight: False\n",
      "layers.9.attention.heads.11.k.bias: False\n",
      "layers.9.attention.heads.11.v.weight: False\n",
      "layers.9.attention.heads.11.v.bias: False\n",
      "layers.9.attention.out_linear.weight: False\n",
      "layers.9.attention.out_linear.bias: False\n",
      "layers.9.feed_forward.linear1.weight: False\n",
      "layers.9.feed_forward.linear1.bias: False\n",
      "layers.9.feed_forward.linear2.weight: False\n",
      "layers.9.feed_forward.linear2.bias: False\n",
      "layers.10.norm1.weight: False\n",
      "layers.10.norm1.bias: False\n",
      "layers.10.norm2.weight: False\n",
      "layers.10.norm2.bias: False\n",
      "layers.10.attention.heads.0.q.weight: False\n",
      "layers.10.attention.heads.0.q.bias: False\n",
      "layers.10.attention.heads.0.k.weight: False\n",
      "layers.10.attention.heads.0.k.bias: False\n",
      "layers.10.attention.heads.0.v.weight: False\n",
      "layers.10.attention.heads.0.v.bias: False\n",
      "layers.10.attention.heads.1.q.weight: False\n",
      "layers.10.attention.heads.1.q.bias: False\n",
      "layers.10.attention.heads.1.k.weight: False\n",
      "layers.10.attention.heads.1.k.bias: False\n",
      "layers.10.attention.heads.1.v.weight: False\n",
      "layers.10.attention.heads.1.v.bias: False\n",
      "layers.10.attention.heads.2.q.weight: False\n",
      "layers.10.attention.heads.2.q.bias: False\n",
      "layers.10.attention.heads.2.k.weight: False\n",
      "layers.10.attention.heads.2.k.bias: False\n",
      "layers.10.attention.heads.2.v.weight: False\n",
      "layers.10.attention.heads.2.v.bias: False\n",
      "layers.10.attention.heads.3.q.weight: False\n",
      "layers.10.attention.heads.3.q.bias: False\n",
      "layers.10.attention.heads.3.k.weight: False\n",
      "layers.10.attention.heads.3.k.bias: False\n",
      "layers.10.attention.heads.3.v.weight: False\n",
      "layers.10.attention.heads.3.v.bias: False\n",
      "layers.10.attention.heads.4.q.weight: False\n",
      "layers.10.attention.heads.4.q.bias: False\n",
      "layers.10.attention.heads.4.k.weight: False\n",
      "layers.10.attention.heads.4.k.bias: False\n",
      "layers.10.attention.heads.4.v.weight: False\n",
      "layers.10.attention.heads.4.v.bias: False\n",
      "layers.10.attention.heads.5.q.weight: False\n",
      "layers.10.attention.heads.5.q.bias: False\n",
      "layers.10.attention.heads.5.k.weight: False\n",
      "layers.10.attention.heads.5.k.bias: False\n",
      "layers.10.attention.heads.5.v.weight: False\n",
      "layers.10.attention.heads.5.v.bias: False\n",
      "layers.10.attention.heads.6.q.weight: False\n",
      "layers.10.attention.heads.6.q.bias: False\n",
      "layers.10.attention.heads.6.k.weight: False\n",
      "layers.10.attention.heads.6.k.bias: False\n",
      "layers.10.attention.heads.6.v.weight: False\n",
      "layers.10.attention.heads.6.v.bias: False\n",
      "layers.10.attention.heads.7.q.weight: False\n",
      "layers.10.attention.heads.7.q.bias: False\n",
      "layers.10.attention.heads.7.k.weight: False\n",
      "layers.10.attention.heads.7.k.bias: False\n",
      "layers.10.attention.heads.7.v.weight: False\n",
      "layers.10.attention.heads.7.v.bias: False\n",
      "layers.10.attention.heads.8.q.weight: False\n",
      "layers.10.attention.heads.8.q.bias: False\n",
      "layers.10.attention.heads.8.k.weight: False\n",
      "layers.10.attention.heads.8.k.bias: False\n",
      "layers.10.attention.heads.8.v.weight: False\n",
      "layers.10.attention.heads.8.v.bias: False\n",
      "layers.10.attention.heads.9.q.weight: False\n",
      "layers.10.attention.heads.9.q.bias: False\n",
      "layers.10.attention.heads.9.k.weight: False\n",
      "layers.10.attention.heads.9.k.bias: False\n",
      "layers.10.attention.heads.9.v.weight: False\n",
      "layers.10.attention.heads.9.v.bias: False\n",
      "layers.10.attention.heads.10.q.weight: False\n",
      "layers.10.attention.heads.10.q.bias: False\n",
      "layers.10.attention.heads.10.k.weight: False\n",
      "layers.10.attention.heads.10.k.bias: False\n",
      "layers.10.attention.heads.10.v.weight: False\n",
      "layers.10.attention.heads.10.v.bias: False\n",
      "layers.10.attention.heads.11.q.weight: False\n",
      "layers.10.attention.heads.11.q.bias: False\n",
      "layers.10.attention.heads.11.k.weight: False\n",
      "layers.10.attention.heads.11.k.bias: False\n",
      "layers.10.attention.heads.11.v.weight: False\n",
      "layers.10.attention.heads.11.v.bias: False\n",
      "layers.10.attention.out_linear.weight: False\n",
      "layers.10.attention.out_linear.bias: False\n",
      "layers.10.feed_forward.linear1.weight: False\n",
      "layers.10.feed_forward.linear1.bias: False\n",
      "layers.10.feed_forward.linear2.weight: False\n",
      "layers.10.feed_forward.linear2.bias: False\n",
      "layers.11.norm1.weight: False\n",
      "layers.11.norm1.bias: False\n",
      "layers.11.norm2.weight: False\n",
      "layers.11.norm2.bias: False\n",
      "layers.11.attention.heads.0.q.weight: False\n",
      "layers.11.attention.heads.0.q.bias: False\n",
      "layers.11.attention.heads.0.k.weight: False\n",
      "layers.11.attention.heads.0.k.bias: False\n",
      "layers.11.attention.heads.0.v.weight: False\n",
      "layers.11.attention.heads.0.v.bias: False\n",
      "layers.11.attention.heads.1.q.weight: False\n",
      "layers.11.attention.heads.1.q.bias: False\n",
      "layers.11.attention.heads.1.k.weight: False\n",
      "layers.11.attention.heads.1.k.bias: False\n",
      "layers.11.attention.heads.1.v.weight: False\n",
      "layers.11.attention.heads.1.v.bias: False\n",
      "layers.11.attention.heads.2.q.weight: False\n",
      "layers.11.attention.heads.2.q.bias: False\n",
      "layers.11.attention.heads.2.k.weight: False\n",
      "layers.11.attention.heads.2.k.bias: False\n",
      "layers.11.attention.heads.2.v.weight: False\n",
      "layers.11.attention.heads.2.v.bias: False\n",
      "layers.11.attention.heads.3.q.weight: False\n",
      "layers.11.attention.heads.3.q.bias: False\n",
      "layers.11.attention.heads.3.k.weight: False\n",
      "layers.11.attention.heads.3.k.bias: False\n",
      "layers.11.attention.heads.3.v.weight: False\n",
      "layers.11.attention.heads.3.v.bias: False\n",
      "layers.11.attention.heads.4.q.weight: False\n",
      "layers.11.attention.heads.4.q.bias: False\n",
      "layers.11.attention.heads.4.k.weight: False\n",
      "layers.11.attention.heads.4.k.bias: False\n",
      "layers.11.attention.heads.4.v.weight: False\n",
      "layers.11.attention.heads.4.v.bias: False\n",
      "layers.11.attention.heads.5.q.weight: False\n",
      "layers.11.attention.heads.5.q.bias: False\n",
      "layers.11.attention.heads.5.k.weight: False\n",
      "layers.11.attention.heads.5.k.bias: False\n",
      "layers.11.attention.heads.5.v.weight: False\n",
      "layers.11.attention.heads.5.v.bias: False\n",
      "layers.11.attention.heads.6.q.weight: False\n",
      "layers.11.attention.heads.6.q.bias: False\n",
      "layers.11.attention.heads.6.k.weight: False\n",
      "layers.11.attention.heads.6.k.bias: False\n",
      "layers.11.attention.heads.6.v.weight: False\n",
      "layers.11.attention.heads.6.v.bias: False\n",
      "layers.11.attention.heads.7.q.weight: False\n",
      "layers.11.attention.heads.7.q.bias: False\n",
      "layers.11.attention.heads.7.k.weight: False\n",
      "layers.11.attention.heads.7.k.bias: False\n",
      "layers.11.attention.heads.7.v.weight: False\n",
      "layers.11.attention.heads.7.v.bias: False\n",
      "layers.11.attention.heads.8.q.weight: False\n",
      "layers.11.attention.heads.8.q.bias: False\n",
      "layers.11.attention.heads.8.k.weight: False\n",
      "layers.11.attention.heads.8.k.bias: False\n",
      "layers.11.attention.heads.8.v.weight: False\n",
      "layers.11.attention.heads.8.v.bias: False\n",
      "layers.11.attention.heads.9.q.weight: False\n",
      "layers.11.attention.heads.9.q.bias: False\n",
      "layers.11.attention.heads.9.k.weight: False\n",
      "layers.11.attention.heads.9.k.bias: False\n",
      "layers.11.attention.heads.9.v.weight: False\n",
      "layers.11.attention.heads.9.v.bias: False\n",
      "layers.11.attention.heads.10.q.weight: False\n",
      "layers.11.attention.heads.10.q.bias: False\n",
      "layers.11.attention.heads.10.k.weight: False\n",
      "layers.11.attention.heads.10.k.bias: False\n",
      "layers.11.attention.heads.10.v.weight: False\n",
      "layers.11.attention.heads.10.v.bias: False\n",
      "layers.11.attention.heads.11.q.weight: False\n",
      "layers.11.attention.heads.11.q.bias: False\n",
      "layers.11.attention.heads.11.k.weight: False\n",
      "layers.11.attention.heads.11.k.bias: False\n",
      "layers.11.attention.heads.11.v.weight: False\n",
      "layers.11.attention.heads.11.v.bias: False\n",
      "layers.11.attention.out_linear.weight: False\n",
      "layers.11.attention.out_linear.bias: False\n",
      "layers.11.feed_forward.linear1.weight: False\n",
      "layers.11.feed_forward.linear1.bias: False\n",
      "layers.11.feed_forward.linear2.weight: False\n",
      "layers.11.feed_forward.linear2.bias: False\n"
     ]
    }
   ],
   "source": [
    "# Now, check if the parameters are frozen\n",
    "for name, param in encoder.named_parameters():\n",
    "    print(f'{name}: {param.requires_grad}')\n",
    "\n",
    "# Use the encoder for inference\n",
    "encoder_output = encoder(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "50cb84d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:08.986890Z",
     "iopub.status.busy": "2023-11-07T12:12:08.985912Z",
     "iopub.status.idle": "2023-11-07T12:12:08.991281Z",
     "shell.execute_reply": "2023-11-07T12:12:08.990709Z"
    },
    "papermill": {
     "duration": 0.024749,
     "end_time": "2023-11-07T12:12:08.992754",
     "exception": false,
     "start_time": "2023-11-07T12:12:08.968005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# hidden state for each token in a batch\n",
    "encoder_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7c9c2b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6423]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4161345",
   "metadata": {
    "papermill": {
     "duration": 0.016716,
     "end_time": "2023-11-07T12:12:09.026352",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.009636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#F1A424\"><b><span style='color:#FFFFFF'>8 |</span></b> <b>CLASSIFICATION HEAD</b></div>\n",
    "\n",
    "Quite often, transformers are divided into:\n",
    "- Task independent body (`TransformerEncoder`)\n",
    "- Task dependent head (`TransformerClassifier`)\n",
    "\n",
    "Select one of the token outputs:\n",
    "- The first token in such models is often used for the prediction **[CLS] token**\n",
    "- Can attach a `dropout` and a `linear` transformation layer to make a classification prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50466a72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:09.063655Z",
     "iopub.status.busy": "2023-11-07T12:12:09.063083Z",
     "iopub.status.idle": "2023-11-07T12:12:09.068612Z",
     "shell.execute_reply": "2023-11-07T12:12:09.068049Z"
    },
    "papermill": {
     "duration": 0.025845,
     "end_time": "2023-11-07T12:12:09.070128",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.044283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        \n",
    "        # Classification Head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[:, 0, :] # select hidden state of [CLS] token\n",
    "        print(x.size())\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x) # 768 -> 3 \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a5f09",
   "metadata": {
    "papermill": {
     "duration": 0.016599,
     "end_time": "2023-11-07T12:12:09.103550",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.086951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- For each sample in the batch we get the **unnormalized logits** for each class in the output, which corresponds to the BERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "74c29271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T12:12:09.138526Z",
     "iopub.status.busy": "2023-11-07T12:12:09.138069Z",
     "iopub.status.idle": "2023-11-07T12:12:10.191689Z",
     "shell.execute_reply": "2023-11-07T12:12:10.191034Z"
    },
    "papermill": {
     "duration": 1.073469,
     "end_time": "2023-11-07T12:12:10.193779",
     "exception": false,
     "start_time": "2023-11-07T12:12:09.120310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3187]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.num_labels = 1\n",
    "encoder_classifier = TransformerClassifier(config)\n",
    "output = encoder_classifier(inputs.input_ids)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f5e54b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1996, 11286,  1997,  1037,  5340,  3392,  2003,  2200,  5931]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82af357d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7248, -1.0299, -0.2984, -0.8205,  1.5645]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78cfec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6423, 2003, 3835],\n",
      "        [6423, 2003, 2785],\n",
      "        [6423, 2003, 2812],\n",
      "        [6423, 2003, 3407]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenise input (text)\n",
    "inputs = tokenizer([\"julia is nice\",\"julia is kind\",\"julia is mean\",\"julia is happy\"], \n",
    "                   return_tensors=\"pt\",      # pytorc tensor\n",
    "                   add_special_tokens=False) # don't use pad, sep tokens\n",
    "\n",
    "print(inputs.input_ids)\n",
    "inputs.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b60fc987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2858,  2.2910,  1.1027, -1.3655,  0.5057],\n",
       "        [-0.4398,  1.7071, -0.3332, -1.3267,  0.0404],\n",
       "        [ 1.2801, -0.3843, -0.8903,  0.2645,  0.0164],\n",
       "        [ 0.7872,  0.4755, -0.2488,  0.9355,  0.0259]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.num_labels = 5\n",
    "encoder_classifier = TransformerClassifier(config)\n",
    "output = encoder_classifier(inputs.input_ids)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0c8481d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2858461 ,  2.291011  ,  1.1027378 , -1.3654897 ,  0.50570506],\n",
       "       [-0.43984768,  1.707121  , -0.33323628, -1.3266757 ,  0.0403869 ],\n",
       "       [ 1.2801098 , -0.38431922, -0.89034826,  0.26452443,  0.01639184],\n",
       "       [ 0.787185  ,  0.47547337, -0.2487884 ,  0.93552494,  0.02594745]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "11ede128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.30067572, -0.19365877,  1.5731525 ,  0.34049684,  0.61987585],\n",
       "       [ 1.599041  ,  0.65223604, -0.30029094, -0.67572856,  1.787407  ],\n",
       "       [ 1.168354  ,  0.27019048,  0.68573517, -0.11251289,  0.5283011 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(x, \n",
    "                   return_tensors=\"pt\",      # pytorc tensor\n",
    "                   add_special_tokens=False,\n",
    "                  padding=True ) # don't use pad, sep tokens\n",
    "                    \n",
    "output = encoder_classifier(inputs.input_ids)\n",
    "output.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d8f51137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.1925466 , -2.004026  ,  0.37853348, -0.53329134,  3.518763  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encoder(x):\n",
    "    inputs = x\n",
    "    inputs = tokenizer(inputs, \n",
    "                   return_tensors=\"pt\",      # pytorc tensor\n",
    "                   add_special_tokens=False,\n",
    "                      ) # don't use pad, sep tokens\n",
    "    output = encoder_classifier(inputs.input_ids)\n",
    "    output = output.detach().numpy()\n",
    "    return output\n",
    "encoder([\"julia\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "78f8a7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.4516523 , -0.29492986, -1.4100991 , -0.5428195 ,  1.6403229 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder([\"julia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f6e1c602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "[[ 1.8389405  -1.0258632  -1.9472094   0.24997222  2.9709525 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.2937596  -0.55749947 -1.5676594  -0.10609275  2.590736  ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.7001611  -0.7492791  -1.4172636   0.41050863  1.5200357 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.38916868 -2.6472218  -1.4488543   0.6265552   2.8951118 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.47231916 -0.53634554 -0.5050098  -0.97858167  2.0714037 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.1571622  -0.14157459 -0.44913638  0.04301509  2.4572744 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.1925933  -2.0172298  -0.03272817  0.05695865  4.1540723 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.26143798 -0.39048213 -0.5843675  -0.12257874  1.6031576 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.00853661 -1.8508751  -0.90174556  0.15717727  0.42443526]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.10971469 -0.96365035 -1.2132721   0.33689216  0.30131382]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.90288585 -1.5594695  -0.31239155  0.93199253  0.9063376 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.575763   -1.474622   -0.01893973 -1.6097691   1.625571  ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.2535087  -0.69128287 -1.3176934   0.89493334  2.8466616 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.83197725  0.6289131  -0.68537045  0.7565023   0.5172089 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.0083814  -0.34590343  0.36498713 -0.28030363  1.0539081 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.8730753 -0.437684  -1.0078217  0.6640351  1.1810595]]\n",
      "torch.Size([1, 768])\n",
      "[[ 2.5567908  -0.6370684  -0.46333343  0.81403226  3.3931787 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.08064005 -0.54463744 -0.7790845   1.1092944   3.923053  ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.61899036 -1.3680719  -1.1154611   0.6824911   0.77538145]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.33561593 -2.0343149  -1.524899    1.6989415   2.596325  ]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.2722288  -0.3572669  -0.9616324   0.10787922  3.452022  ]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.4053358  -0.39284718 -0.38204122 -0.5995668   1.8725339 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.51498365 -1.5810821  -2.2393973   0.70850456  0.48347938]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.59225935 -0.39468363 -0.00732887  0.4983155   1.4752239 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.03592961 -1.4822865  -1.620661    0.117576    1.4544673 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.5614438   0.38075566 -1.739773   -0.3653347   1.0539811 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-2.1210542   0.8818643   1.1112943   0.48594812  1.6453836 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.32551077 -0.50986385 -0.502342   -0.04689592  3.6750865 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.13877499 -0.15563437 -0.18800986  0.5182731  -0.6704424 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.11773807 -0.16428983 -2.3842516   0.6039371   1.92588   ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 2.1425457  -0.11512989 -1.0949836   0.75699246  1.7416682 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.3208417  -1.5464118   0.62125015 -0.29034024  2.550439  ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.60144365 -0.6072734  -1.378515    1.053808   -0.98943233]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.32254073  0.38350117 -0.18454117  0.03002122  1.4879704 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.09191891 -1.0092053  -1.630301   -0.3063442   2.4158995 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.4171348 -1.353207  -1.0982419  1.6467578  1.3735278]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.48716962 -0.32202932 -2.1942446   0.55379605  0.7841842 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.2397477   0.22638905 -0.30939156  0.835444    2.2260337 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.4308114   0.17134306 -0.5939125  -0.0462442   1.8684789 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.626323    0.06796354 -0.68810093  1.3190384   2.118757  ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.6390155  -2.112834   -0.5299003  -0.05023673  0.7252248 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.25856912 -0.7226182  -2.2387235  -0.23198855  1.1656077 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.274028  -1.7574086  0.096921   1.8841717  2.709712 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.36222175 -1.3736453  -0.40836054  0.15382233  1.7772515 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.23381081 -0.23392355 -1.9281043   0.39893186  3.5724769 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.4431894   0.72074956 -0.5359353  -1.6675327   2.0148437 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.2262979  -0.8515811   0.67380524  0.29503873  2.5982652 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.8360472  -0.18120378 -0.69020474 -1.4587284   1.9068171 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.04131383  0.11164767 -0.8080493  -0.52783376 -2.3015463 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.39576072 -1.1639065  -1.4804735  -0.12025744  2.436457  ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.4484625 -2.0538921 -1.6958259  0.9933771  2.2242017]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.4160248  -1.3930333  -0.18942246  0.623612    0.08719949]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.43605617 -2.2344255  -0.39197445  0.44472963  1.8808546 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.89805245  0.22225529 -0.6375909  -0.6696243   2.0862026 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.1713114   0.7319886  -0.40045345  1.1540313   2.8416429 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.32465222  0.48543108 -0.9959302   1.2915214   3.5112507 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.99878085 -0.8349626  -0.92004585  1.3523242   3.560196  ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.52633226 -0.99074924 -0.960544    0.9033803   1.8321087 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.23120403  0.7676372  -1.2836509  -0.22950771  1.865881  ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.8924391 -0.7007999 -0.571493   1.5513531  3.5236638]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.6974694  -0.08364642 -1.7986574   1.113228    1.8901657 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.5756172  -0.14693576 -1.1404445  -0.5029555   0.75923127]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.4092139 -0.3651498 -2.7156615 -1.0569198  2.508409 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.3930943  -0.3135575  -0.8457608  -0.46265143  2.0891001 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.298455  -1.0888726 -1.8916965 -0.802361   2.314303 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.5716372  -0.59711695 -0.64246696  1.3168776   1.0320425 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.22180796 -0.18839769 -0.36290097 -0.2057769   2.7437599 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.5611175  -1.6015449  -0.7997215  -0.37230211  1.248783  ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.25713152 -1.0948389  -0.3544342   1.1701956   3.397933  ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.9160604 -0.7798491 -1.5856413  0.0536595  3.0639994]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.7685388 -1.099858  -1.1542227  0.4794194  2.1750016]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.51072925 -1.1783179  -1.5086462   2.6846726   2.0703006 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.9705226 -1.7047067 -1.7506663 -1.1098412  1.771829 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.68977666 -1.3588881  -0.62999654 -0.1804983   2.2404003 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.5550665  -0.90361416 -1.3780769   0.12957186  1.5978682 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.45881492 -0.8827839  -1.7530721  -0.72764385  1.6451476 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.1524477  -1.0928568  -0.8808977   0.6768347  -0.42297417]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.3111907  -0.37980264 -0.7307807  -0.75210446  2.6713438 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.08552271 -0.7862924  -0.40623942 -0.021007   -0.02159745]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.7102864   0.36682367 -1.1829648  -0.56853473  1.9983189 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.4110166  -0.40803856 -1.9191628  -0.15314221  2.015008  ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.25014094  0.5698333   0.71770227 -0.07571691  0.99761754]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.3229557  -0.41547495 -2.289988   -0.5374194   3.8663256 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.67896247  0.26633394 -0.44540396  1.362362    1.1451045 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.58874834 -1.4151895  -2.155796    0.230243    1.3187569 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.4467368   0.18704404  0.8273399  -0.7809509   2.2522595 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.614736   -0.8856894   1.2427907   0.08576655  0.40143383]]\n",
      "torch.Size([1, 768])\n",
      "[[-1.1888365  -0.6517862  -1.6726769  -0.1863113   0.11790869]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.9329157 -1.4354485 -1.3888346 -1.454856   2.7464812]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.21539357  0.19353107 -0.3561064  -0.67020607  2.3526652 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.3208334 -0.772766  -0.3280922 -0.8530589  2.1623845]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.8257766  -2.7141287  -1.769961   -0.61564994  0.90081394]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.45673493 -0.5919855  -0.47654578 -0.3692783   3.2641232 ]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.0165489  -0.5201651  -2.5520673  -0.14356697  0.99685526]]\n",
      "torch.Size([1, 768])\n",
      "[[-0.06110967 -2.463143   -0.8752372   1.514087    1.1939648 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.298265   -2.6253521  -0.41841543  1.9849263   3.3019104 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.18694386 -2.2086885  -0.4890774   0.53339815  1.7385726 ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.1013749 -1.6154352 -2.458239  -0.8619126  2.6202486]]\n",
      "torch.Size([1, 768])\n",
      "[[ 0.95002925  1.3246802  -2.005942   -0.52968824  0.12671   ]]\n",
      "torch.Size([1, 768])\n",
      "[[ 1.1053149  -0.22370335  0.4003247  -0.65588975  2.293155  ]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(encoder([\"julia\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e89c6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "class Embeddings:\n",
    "    #CLS is a special classification token and the last hidden state of BERT Embedding\n",
    "    def cls_pooling(self, model_output):\n",
    "        return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "    #BERT tokenizer of input text\n",
    "    def get_embeddings(self, text_list):\n",
    "        encoded_input = tokenizer(\n",
    "            text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        model_output = model(**encoded_input)\n",
    "        return self.cls_pooling(model_output).cpu().detach().numpy()\n",
    "    \n",
    "    \n",
    "    #convert dataset into embeddings dataset to run FAISS\n",
    "    def makeEmbeddings(self,dataset):\n",
    "        embeddings = []\n",
    "        for data in dataset:\n",
    "            embeddings.append(self.get_embeddings(data)[0])\n",
    "        return np.array(embeddings)\n",
    "    \n",
    "    def getQueryEmbedding(self, query):\n",
    "        return self.get_embeddings([query])\n",
    "    \n",
    "class Faiss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def faiss(self,xb):\n",
    "        d = xb[0].size\n",
    "        M = 32\n",
    "        index = faiss.IndexHNSWFlat(d, M)            \n",
    "        index.hnsw.efConstruction = 40         # Setting the value for efConstruction.\n",
    "        index.hnsw.efSearch = 16               # Setting the value for efSearch.\n",
    "        index.add(xb)\n",
    "        return index\n",
    "    \n",
    "    def query(self,index,xq,k=3):\n",
    "        D, I = index.search(xq, k)   \n",
    "        return D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "57189376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = encoder([\"julia is nice\", \"isabelle is planning\", \"julia plans too\"])\n",
    "xq = encoder([\"isabelle plans it\"])\n",
    "index = Faiss().faiss(xb)\n",
    "D,I = Faiss().query(index,xq)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a7b59a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"SEC-CompanyTicker.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9ab44d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  9, 17],\n",
       "       [ 1, 10,  6],\n",
       "       [ 2,  7,  8],\n",
       "       [ 3, 13, 10],\n",
       "       [ 4,  6,  0],\n",
       "       [ 5,  0,  9],\n",
       "       [ 6,  1,  4],\n",
       "       [ 7,  2,  8],\n",
       "       [ 8,  7,  0],\n",
       "       [ 9, 17,  0],\n",
       "       [10,  1,  3],\n",
       "       [11, 15,  6],\n",
       "       [12,  1,  9],\n",
       "       [13,  3, 10],\n",
       "       [14, 16, 17],\n",
       "       [15, 10, 11],\n",
       "       [16, 14, 17],\n",
       "       [17,  9,  0],\n",
       "       [18,  4,  2],\n",
       "       [19,  7,  3]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(df.head(20).companyName)\n",
    "q = [\"Apple Inc.\"]\n",
    "xb,xq = encoder(x,q)\n",
    "index = Faiss().faiss(xb)\n",
    "D,I = Faiss().query(index,xb)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c70c56e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple Inc.',\n",
       " 'Microsoft Corp',\n",
       " 'Alphabet Inc.',\n",
       " 'Amazon Com Inc',\n",
       " 'Nvidia Corp',\n",
       " 'Tesla, Inc.',\n",
       " 'Berkshire Hathaway Inc',\n",
       " 'Meta Platforms, Inc.',\n",
       " 'Eli Lilly & Co',\n",
       " 'Visa Inc.',\n",
       " 'Taiwan Semiconductor Manufacturing Co Ltd',\n",
       " 'Exxon Mobil Corp',\n",
       " 'Unitedhealth Group Inc',\n",
       " 'Walmart Inc.',\n",
       " 'Novo Nordisk A S',\n",
       " 'Jpmorgan Chase & Co',\n",
       " 'Spdr S&P 500 Etf Trust',\n",
       " 'Johnson & Johnson',\n",
       " 'Mastercard Inc',\n",
       " 'Lvmh Moet Hennessy Louis Vuitton']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "71a22b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.6796455 , -0.26035303,  0.939491  , -0.8765463 ,  1.2847595 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"am\"\n",
    "encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2485038c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.261257,
   "end_time": "2023-11-07T12:12:13.753168",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-07T12:11:25.491911",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f54ff68288a47e4ab08fe1bbfc33d55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_23e2a9ed016a4afcbce85d623df9d64e",
       "max": 28,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fa9b11bb2bba4257a632795bfe9f9b6e",
       "value": 28
      }
     },
     "0f6539d2bc1244888a6850ce92c31d4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ac3fe35df01454abc6b7a3bfdf4df94",
        "IPY_MODEL_dcad6910ef2b43e7a8001ab17ab10112",
        "IPY_MODEL_57bbb2ada9f0494aa4335a1418e1809e"
       ],
       "layout": "IPY_MODEL_79f1527694f74b80a5330cf6f99ea84e"
      }
     },
     "0fb39f643b2f4811be0d0c3409323d80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "17348793a7bb456bbb5ace7f13f537f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_98d3a93be64a4c01a2d1c98d00515f5a",
       "placeholder": "​",
       "style": "IPY_MODEL_4698dfa31864465ab5841f5b2d8c6e5c",
       "value": " 570/570 [00:00&lt;00:00, 25.3kB/s]"
      }
     },
     "1ac3fe35df01454abc6b7a3bfdf4df94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f5a281ae964e44528a7773b0213cb3a9",
       "placeholder": "​",
       "style": "IPY_MODEL_4c762ca4426949989ec3bf96ef853188",
       "value": "Downloading: 100%"
      }
     },
     "23e2a9ed016a4afcbce85d623df9d64e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c55c0d364b742ed8da1f4194e9d73db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ecc0ca0282a4b51a9f47f299ddb0e25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "402bec0969c2439d9fe12534438cfd18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4698dfa31864465ab5841f5b2d8c6e5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c762ca4426949989ec3bf96ef853188": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "508357fee53643ae9bbc41e2cbb0c6b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52ea49af22194ceeb7d0014756942b23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5653cd0054e34263946603a7d6c3e3b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "57bbb2ada9f0494aa4335a1418e1809e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_caf3de995ab1481fadb9cf72b9c573fc",
       "placeholder": "​",
       "style": "IPY_MODEL_0fb39f643b2f4811be0d0c3409323d80",
       "value": " 226k/226k [00:00&lt;00:00, 4.39MB/s]"
      }
     },
     "5865b31e0bf24e4e80dd75fa252761e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58ec168261d746b2a2a803f6a87449c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "656311e69fa04ec7b6ddb361d470b11b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67c471286bcd4dcbb385a93887879a02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "694fd1a41ff147edb6eb32dd33fdb7c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b365053df97498e956e67bbe6b9ccfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2ecc0ca0282a4b51a9f47f299ddb0e25",
       "placeholder": "​",
       "style": "IPY_MODEL_5653cd0054e34263946603a7d6c3e3b8",
       "value": "Downloading: 100%"
      }
     },
     "6d448241463c48228efdfbe658d57acf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6d59d2793acc4f30a0537f06d94c947b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "76a8d4885d704b68a49cc354bd98162d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_67c471286bcd4dcbb385a93887879a02",
       "placeholder": "​",
       "style": "IPY_MODEL_834207598a374281ab4b2457b33ac1f1",
       "value": "Downloading: 100%"
      }
     },
     "7909f11c3d9d4884bef998dc86c6c433": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_694fd1a41ff147edb6eb32dd33fdb7c7",
       "placeholder": "​",
       "style": "IPY_MODEL_402bec0969c2439d9fe12534438cfd18",
       "value": " 455k/455k [00:00&lt;00:00, 5.73MB/s]"
      }
     },
     "79f1527694f74b80a5330cf6f99ea84e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d3e823820b9404eb59a5fc22f235788": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7efc71dd48044f4182faee7196648d75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_656311e69fa04ec7b6ddb361d470b11b",
       "max": 570,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_52ea49af22194ceeb7d0014756942b23",
       "value": 570
      }
     },
     "834207598a374281ab4b2457b33ac1f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9444d2913a734d248a9741f3727b10f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98d3a93be64a4c01a2d1c98d00515f5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c01269053814648ac62141686c8ff2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a28f0dbdde2448c4b1a3290a62c43eba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6b365053df97498e956e67bbe6b9ccfd",
        "IPY_MODEL_7efc71dd48044f4182faee7196648d75",
        "IPY_MODEL_17348793a7bb456bbb5ace7f13f537f6"
       ],
       "layout": "IPY_MODEL_7d3e823820b9404eb59a5fc22f235788"
      }
     },
     "a80cfef718d84bc8967f53cdf83a5986": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_508357fee53643ae9bbc41e2cbb0c6b0",
       "max": 466062,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6d59d2793acc4f30a0537f06d94c947b",
       "value": 466062
      }
     },
     "acf742bc1b9b4f71ae1f9ec994d85847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b8784b0f034242d3b9551a4b45615e53",
       "placeholder": "​",
       "style": "IPY_MODEL_9c01269053814648ac62141686c8ff2a",
       "value": " 28.0/28.0 [00:00&lt;00:00, 1.15kB/s]"
      }
     },
     "b4e4504a77a3486b9f66e38cebc63182": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8784b0f034242d3b9551a4b45615e53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c067bf2601a84417bf052635a54ef790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ce198efee07e4dd582a7c889f3b5f6d9",
        "IPY_MODEL_a80cfef718d84bc8967f53cdf83a5986",
        "IPY_MODEL_7909f11c3d9d4884bef998dc86c6c433"
       ],
       "layout": "IPY_MODEL_9444d2913a734d248a9741f3727b10f9"
      }
     },
     "c61426e6570245e6b1c07b09149e61bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_76a8d4885d704b68a49cc354bd98162d",
        "IPY_MODEL_0f54ff68288a47e4ab08fe1bbfc33d55",
        "IPY_MODEL_acf742bc1b9b4f71ae1f9ec994d85847"
       ],
       "layout": "IPY_MODEL_5865b31e0bf24e4e80dd75fa252761e1"
      }
     },
     "caf3de995ab1481fadb9cf72b9c573fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce198efee07e4dd582a7c889f3b5f6d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2c55c0d364b742ed8da1f4194e9d73db",
       "placeholder": "​",
       "style": "IPY_MODEL_6d448241463c48228efdfbe658d57acf",
       "value": "Downloading: 100%"
      }
     },
     "dcad6910ef2b43e7a8001ab17ab10112": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b4e4504a77a3486b9f66e38cebc63182",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_58ec168261d746b2a2a803f6a87449c5",
       "value": 231508
      }
     },
     "f5a281ae964e44528a7773b0213cb3a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa9b11bb2bba4257a632795bfe9f9b6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
