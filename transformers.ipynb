{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d843d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "        # Define layers for your custom transformer\n",
    "        self.transformer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.transformer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Assuming BERT embeddings size is 768\n",
    "input_dim = 768\n",
    "hidden_dim = 100\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "\n",
    "# Instantiate your custom transformer model\n",
    "custom_transformer = CustomTransformer(input_dim, hidden_dim, num_heads, num_layers)\n",
    "\n",
    "# Freeze the model parameters\n",
    "for param in custom_transformer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "32948913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5655032 , 0.0629204 , 0.035607  , 0.02010247, 1.4503956 ,\n",
       "        0.09055949, 0.        , 0.421587  , 0.        , 0.        ,\n",
       "        0.        , 0.6744474 , 0.2500276 , 0.14058623, 0.        ,\n",
       "        0.14104715, 0.20743507, 0.        , 0.6586079 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.22981495,\n",
       "        0.52168685, 0.0683948 , 0.1984303 , 0.        , 0.        ,\n",
       "        1.152183  , 0.33594042, 0.        , 0.09970921, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21027005,\n",
       "        0.        , 0.61612564, 0.        , 0.2756435 , 0.        ,\n",
       "        0.9495958 , 0.06774285, 0.8426675 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0373522 , 0.        , 0.42545766,\n",
       "        0.5773406 , 0.08728976, 0.        , 0.53563184, 0.        ,\n",
       "        0.        , 0.        , 0.01295132, 0.        , 0.52636856,\n",
       "        0.36273396, 0.4247045 , 0.        , 0.        , 0.01401085,\n",
       "        0.        , 0.        , 0.39746425, 0.8293907 , 0.05633289,\n",
       "        0.        , 0.19935398, 0.41709164, 0.9109269 , 0.71924156,\n",
       "        0.        , 0.        , 0.        , 0.3890374 , 0.        ,\n",
       "        0.        , 0.        , 0.7173725 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.2968187 , 1.5603547 , 0.        ,\n",
       "        0.1581842 , 0.6613386 , 0.        , 0.        , 0.18812901],\n",
       "       [0.12497017, 0.        , 0.        , 0.02940417, 1.2712435 ,\n",
       "        0.        , 0.08013362, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.49822763, 0.7959704 , 0.        , 0.        ,\n",
       "        0.30362076, 0.42414993, 0.        , 0.48073986, 0.        ,\n",
       "        0.30976966, 0.        , 0.        , 0.        , 0.70354277,\n",
       "        0.717788  , 0.        , 0.49068394, 0.        , 0.        ,\n",
       "        0.78611135, 0.14573823, 0.        , 0.35196573, 0.4964801 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16368997,\n",
       "        0.        , 0.2516388 , 0.        , 0.18130545, 0.45950755,\n",
       "        1.0887734 , 0.44169942, 0.81551635, 0.        , 0.34032822,\n",
       "        0.        , 0.        , 0.52407444, 0.32071033, 1.1685892 ,\n",
       "        0.82566416, 0.06411995, 0.        , 0.7212066 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.6946024 ,\n",
       "        0.        , 0.38756096, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5110537 , 0.04955871, 0.18735602, 0.18573694,\n",
       "        0.        , 1.1488973 , 0.26411697, 0.27636874, 0.2526963 ,\n",
       "        0.03291738, 0.        , 0.        , 0.9221464 , 0.        ,\n",
       "        0.        , 0.        , 0.06012075, 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.2902527 , 1.2163068 , 0.03902481,\n",
       "        0.0716404 , 0.30683914, 0.        , 0.        , 0.29512078],\n",
       "       [0.08565041, 0.        , 0.51633096, 0.5931968 , 0.04532242,\n",
       "        0.3216913 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32632348, 0.        , 0.22963047, 0.        ,\n",
       "        0.48302674, 0.765257  , 0.8555095 , 0.        , 0.        ,\n",
       "        0.3492543 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.07149115, 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.0233606 , 0.15442424, 0.        , 0.38698867, 0.2259089 ,\n",
       "        0.        , 0.7316801 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13220906, 0.40059456, 0.        , 0.        ,\n",
       "        0.18545566, 0.38025355, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15582705, 0.07638518, 0.        ,\n",
       "        0.9943968 , 0.        , 0.        , 0.9658755 , 0.        ,\n",
       "        0.        , 0.        , 0.64795285, 0.        , 0.42846963,\n",
       "        0.        , 0.        , 0.52795994, 0.        , 0.        ,\n",
       "        0.14727001, 0.66995007, 0.66500396, 0.        , 0.9049411 ,\n",
       "        0.        , 0.        , 0.        , 0.2439464 , 0.434475  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.03330337, 0.9907783 , 0.6351759 , 0.        ,\n",
       "        0.        , 0.        , 1.5536447 , 0.7658546 , 0.        ,\n",
       "        0.2331052 , 0.4512464 , 0.5377969 , 0.        , 0.        ],\n",
       "       [0.32890612, 0.37272385, 0.6896137 , 0.711786  , 0.5252039 ,\n",
       "        0.        , 0.01453317, 0.1488619 , 0.        , 0.89055485,\n",
       "        0.        , 0.01780896, 0.        , 0.50311494, 0.35330898,\n",
       "        0.26839647, 0.        , 0.2095265 , 0.15467879, 0.        ,\n",
       "        0.15549411, 0.2771639 , 0.        , 0.        , 0.16012497,\n",
       "        0.39347172, 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.0008359 , 0.24161008, 0.        , 0.64917237, 0.        ,\n",
       "        0.        , 0.2130384 , 0.        , 0.        , 0.491942  ,\n",
       "        0.        , 1.5853516 , 0.        , 0.6055695 , 0.15136452,\n",
       "        0.15518664, 0.49283996, 0.73798275, 0.        , 0.46311152,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1666965 ,\n",
       "        0.9095487 , 0.6054189 , 0.        , 1.1721979 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.30210295,\n",
       "        0.2659969 , 0.        , 0.        , 0.07478608, 0.        ,\n",
       "        0.        , 0.32645723, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.7549837 , 0.07076424, 1.125985  , 1.0144166 ,\n",
       "        0.        , 0.        , 0.        , 0.53428376, 0.        ,\n",
       "        0.        , 0.        , 0.5315026 , 0.54728204, 0.02598044,\n",
       "        0.        , 0.        , 0.93741834, 1.3343892 , 0.        ,\n",
       "        0.        , 0.30225313, 0.        , 0.1501782 , 0.        ],\n",
       "       [0.        , 0.        , 0.5670977 , 0.6394368 , 0.3107734 ,\n",
       "        0.        , 0.33971223, 0.        , 0.        , 0.11689204,\n",
       "        0.        , 0.3936182 , 0.37603432, 0.07245736, 0.6777852 ,\n",
       "        0.1929517 , 0.        , 0.27321157, 0.04674309, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1220435 ,\n",
       "        0.41908246, 0.09447516, 0.        , 0.        , 0.        ,\n",
       "        0.24436232, 0.14927799, 0.        , 0.        , 0.09268155,\n",
       "        0.        , 0.09772471, 0.        , 0.        , 0.85467815,\n",
       "        0.        , 1.2277962 , 0.14142135, 0.        , 0.40393037,\n",
       "        0.        , 0.7637555 , 0.49455518, 0.        , 0.8745331 ,\n",
       "        0.35811412, 0.        , 0.        , 0.21312363, 0.44525257,\n",
       "        0.852415  , 0.2721841 , 0.        , 1.644898  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.6400478 ,\n",
       "        0.01618051, 0.        , 0.        , 0.07588373, 0.08346815,\n",
       "        0.        , 0.4532409 , 0.6192842 , 0.3711217 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.47110566, 0.498631  ,\n",
       "        0.        , 0.        , 0.        , 0.40294194, 0.        ,\n",
       "        0.        , 0.26890713, 0.9185055 , 0.        , 0.13857713,\n",
       "        0.        , 0.        , 1.2959359 , 1.5999019 , 0.        ,\n",
       "        0.23109704, 0.21393766, 0.28291932, 0.        , 0.        ],\n",
       "       [0.3494446 , 0.7846924 , 0.6804622 , 0.54850715, 0.3160228 ,\n",
       "        0.06741425, 0.        , 0.794934  , 0.        , 0.77294654,\n",
       "        0.        , 0.        , 0.14705746, 0.02204178, 0.8506055 ,\n",
       "        0.98438245, 0.        , 0.        , 0.        , 0.23393023,\n",
       "        0.39485165, 0.        , 0.        , 0.77387655, 0.12239694,\n",
       "        0.03305601, 0.        , 0.04607843, 0.        , 0.        ,\n",
       "        0.68494165, 0.20634045, 1.0252686 , 0.        , 0.22590487,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.9302589 ,\n",
       "        0.        , 0.8731115 , 0.        , 0.52377266, 0.        ,\n",
       "        0.23517227, 0.8122318 , 0.        , 0.        , 0.15585397,\n",
       "        0.13472511, 0.        , 0.        , 0.        , 0.17810214,\n",
       "        0.9408668 , 0.14231606, 0.        , 0.        , 0.33856526,\n",
       "        0.25973848, 0.        , 0.8496238 , 0.        , 0.        ,\n",
       "        0.8792365 , 0.        , 0.20955236, 0.        , 0.        ,\n",
       "        0.        , 0.20152919, 0.        , 0.        , 0.58880246,\n",
       "        0.        , 0.        , 0.12530531, 0.09893768, 0.82546264,\n",
       "        0.        , 0.        , 0.        , 0.67076564, 0.        ,\n",
       "        0.        , 0.1693084 , 0.169576  , 0.        , 0.03256713,\n",
       "        0.02341828, 0.        , 0.37150842, 0.99253327, 0.        ,\n",
       "        0.        , 0.63130814, 0.18135804, 0.8111898 , 0.        ],\n",
       "       [0.7335155 , 0.6618778 , 1.1007535 , 0.        , 1.2568662 ,\n",
       "        0.        , 0.        , 0.        , 0.16973732, 0.64854485,\n",
       "        0.11725934, 0.        , 0.0848669 , 0.34012726, 0.5243255 ,\n",
       "        0.5839376 , 0.        , 0.53205013, 0.        , 0.1096787 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5018163 ,\n",
       "        0.        , 0.03441791, 0.        , 0.        , 0.        ,\n",
       "        0.7107306 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.03023657, 0.46164557, 0.        , 0.788022  , 0.        ,\n",
       "        0.4496852 , 0.03168474, 0.30848467, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.18309651, 0.        , 0.        ,\n",
       "        0.93325996, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04572175, 0.        , 0.20223694,\n",
       "        0.56499785, 0.26742452, 0.        , 0.60372066, 0.        ,\n",
       "        0.        , 0.6049653 , 0.        , 0.        , 0.31240463,\n",
       "        0.        , 0.05678489, 0.        , 0.7663859 , 0.6874973 ,\n",
       "        0.        , 0.        , 0.        , 0.2324404 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.98607665, 0.        ,\n",
       "        0.        , 0.        , 0.2572551 , 0.40679967, 0.        ,\n",
       "        0.        , 1.0876244 , 0.        , 0.72249675, 0.        ],\n",
       "       [0.36588386, 0.        , 0.39284542, 0.24139138, 0.2827353 ,\n",
       "        0.19054706, 0.        , 0.        , 0.        , 0.32495362,\n",
       "        1.0300053 , 0.11295403, 0.14682283, 0.        , 0.        ,\n",
       "        0.09582428, 0.03791351, 0.64984334, 0.        , 0.8838473 ,\n",
       "        0.        , 0.18392578, 0.        , 0.        , 0.28172752,\n",
       "        0.48130894, 0.        , 0.        , 0.24404302, 0.21310304,\n",
       "        0.34533137, 0.        , 0.39240754, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.40033096, 0.        , 0.        ,\n",
       "        0.        , 0.90476817, 0.3642347 , 0.        , 0.        ,\n",
       "        0.4061603 , 0.77801645, 0.52860963, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.49832225, 0.        , 0.01622028,\n",
       "        0.7169599 , 0.        , 0.        , 0.5659508 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.22492939,\n",
       "        0.34337106, 0.        , 0.58545095, 0.        , 0.        ,\n",
       "        0.        , 1.0074277 , 0.40670168, 0.14410707, 0.20328009,\n",
       "        0.        , 0.        , 0.        , 0.33352706, 0.92999923,\n",
       "        0.        , 0.        , 0.        , 0.8278682 , 0.        ,\n",
       "        0.        , 0.28531504, 0.624797  , 0.        , 0.210319  ,\n",
       "        0.        , 0.        , 0.82138103, 1.2561551 , 0.        ,\n",
       "        0.        , 0.86191034, 0.        , 0.44790086, 0.        ],\n",
       "       [0.        , 0.        , 1.0158585 , 0.6819924 , 0.39183986,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.19887479,\n",
       "        0.        , 0.10284373, 0.        , 0.17911491, 0.48301947,\n",
       "        0.8473507 , 0.21704707, 0.21824007, 0.        , 0.        ,\n",
       "        0.08759748, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.386105  , 0.09260314, 0.00539866, 0.30043995, 0.25140464,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.50247097, 0.        , 0.0300398 , 0.        ,\n",
       "        0.5479768 , 0.97784865, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13881093, 0.        , 0.5700488 ,\n",
       "        0.785929  , 0.        , 0.        , 0.6547961 , 0.        ,\n",
       "        0.        , 0.        , 0.41005152, 0.        , 0.96659255,\n",
       "        0.        , 0.        , 0.2709124 , 0.31606156, 0.        ,\n",
       "        0.        , 0.31350523, 0.6791744 , 0.44645253, 1.3292989 ,\n",
       "        0.        , 0.15370576, 0.        , 1.0355415 , 0.4377466 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92523164, 0.        , 0.        ,\n",
       "        0.3647359 , 0.33507118, 1.5186669 , 1.3293651 , 0.        ,\n",
       "        0.        , 0.39361304, 0.27689436, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.23551759, 0.63043827, 0.        ,\n",
       "        0.        , 0.29021248, 0.        , 0.        , 0.        ,\n",
       "        0.25673515, 0.44700655, 0.3153596 , 0.        , 0.14477935,\n",
       "        0.8247325 , 0.6355254 , 0.29495165, 0.        , 0.5273364 ,\n",
       "        0.25499418, 0.        , 0.25798997, 0.2613941 , 0.22946076,\n",
       "        0.2849401 , 0.09044528, 0.3615719 , 0.        , 0.        ,\n",
       "        0.6684036 , 0.        , 0.36179215, 0.26112714, 0.1750777 ,\n",
       "        0.        , 0.54953194, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.99717945, 1.0775675 , 0.        , 0.        ,\n",
       "        0.7295151 , 0.9970536 , 0.27765417, 0.04361241, 0.        ,\n",
       "        0.        , 0.01977212, 0.24672377, 0.        , 0.02979191,\n",
       "        0.5470888 , 0.03019462, 0.        , 0.72749263, 0.        ,\n",
       "        0.        , 0.        , 0.10577321, 0.20392385, 0.44081837,\n",
       "        0.        , 0.00794947, 0.9732777 , 0.        , 0.        ,\n",
       "        0.        , 0.7368231 , 0.62611824, 0.22642143, 0.3700548 ,\n",
       "        0.        , 0.        , 0.3099863 , 0.31010094, 0.53087157,\n",
       "        0.        , 0.        , 0.        , 0.22133656, 0.00538145,\n",
       "        0.05058939, 0.        , 0.688728  , 0.        , 0.25951797,\n",
       "        0.298407  , 0.        , 0.5170786 , 0.8665954 , 0.        ,\n",
       "        0.        , 0.949622  , 0.        , 0.5165448 , 0.02411245]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embeddings = Embeddings().get_embeddings([\"hi\",\"hey\", \"julia hates code\", \"fuck college\", \"fuck\", \"penn\", \"upenn\", \"vedha\", \"julia\", \"vedha loves pie\"])[1].last_hidden_state[:, 0]\n",
    "\n",
    "# Print the same output multiple times\n",
    "for _ in range(1000):\n",
    "    # Use the transformer to generate output\n",
    "    output = custom_transformer(bert_embeddings).cpu().detach().numpy()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0217ea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.self_attn.in_proj_weight False\n",
      "transformer.self_attn.in_proj_bias False\n",
      "transformer.self_attn.out_proj.weight False\n",
      "transformer.self_attn.out_proj.bias False\n",
      "transformer.linear1.weight False\n",
      "transformer.linear1.bias False\n",
      "transformer.linear2.weight False\n",
      "transformer.linear2.bias False\n",
      "transformer.norm1.weight False\n",
      "transformer.norm1.bias False\n",
      "transformer.norm2.weight False\n",
      "transformer.norm2.bias False\n",
      "transformer_encoder.layers.0.self_attn.in_proj_weight False\n",
      "transformer_encoder.layers.0.self_attn.in_proj_bias False\n",
      "transformer_encoder.layers.0.self_attn.out_proj.weight False\n",
      "transformer_encoder.layers.0.self_attn.out_proj.bias False\n",
      "transformer_encoder.layers.0.linear1.weight False\n",
      "transformer_encoder.layers.0.linear1.bias False\n",
      "transformer_encoder.layers.0.linear2.weight False\n",
      "transformer_encoder.layers.0.linear2.bias False\n",
      "transformer_encoder.layers.0.norm1.weight False\n",
      "transformer_encoder.layers.0.norm1.bias False\n",
      "transformer_encoder.layers.0.norm2.weight False\n",
      "transformer_encoder.layers.0.norm2.bias False\n",
      "transformer_encoder.layers.1.self_attn.in_proj_weight False\n",
      "transformer_encoder.layers.1.self_attn.in_proj_bias False\n",
      "transformer_encoder.layers.1.self_attn.out_proj.weight False\n",
      "transformer_encoder.layers.1.self_attn.out_proj.bias False\n",
      "transformer_encoder.layers.1.linear1.weight False\n",
      "transformer_encoder.layers.1.linear1.bias False\n",
      "transformer_encoder.layers.1.linear2.weight False\n",
      "transformer_encoder.layers.1.linear2.bias False\n",
      "transformer_encoder.layers.1.norm1.weight False\n",
      "transformer_encoder.layers.1.norm1.bias False\n",
      "transformer_encoder.layers.1.norm2.weight False\n",
      "transformer_encoder.layers.1.norm2.bias False\n",
      "fc.weight False\n",
      "fc.bias False\n"
     ]
    }
   ],
   "source": [
    "# Print requires_grad status of parameters\n",
    "for name, param in custom_transformer.named_parameters():\n",
    "    print(name, param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9aba4afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32492712, 0.        , 0.        ],\n",
       "       [0.68284047, 0.        , 0.23811845],\n",
       "       [0.5894346 , 1.0451578 , 0.        ],\n",
       "       [0.25341946, 0.        , 1.0140357 ]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use BERT embeddings as input to your transformer\n",
    "output = custom_transformer(bert_embeddings)\n",
    "\n",
    "# Your model will now always output the same result, as the parameters are frozen\n",
    "embeddings_dataset = output.cpu().detach().numpy()\n",
    "embeddings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53c2e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import faiss\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Embeddings:\n",
    "    #CLS is a special classification token and the last hidden state of BERT Embedding\n",
    "    def cls_pooling(self, model_output):\n",
    "        return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "    #BERT tokenizer of input text\n",
    "    def get_embeddings(self, text_list):\n",
    "        encoded_input = tokenizer(\n",
    "            text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        model_output = model(**encoded_input)\n",
    "        return self.cls_pooling(model_output).cpu().detach().numpy(), model_output\n",
    "    \n",
    "    \n",
    "    #convert dataset into embeddings dataset to run FAISS\n",
    "    def makeEmbeddings(self,dataset):\n",
    "        embeddings = []\n",
    "        for data in dataset:\n",
    "            embeddings.append(self.get_embeddings(data)[0])\n",
    "        return np.array(embeddings)\n",
    "    \n",
    "    def getQueryEmbedding(self, query):\n",
    "        return self.get_embeddings([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a79424f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = Embeddings().get_embeddings([\"hi\",\"hey\", \"julia hates code\", \"fuck college\"])[1].last_hidden_state[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5418508a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embeddings.is_nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "42d71dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class Faiss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def faiss(self,xb):\n",
    "        d = xb[0].size\n",
    "        M = 32\n",
    "        index = faiss.IndexHNSWFlat(d, M)            \n",
    "        index.hnsw.efConstruction = 40         # Setting the value for efConstruction.\n",
    "        index.hnsw.efSearch = 16               # Setting the value for efSearch.\n",
    "        index.add(xb)\n",
    "        return index\n",
    "    \n",
    "    def query(self,index,xq,k=3):\n",
    "        D, I = index.search(xq, k)   \n",
    "        return D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f46e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dataset = output[:len(output)-1]\n",
    "xq = output[len(output)-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "de974f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = embeddings_dataset\n",
    "\n",
    "index = Faiss().faiss(xb)\n",
    "D,I = Faiss().query(index,xq)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c9bd4a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.68749493, 0.67374915],\n",
       "       [0.        , 0.43349937, 0.75967026]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7fa3a727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.3699596 , 0.5188751 ],\n",
       "       [0.        , 0.561179  , 0.        ],\n",
       "       [0.        , 0.12295088, 0.        ],\n",
       "       [0.        , 0.68749493, 0.67374915]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca7fe53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.3699596 , 0.5188751 ],\n",
       "       [0.        , 0.561179  , 0.        ],\n",
       "       [0.        , 0.12295088, 0.        ],\n",
       "       [0.        , 0.68749493, 0.67374915],\n",
       "       [0.        , 0.43349937, 0.75967026]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7fd0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
